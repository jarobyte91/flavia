{"sentences": "{\"filename\":{\"0\":\"obesity.pdf\",\"1\":\"obesity.pdf\",\"2\":\"obesity.pdf\",\"3\":\"obesity.pdf\",\"4\":\"obesity.pdf\",\"5\":\"obesity.pdf\",\"6\":\"obesity.pdf\",\"7\":\"obesity.pdf\",\"8\":\"obesity.pdf\",\"9\":\"obesity.pdf\",\"10\":\"obesity.pdf\",\"11\":\"obesity.pdf\",\"12\":\"obesity.pdf\",\"13\":\"obesity.pdf\",\"14\":\"obesity.pdf\",\"15\":\"obesity.pdf\",\"16\":\"obesity.pdf\",\"17\":\"obesity.pdf\",\"18\":\"obesity.pdf\",\"19\":\"obesity.pdf\",\"20\":\"obesity.pdf\",\"21\":\"obesity.pdf\",\"22\":\"obesity.pdf\",\"23\":\"obesity.pdf\",\"24\":\"obesity.pdf\",\"25\":\"obesity.pdf\",\"26\":\"obesity.pdf\",\"27\":\"obesity.pdf\",\"28\":\"obesity.pdf\",\"29\":\"obesity.pdf\",\"30\":\"obesity.pdf\",\"31\":\"obesity.pdf\",\"32\":\"obesity.pdf\",\"33\":\"obesity.pdf\",\"34\":\"obesity.pdf\",\"35\":\"obesity.pdf\",\"36\":\"obesity.pdf\",\"37\":\"obesity.pdf\",\"38\":\"obesity.pdf\",\"39\":\"obesity.pdf\",\"40\":\"obesity.pdf\",\"41\":\"obesity.pdf\",\"42\":\"obesity.pdf\",\"43\":\"obesity.pdf\",\"44\":\"obesity.pdf\",\"45\":\"obesity.pdf\",\"46\":\"obesity.pdf\",\"47\":\"obesity.pdf\",\"48\":\"obesity.pdf\",\"49\":\"obesity.pdf\",\"50\":\"obesity.pdf\",\"51\":\"obesity.pdf\",\"52\":\"obesity.pdf\",\"53\":\"obesity.pdf\",\"54\":\"obesity.pdf\",\"55\":\"obesity.pdf\",\"56\":\"obesity.pdf\",\"57\":\"obesity.pdf\",\"58\":\"obesity.pdf\",\"59\":\"obesity.pdf\",\"60\":\"obesity.pdf\",\"61\":\"obesity.pdf\",\"62\":\"obesity.pdf\",\"63\":\"obesity.pdf\",\"64\":\"obesity.pdf\",\"65\":\"obesity.pdf\",\"66\":\"obesity.pdf\",\"67\":\"obesity.pdf\",\"68\":\"obesity.pdf\",\"69\":\"obesity.pdf\",\"70\":\"obesity.pdf\",\"71\":\"obesity.pdf\",\"72\":\"obesity.pdf\",\"73\":\"obesity.pdf\",\"74\":\"obesity.pdf\",\"75\":\"obesity.pdf\",\"76\":\"obesity.pdf\",\"77\":\"obesity.pdf\",\"78\":\"obesity.pdf\",\"79\":\"obesity.pdf\",\"80\":\"obesity.pdf\",\"81\":\"obesity.pdf\",\"82\":\"obesity.pdf\",\"83\":\"obesity.pdf\",\"84\":\"obesity.pdf\",\"85\":\"obesity.pdf\",\"86\":\"obesity.pdf\",\"87\":\"obesity.pdf\",\"88\":\"obesity.pdf\",\"89\":\"obesity.pdf\",\"90\":\"obesity.pdf\",\"91\":\"obesity.pdf\",\"92\":\"obesity.pdf\",\"93\":\"obesity.pdf\",\"94\":\"obesity.pdf\",\"95\":\"obesity.pdf\",\"96\":\"obesity.pdf\",\"97\":\"obesity.pdf\",\"98\":\"obesity.pdf\",\"99\":\"obesity.pdf\",\"100\":\"obesity.pdf\",\"101\":\"obesity.pdf\",\"102\":\"obesity.pdf\",\"103\":\"obesity.pdf\",\"104\":\"obesity.pdf\",\"105\":\"obesity.pdf\",\"106\":\"obesity.pdf\",\"107\":\"obesity.pdf\",\"108\":\"obesity.pdf\",\"109\":\"obesity.pdf\",\"110\":\"obesity.pdf\",\"111\":\"obesity.pdf\",\"112\":\"obesity.pdf\",\"113\":\"obesity.pdf\",\"114\":\"obesity.pdf\",\"115\":\"obesity.pdf\",\"116\":\"obesity.pdf\",\"117\":\"obesity.pdf\",\"118\":\"obesity.pdf\",\"119\":\"obesity.pdf\",\"120\":\"obesity.pdf\",\"121\":\"obesity.pdf\",\"122\":\"obesity.pdf\",\"123\":\"obesity.pdf\",\"124\":\"obesity.pdf\",\"125\":\"obesity.pdf\",\"126\":\"obesity.pdf\",\"127\":\"obesity.pdf\",\"128\":\"obesity.pdf\",\"129\":\"obesity.pdf\",\"130\":\"obesity.pdf\",\"131\":\"obesity.pdf\",\"132\":\"obesity.pdf\",\"133\":\"obesity.pdf\",\"134\":\"obesity.pdf\",\"135\":\"obesity.pdf\",\"136\":\"obesity.pdf\",\"137\":\"obesity.pdf\",\"138\":\"obesity.pdf\",\"139\":\"obesity.pdf\",\"140\":\"obesity.pdf\",\"141\":\"obesity.pdf\",\"142\":\"obesity.pdf\",\"143\":\"obesity.pdf\",\"144\":\"obesity.pdf\",\"145\":\"obesity.pdf\",\"146\":\"obesity.pdf\",\"147\":\"obesity.pdf\",\"148\":\"obesity.pdf\",\"149\":\"obesity.pdf\",\"150\":\"obesity.pdf\",\"151\":\"obesity.pdf\",\"152\":\"obesity.pdf\",\"153\":\"obesity.pdf\",\"154\":\"obesity.pdf\",\"155\":\"obesity.pdf\",\"156\":\"obesity.pdf\",\"157\":\"obesity.pdf\",\"158\":\"obesity.pdf\",\"159\":\"obesity.pdf\",\"160\":\"obesity.pdf\",\"161\":\"obesity.pdf\",\"162\":\"obesity.pdf\",\"163\":\"obesity.pdf\",\"164\":\"obesity.pdf\",\"165\":\"obesity.pdf\",\"166\":\"obesity.pdf\",\"167\":\"obesity.pdf\",\"168\":\"obesity.pdf\",\"169\":\"obesity.pdf\",\"170\":\"obesity.pdf\",\"171\":\"obesity.pdf\",\"172\":\"obesity.pdf\",\"173\":\"obesity.pdf\",\"174\":\"obesity.pdf\",\"175\":\"obesity.pdf\",\"176\":\"obesity.pdf\",\"177\":\"obesity.pdf\",\"178\":\"obesity.pdf\",\"179\":\"obesity.pdf\",\"180\":\"obesity.pdf\",\"181\":\"obesity.pdf\",\"182\":\"obesity.pdf\",\"183\":\"obesity.pdf\",\"184\":\"obesity.pdf\",\"185\":\"obesity.pdf\",\"186\":\"obesity.pdf\",\"187\":\"obesity.pdf\",\"188\":\"obesity.pdf\",\"189\":\"obesity.pdf\",\"190\":\"obesity.pdf\",\"191\":\"obesity.pdf\",\"192\":\"obesity.pdf\",\"193\":\"obesity.pdf\",\"194\":\"obesity.pdf\",\"195\":\"obesity.pdf\",\"196\":\"obesity.pdf\",\"197\":\"obesity.pdf\",\"198\":\"obesity.pdf\",\"199\":\"obesity.pdf\",\"200\":\"obesity.pdf\",\"201\":\"obesity.pdf\",\"202\":\"obesity.pdf\",\"203\":\"obesity.pdf\",\"204\":\"obesity.pdf\",\"205\":\"obesity.pdf\",\"206\":\"obesity.pdf\",\"207\":\"obesity.pdf\",\"208\":\"obesity.pdf\",\"209\":\"obesity.pdf\",\"210\":\"obesity.pdf\",\"211\":\"obesity.pdf\",\"212\":\"obesity.pdf\",\"213\":\"obesity.pdf\",\"214\":\"obesity.pdf\",\"215\":\"obesity.pdf\",\"216\":\"obesity.pdf\",\"217\":\"obesity.pdf\",\"218\":\"obesity.pdf\",\"219\":\"obesity.pdf\",\"220\":\"obesity.pdf\",\"221\":\"obesity.pdf\",\"222\":\"obesity.pdf\",\"223\":\"obesity.pdf\",\"224\":\"obesity.pdf\",\"225\":\"obesity.pdf\",\"226\":\"obesity.pdf\",\"227\":\"obesity.pdf\",\"228\":\"obesity.pdf\",\"229\":\"obesity.pdf\",\"230\":\"obesity.pdf\",\"231\":\"obesity.pdf\",\"232\":\"obesity.pdf\",\"233\":\"obesity.pdf\",\"234\":\"obesity.pdf\",\"235\":\"obesity.pdf\",\"236\":\"obesity.pdf\",\"237\":\"obesity.pdf\",\"238\":\"obesity.pdf\",\"239\":\"obesity.pdf\",\"240\":\"obesity.pdf\",\"241\":\"obesity.pdf\",\"242\":\"obesity.pdf\",\"243\":\"obesity.pdf\",\"244\":\"obesity.pdf\",\"245\":\"obesity.pdf\",\"246\":\"obesity.pdf\",\"247\":\"obesity.pdf\",\"248\":\"obesity.pdf\",\"249\":\"obesity.pdf\",\"250\":\"obesity.pdf\",\"251\":\"obesity.pdf\",\"252\":\"obesity.pdf\",\"253\":\"obesity.pdf\",\"254\":\"obesity.pdf\",\"255\":\"obesity.pdf\",\"256\":\"obesity.pdf\",\"257\":\"obesity.pdf\",\"258\":\"obesity.pdf\",\"259\":\"obesity.pdf\",\"260\":\"obesity.pdf\",\"261\":\"obesity.pdf\",\"262\":\"obesity.pdf\",\"263\":\"obesity.pdf\",\"264\":\"obesity.pdf\",\"265\":\"obesity.pdf\",\"266\":\"obesity.pdf\",\"267\":\"obesity.pdf\",\"268\":\"obesity.pdf\",\"269\":\"obesity.pdf\",\"270\":\"obesity.pdf\",\"271\":\"obesity.pdf\",\"272\":\"obesity.pdf\",\"273\":\"obesity.pdf\",\"274\":\"obesity.pdf\",\"275\":\"fgene-12-783845.pdf\",\"276\":\"fgene-12-783845.pdf\",\"277\":\"fgene-12-783845.pdf\",\"278\":\"fgene-12-783845.pdf\",\"279\":\"fgene-12-783845.pdf\",\"280\":\"fgene-12-783845.pdf\",\"281\":\"fgene-12-783845.pdf\",\"282\":\"fgene-12-783845.pdf\",\"283\":\"fgene-12-783845.pdf\",\"284\":\"fgene-12-783845.pdf\",\"285\":\"fgene-12-783845.pdf\",\"286\":\"fgene-12-783845.pdf\",\"287\":\"fgene-12-783845.pdf\",\"288\":\"fgene-12-783845.pdf\",\"289\":\"fgene-12-783845.pdf\",\"290\":\"fgene-12-783845.pdf\",\"291\":\"fgene-12-783845.pdf\",\"292\":\"fgene-12-783845.pdf\",\"293\":\"fgene-12-783845.pdf\",\"294\":\"fgene-12-783845.pdf\",\"295\":\"fgene-12-783845.pdf\",\"296\":\"fgene-12-783845.pdf\",\"297\":\"fgene-12-783845.pdf\",\"298\":\"fgene-12-783845.pdf\",\"299\":\"fgene-12-783845.pdf\",\"300\":\"fgene-12-783845.pdf\",\"301\":\"fgene-12-783845.pdf\",\"302\":\"fgene-12-783845.pdf\",\"303\":\"fgene-12-783845.pdf\",\"304\":\"fgene-12-783845.pdf\",\"305\":\"fgene-12-783845.pdf\",\"306\":\"fgene-12-783845.pdf\",\"307\":\"fgene-12-783845.pdf\",\"308\":\"fgene-12-783845.pdf\",\"309\":\"fgene-12-783845.pdf\",\"310\":\"fgene-12-783845.pdf\",\"311\":\"fgene-12-783845.pdf\",\"312\":\"fgene-12-783845.pdf\",\"313\":\"fgene-12-783845.pdf\",\"314\":\"fgene-12-783845.pdf\",\"315\":\"fgene-12-783845.pdf\",\"316\":\"fgene-12-783845.pdf\",\"317\":\"fgene-12-783845.pdf\",\"318\":\"fgene-12-783845.pdf\",\"319\":\"fgene-12-783845.pdf\",\"320\":\"fgene-12-783845.pdf\",\"321\":\"fgene-12-783845.pdf\",\"322\":\"fgene-12-783845.pdf\",\"323\":\"fgene-12-783845.pdf\",\"324\":\"fgene-12-783845.pdf\",\"325\":\"fgene-12-783845.pdf\",\"326\":\"fgene-12-783845.pdf\",\"327\":\"fgene-12-783845.pdf\",\"328\":\"fgene-12-783845.pdf\",\"329\":\"fgene-12-783845.pdf\",\"330\":\"fgene-12-783845.pdf\",\"331\":\"fgene-12-783845.pdf\",\"332\":\"fgene-12-783845.pdf\",\"333\":\"fgene-12-783845.pdf\",\"334\":\"fgene-12-783845.pdf\",\"335\":\"fgene-12-783845.pdf\",\"336\":\"fgene-12-783845.pdf\",\"337\":\"fgene-12-783845.pdf\",\"338\":\"fgene-12-783845.pdf\",\"339\":\"fgene-12-783845.pdf\",\"340\":\"fgene-12-783845.pdf\",\"341\":\"fgene-12-783845.pdf\",\"342\":\"fgene-12-783845.pdf\",\"343\":\"fgene-12-783845.pdf\",\"344\":\"fgene-12-783845.pdf\",\"345\":\"fgene-12-783845.pdf\",\"346\":\"fgene-12-783845.pdf\",\"347\":\"fgene-12-783845.pdf\",\"348\":\"fgene-12-783845.pdf\",\"349\":\"fgene-12-783845.pdf\",\"350\":\"fgene-12-783845.pdf\",\"351\":\"fgene-12-783845.pdf\",\"352\":\"fgene-12-783845.pdf\",\"353\":\"fgene-12-783845.pdf\",\"354\":\"fgene-12-783845.pdf\",\"355\":\"fgene-12-783845.pdf\",\"356\":\"fgene-12-783845.pdf\",\"357\":\"fgene-12-783845.pdf\",\"358\":\"fgene-12-783845.pdf\",\"359\":\"fgene-12-783845.pdf\",\"360\":\"fgene-12-783845.pdf\",\"361\":\"fgene-12-783845.pdf\",\"362\":\"fgene-12-783845.pdf\",\"363\":\"fgene-12-783845.pdf\",\"364\":\"fgene-12-783845.pdf\",\"365\":\"fgene-12-783845.pdf\",\"366\":\"fgene-12-783845.pdf\",\"367\":\"fgene-12-783845.pdf\",\"368\":\"fgene-12-783845.pdf\",\"369\":\"fgene-12-783845.pdf\",\"370\":\"fgene-12-783845.pdf\",\"371\":\"fgene-12-783845.pdf\",\"372\":\"fgene-12-783845.pdf\",\"373\":\"fgene-12-783845.pdf\",\"374\":\"fgene-12-783845.pdf\",\"375\":\"fgene-12-783845.pdf\",\"376\":\"fgene-12-783845.pdf\",\"377\":\"fgene-12-783845.pdf\",\"378\":\"fgene-12-783845.pdf\",\"379\":\"fgene-12-783845.pdf\",\"380\":\"fgene-12-783845.pdf\",\"381\":\"fgene-12-783845.pdf\",\"382\":\"fgene-12-783845.pdf\",\"383\":\"fgene-12-783845.pdf\",\"384\":\"fgene-12-783845.pdf\",\"385\":\"fgene-12-783845.pdf\",\"386\":\"fgene-12-783845.pdf\",\"387\":\"fgene-12-783845.pdf\",\"388\":\"fgene-12-783845.pdf\",\"389\":\"fgene-12-783845.pdf\",\"390\":\"fgene-12-783845.pdf\",\"391\":\"fgene-12-783845.pdf\",\"392\":\"fgene-12-783845.pdf\",\"393\":\"fgene-12-783845.pdf\",\"394\":\"fgene-12-783845.pdf\",\"395\":\"fgene-12-783845.pdf\",\"396\":\"fgene-12-783845.pdf\",\"397\":\"fgene-12-783845.pdf\",\"398\":\"fgene-12-783845.pdf\",\"399\":\"fgene-12-783845.pdf\",\"400\":\"fgene-12-783845.pdf\",\"401\":\"fgene-12-783845.pdf\",\"402\":\"fgene-12-783845.pdf\",\"403\":\"fgene-12-783845.pdf\",\"404\":\"fgene-12-783845.pdf\",\"405\":\"fgene-12-783845.pdf\",\"406\":\"fgene-12-783845.pdf\",\"407\":\"fgene-12-783845.pdf\",\"408\":\"fgene-12-783845.pdf\",\"409\":\"fgene-12-783845.pdf\",\"410\":\"fgene-12-783845.pdf\",\"411\":\"fgene-12-783845.pdf\",\"412\":\"fgene-12-783845.pdf\",\"413\":\"fgene-12-783845.pdf\",\"414\":\"fgene-12-783845.pdf\",\"415\":\"fgene-12-783845.pdf\",\"416\":\"fgene-12-783845.pdf\",\"417\":\"fgene-12-783845.pdf\",\"418\":\"fgene-12-783845.pdf\",\"419\":\"fgene-12-783845.pdf\",\"420\":\"fgene-12-783845.pdf\",\"421\":\"fgene-12-783845.pdf\",\"422\":\"fgene-12-783845.pdf\",\"423\":\"fgene-12-783845.pdf\",\"424\":\"fgene-12-783845.pdf\",\"425\":\"fgene-12-783845.pdf\",\"426\":\"fgene-12-783845.pdf\",\"427\":\"fgene-12-783845.pdf\",\"428\":\"fgene-12-783845.pdf\",\"429\":\"fgene-12-783845.pdf\",\"430\":\"fgene-12-783845.pdf\",\"431\":\"fgene-12-783845.pdf\",\"432\":\"fgene-12-783845.pdf\",\"433\":\"fgene-12-783845.pdf\",\"434\":\"fgene-12-783845.pdf\",\"435\":\"fgene-12-783845.pdf\",\"436\":\"fgene-12-783845.pdf\",\"437\":\"fgene-12-783845.pdf\",\"438\":\"fgene-12-783845.pdf\",\"439\":\"fgene-12-783845.pdf\",\"440\":\"fgene-12-783845.pdf\",\"441\":\"fgene-12-783845.pdf\",\"442\":\"fgene-12-783845.pdf\",\"443\":\"fgene-12-783845.pdf\",\"444\":\"fgene-12-783845.pdf\",\"445\":\"fgene-12-783845.pdf\",\"446\":\"fgene-12-783845.pdf\",\"447\":\"fgene-12-783845.pdf\",\"448\":\"fgene-12-783845.pdf\",\"449\":\"fgene-12-783845.pdf\",\"450\":\"fgene-12-783845.pdf\",\"451\":\"fgene-12-783845.pdf\",\"452\":\"fgene-12-783845.pdf\",\"453\":\"fgene-12-783845.pdf\",\"454\":\"fgene-12-783845.pdf\",\"455\":\"fgene-12-783845.pdf\",\"456\":\"fgene-12-783845.pdf\",\"457\":\"fgene-12-783845.pdf\",\"458\":\"fgene-12-783845.pdf\",\"459\":\"fgene-12-783845.pdf\",\"460\":\"fgene-12-783845.pdf\",\"461\":\"fgene-12-783845.pdf\",\"462\":\"fgene-12-783845.pdf\",\"463\":\"fgene-12-783845.pdf\",\"464\":\"fgene-12-783845.pdf\",\"465\":\"fgene-12-783845.pdf\",\"466\":\"fgene-12-783845.pdf\",\"467\":\"fgene-12-783845.pdf\",\"468\":\"fgene-12-783845.pdf\",\"469\":\"fgene-12-783845.pdf\",\"470\":\"fgene-12-783845.pdf\",\"471\":\"fgene-12-783845.pdf\",\"472\":\"fgene-12-783845.pdf\",\"473\":\"fgene-12-783845.pdf\",\"474\":\"fgene-12-783845.pdf\",\"475\":\"fgene-12-783845.pdf\",\"476\":\"fgene-12-783845.pdf\",\"477\":\"fgene-12-783845.pdf\",\"478\":\"fgene-12-783845.pdf\",\"479\":\"fgene-12-783845.pdf\",\"480\":\"fgene-12-783845.pdf\",\"481\":\"fgene-12-783845.pdf\",\"482\":\"fgene-12-783845.pdf\",\"483\":\"fgene-12-783845.pdf\",\"484\":\"fgene-12-783845.pdf\",\"485\":\"fgene-12-783845.pdf\",\"486\":\"fgene-12-783845.pdf\",\"487\":\"fgene-12-783845.pdf\",\"488\":\"fgene-12-783845.pdf\",\"489\":\"fgene-12-783845.pdf\",\"490\":\"fgene-12-783845.pdf\",\"491\":\"fgene-12-783845.pdf\",\"492\":\"fgene-12-783845.pdf\",\"493\":\"fgene-12-783845.pdf\",\"494\":\"fgene-12-783845.pdf\",\"495\":\"fgene-12-783845.pdf\",\"496\":\"fgene-12-783845.pdf\",\"497\":\"fgene-12-783845.pdf\",\"498\":\"fgene-12-783845.pdf\",\"499\":\"fgene-12-783845.pdf\",\"500\":\"fgene-12-783845.pdf\",\"501\":\"fgene-12-783845.pdf\",\"502\":\"fgene-12-783845.pdf\",\"503\":\"fgene-12-783845.pdf\",\"504\":\"fgene-12-783845.pdf\",\"505\":\"fgene-12-783845.pdf\",\"506\":\"fgene-12-783845.pdf\",\"507\":\"fgene-12-783845.pdf\",\"508\":\"fgene-12-783845.pdf\",\"509\":\"fgene-12-783845.pdf\",\"510\":\"fgene-12-783845.pdf\",\"511\":\"fgene-12-783845.pdf\",\"512\":\"fgene-12-783845.pdf\",\"513\":\"fgene-12-783845.pdf\",\"514\":\"fgene-12-783845.pdf\",\"515\":\"fgene-12-783845.pdf\",\"516\":\"fgene-12-783845.pdf\",\"517\":\"fgene-12-783845.pdf\",\"518\":\"fgene-12-783845.pdf\",\"519\":\"fgene-12-783845.pdf\",\"520\":\"fgene-12-783845.pdf\",\"521\":\"fgene-12-783845.pdf\",\"522\":\"fgene-12-783845.pdf\",\"523\":\"fgene-12-783845.pdf\",\"524\":\"fgene-12-783845.pdf\",\"525\":\"fgene-12-783845.pdf\",\"526\":\"fgene-12-783845.pdf\",\"527\":\"fgene-12-783845.pdf\",\"528\":\"fgene-12-783845.pdf\",\"529\":\"fgene-12-783845.pdf\",\"530\":\"fgene-12-783845.pdf\",\"531\":\"fgene-12-783845.pdf\",\"532\":\"fgene-12-783845.pdf\",\"533\":\"fgene-12-783845.pdf\",\"534\":\"fgene-12-783845.pdf\",\"535\":\"fgene-12-783845.pdf\",\"536\":\"fgene-12-783845.pdf\",\"537\":\"fgene-12-783845.pdf\",\"538\":\"fgene-12-783845.pdf\",\"539\":\"fgene-12-783845.pdf\",\"540\":\"fgene-12-783845.pdf\",\"541\":\"fgene-12-783845.pdf\",\"542\":\"fgene-12-783845.pdf\",\"543\":\"fgene-12-783845.pdf\",\"544\":\"fgene-12-783845.pdf\",\"545\":\"fgene-12-783845.pdf\",\"546\":\"fgene-12-783845.pdf\",\"547\":\"fgene-12-783845.pdf\",\"548\":\"fgene-12-783845.pdf\",\"549\":\"fgene-12-783845.pdf\",\"550\":\"fgene-12-783845.pdf\",\"551\":\"fgene-12-783845.pdf\",\"552\":\"fgene-12-783845.pdf\",\"553\":\"fgene-12-783845.pdf\",\"554\":\"fgene-12-783845.pdf\",\"555\":\"fgene-12-783845.pdf\",\"556\":\"fgene-12-783845.pdf\",\"557\":\"fgene-12-783845.pdf\",\"558\":\"fgene-12-783845.pdf\",\"559\":\"fgene-12-783845.pdf\",\"560\":\"fgene-12-783845.pdf\",\"561\":\"fgene-12-783845.pdf\",\"562\":\"fgene-12-783845.pdf\",\"563\":\"fgene-12-783845.pdf\",\"564\":\"fgene-12-783845.pdf\",\"565\":\"fgene-12-783845.pdf\",\"566\":\"fgene-12-783845.pdf\",\"567\":\"fgene-12-783845.pdf\",\"568\":\"fgene-12-783845.pdf\",\"569\":\"fgene-12-783845.pdf\",\"570\":\"fgene-12-783845.pdf\",\"571\":\"fgene-12-783845.pdf\",\"572\":\"fgene-12-783845.pdf\",\"573\":\"fgene-12-783845.pdf\",\"574\":\"fgene-12-783845.pdf\",\"575\":\"fgene-12-783845.pdf\",\"576\":\"fgene-12-783845.pdf\",\"577\":\"fgene-12-783845.pdf\",\"578\":\"fgene-12-783845.pdf\",\"579\":\"fgene-12-783845.pdf\",\"580\":\"fgene-12-783845.pdf\",\"581\":\"fgene-12-783845.pdf\",\"582\":\"fgene-12-783845.pdf\",\"583\":\"fgene-12-783845.pdf\",\"584\":\"fgene-12-783845.pdf\",\"585\":\"fgene-12-783845.pdf\",\"586\":\"fgene-12-783845.pdf\",\"587\":\"fgene-12-783845.pdf\",\"588\":\"fgene-12-783845.pdf\",\"589\":\"fgene-12-783845.pdf\",\"590\":\"fgene-12-783845.pdf\",\"591\":\"fgene-12-783845.pdf\",\"592\":\"fgene-12-783845.pdf\",\"593\":\"fgene-12-783845.pdf\",\"594\":\"fgene-12-783845.pdf\",\"595\":\"fgene-12-783845.pdf\",\"596\":\"fgene-12-783845.pdf\",\"597\":\"fgene-12-783845.pdf\",\"598\":\"fgene-12-783845.pdf\",\"599\":\"fgene-12-783845.pdf\",\"600\":\"fgene-12-783845.pdf\",\"601\":\"fgene-12-783845.pdf\",\"602\":\"fgene-12-783845.pdf\",\"603\":\"fgene-12-783845.pdf\",\"604\":\"fgene-12-783845.pdf\",\"605\":\"fgene-12-783845.pdf\",\"606\":\"fgene-12-783845.pdf\",\"607\":\"fgene-12-783845.pdf\",\"608\":\"fgene-12-783845.pdf\",\"609\":\"fgene-12-783845.pdf\",\"610\":\"fgene-12-783845.pdf\",\"611\":\"fgene-12-783845.pdf\",\"612\":\"fgene-12-783845.pdf\",\"613\":\"fgene-12-783845.pdf\",\"614\":\"fgene-12-783845.pdf\",\"615\":\"fgene-12-783845.pdf\",\"616\":\"fgene-12-783845.pdf\",\"617\":\"fgene-12-783845.pdf\",\"618\":\"fgene-12-783845.pdf\",\"619\":\"fgene-12-783845.pdf\",\"620\":\"fgene-12-783845.pdf\",\"621\":\"fgene-12-783845.pdf\",\"622\":\"fgene-12-783845.pdf\",\"623\":\"fgene-12-783845.pdf\",\"624\":\"fgene-12-783845.pdf\",\"625\":\"fgene-12-783845.pdf\",\"626\":\"fgene-12-783845.pdf\",\"627\":\"fgene-12-783845.pdf\",\"628\":\"fgene-12-783845.pdf\",\"629\":\"fgene-12-783845.pdf\",\"630\":\"fgene-12-783845.pdf\",\"631\":\"fgene-12-783845.pdf\",\"632\":\"fgene-12-783845.pdf\",\"633\":\"fgene-12-783845.pdf\",\"634\":\"fgene-12-783845.pdf\",\"635\":\"fgene-12-783845.pdf\",\"636\":\"fgene-12-783845.pdf\",\"637\":\"fgene-12-783845.pdf\",\"638\":\"fgene-12-783845.pdf\",\"639\":\"fgene-12-783845.pdf\",\"640\":\"fgene-12-783845.pdf\",\"641\":\"fgene-12-783845.pdf\",\"642\":\"fgene-12-783845.pdf\",\"643\":\"fgene-12-783845.pdf\",\"644\":\"fgene-12-783845.pdf\",\"645\":\"fgene-12-783845.pdf\",\"646\":\"fgene-12-783845.pdf\",\"647\":\"fgene-12-783845.pdf\",\"648\":\"fgene-12-783845.pdf\",\"649\":\"fgene-12-783845.pdf\",\"650\":\"fgene-12-783845.pdf\",\"651\":\"fgene-12-783845.pdf\",\"652\":\"fgene-12-783845.pdf\",\"653\":\"fgene-12-783845.pdf\",\"654\":\"fgene-12-783845.pdf\",\"655\":\"fgene-12-783845.pdf\",\"656\":\"fgene-12-783845.pdf\",\"657\":\"fgene-12-783845.pdf\",\"658\":\"fgene-12-783845.pdf\",\"659\":\"fgene-12-783845.pdf\",\"660\":\"fgene-12-783845.pdf\",\"661\":\"fgene-12-783845.pdf\",\"662\":\"fgene-12-783845.pdf\",\"663\":\"fgene-12-783845.pdf\",\"664\":\"fgene-12-783845.pdf\",\"665\":\"fgene-12-783845.pdf\",\"666\":\"fgene-12-783845.pdf\",\"667\":\"fgene-12-783845.pdf\",\"668\":\"fgene-12-783845.pdf\",\"669\":\"fgene-12-783845.pdf\",\"670\":\"fgene-12-783845.pdf\",\"671\":\"fgene-12-783845.pdf\",\"672\":\"fgene-12-783845.pdf\",\"673\":\"fgene-12-783845.pdf\",\"674\":\"fnut-08-669155.pdf\",\"675\":\"fnut-08-669155.pdf\",\"676\":\"fnut-08-669155.pdf\",\"677\":\"fnut-08-669155.pdf\",\"678\":\"fnut-08-669155.pdf\",\"679\":\"fnut-08-669155.pdf\",\"680\":\"fnut-08-669155.pdf\",\"681\":\"fnut-08-669155.pdf\",\"682\":\"fnut-08-669155.pdf\",\"683\":\"fnut-08-669155.pdf\",\"684\":\"fnut-08-669155.pdf\",\"685\":\"fnut-08-669155.pdf\",\"686\":\"fnut-08-669155.pdf\",\"687\":\"fnut-08-669155.pdf\",\"688\":\"fnut-08-669155.pdf\",\"689\":\"fnut-08-669155.pdf\",\"690\":\"fnut-08-669155.pdf\",\"691\":\"fnut-08-669155.pdf\",\"692\":\"fnut-08-669155.pdf\",\"693\":\"fnut-08-669155.pdf\",\"694\":\"fnut-08-669155.pdf\",\"695\":\"fnut-08-669155.pdf\",\"696\":\"fnut-08-669155.pdf\",\"697\":\"fnut-08-669155.pdf\",\"698\":\"fnut-08-669155.pdf\",\"699\":\"fnut-08-669155.pdf\",\"700\":\"fnut-08-669155.pdf\",\"701\":\"fnut-08-669155.pdf\",\"702\":\"fnut-08-669155.pdf\",\"703\":\"fnut-08-669155.pdf\",\"704\":\"fnut-08-669155.pdf\",\"705\":\"fnut-08-669155.pdf\",\"706\":\"fnut-08-669155.pdf\",\"707\":\"fnut-08-669155.pdf\",\"708\":\"fnut-08-669155.pdf\",\"709\":\"fnut-08-669155.pdf\",\"710\":\"fnut-08-669155.pdf\",\"711\":\"fnut-08-669155.pdf\",\"712\":\"fnut-08-669155.pdf\",\"713\":\"fnut-08-669155.pdf\",\"714\":\"fnut-08-669155.pdf\",\"715\":\"fnut-08-669155.pdf\",\"716\":\"fnut-08-669155.pdf\",\"717\":\"fnut-08-669155.pdf\",\"718\":\"fnut-08-669155.pdf\",\"719\":\"fnut-08-669155.pdf\",\"720\":\"fnut-08-669155.pdf\",\"721\":\"fnut-08-669155.pdf\",\"722\":\"fnut-08-669155.pdf\",\"723\":\"fnut-08-669155.pdf\",\"724\":\"fnut-08-669155.pdf\",\"725\":\"fnut-08-669155.pdf\",\"726\":\"fnut-08-669155.pdf\",\"727\":\"fnut-08-669155.pdf\",\"728\":\"fnut-08-669155.pdf\",\"729\":\"fnut-08-669155.pdf\",\"730\":\"fnut-08-669155.pdf\",\"731\":\"fnut-08-669155.pdf\",\"732\":\"fnut-08-669155.pdf\",\"733\":\"fnut-08-669155.pdf\",\"734\":\"fnut-08-669155.pdf\",\"735\":\"fnut-08-669155.pdf\",\"736\":\"fnut-08-669155.pdf\",\"737\":\"fnut-08-669155.pdf\",\"738\":\"fnut-08-669155.pdf\",\"739\":\"fnut-08-669155.pdf\",\"740\":\"fnut-08-669155.pdf\",\"741\":\"fnut-08-669155.pdf\",\"742\":\"fnut-08-669155.pdf\",\"743\":\"fnut-08-669155.pdf\",\"744\":\"fnut-08-669155.pdf\",\"745\":\"fnut-08-669155.pdf\",\"746\":\"fnut-08-669155.pdf\",\"747\":\"fnut-08-669155.pdf\",\"748\":\"fnut-08-669155.pdf\",\"749\":\"fnut-08-669155.pdf\",\"750\":\"fnut-08-669155.pdf\",\"751\":\"fnut-08-669155.pdf\",\"752\":\"fnut-08-669155.pdf\",\"753\":\"fnut-08-669155.pdf\",\"754\":\"fnut-08-669155.pdf\",\"755\":\"fnut-08-669155.pdf\",\"756\":\"fnut-08-669155.pdf\",\"757\":\"fnut-08-669155.pdf\",\"758\":\"fnut-08-669155.pdf\",\"759\":\"fnut-08-669155.pdf\",\"760\":\"fnut-08-669155.pdf\",\"761\":\"fnut-08-669155.pdf\",\"762\":\"fnut-08-669155.pdf\",\"763\":\"fnut-08-669155.pdf\",\"764\":\"fnut-08-669155.pdf\",\"765\":\"fnut-08-669155.pdf\",\"766\":\"fnut-08-669155.pdf\",\"767\":\"fnut-08-669155.pdf\",\"768\":\"fnut-08-669155.pdf\",\"769\":\"fnut-08-669155.pdf\",\"770\":\"fnut-08-669155.pdf\",\"771\":\"fnut-08-669155.pdf\",\"772\":\"fnut-08-669155.pdf\",\"773\":\"fnut-08-669155.pdf\",\"774\":\"fnut-08-669155.pdf\",\"775\":\"fnut-08-669155.pdf\",\"776\":\"fnut-08-669155.pdf\",\"777\":\"fnut-08-669155.pdf\",\"778\":\"fnut-08-669155.pdf\",\"779\":\"fnut-08-669155.pdf\",\"780\":\"fnut-08-669155.pdf\",\"781\":\"fnut-08-669155.pdf\",\"782\":\"fnut-08-669155.pdf\",\"783\":\"fnut-08-669155.pdf\",\"784\":\"fnut-08-669155.pdf\",\"785\":\"fnut-08-669155.pdf\",\"786\":\"fnut-08-669155.pdf\",\"787\":\"fnut-08-669155.pdf\",\"788\":\"fnut-08-669155.pdf\",\"789\":\"fnut-08-669155.pdf\",\"790\":\"fnut-08-669155.pdf\",\"791\":\"fnut-08-669155.pdf\",\"792\":\"fnut-08-669155.pdf\",\"793\":\"fnut-08-669155.pdf\",\"794\":\"fnut-08-669155.pdf\",\"795\":\"fnut-08-669155.pdf\",\"796\":\"fnut-08-669155.pdf\",\"797\":\"fnut-08-669155.pdf\",\"798\":\"fnut-08-669155.pdf\",\"799\":\"fnut-08-669155.pdf\",\"800\":\"fnut-08-669155.pdf\",\"801\":\"fnut-08-669155.pdf\",\"802\":\"fnut-08-669155.pdf\",\"803\":\"fnut-08-669155.pdf\",\"804\":\"fnut-08-669155.pdf\",\"805\":\"fnut-08-669155.pdf\",\"806\":\"fnut-08-669155.pdf\",\"807\":\"fnut-08-669155.pdf\",\"808\":\"fnut-08-669155.pdf\",\"809\":\"fnut-08-669155.pdf\",\"810\":\"fnut-08-669155.pdf\",\"811\":\"fnut-08-669155.pdf\",\"812\":\"fnut-08-669155.pdf\",\"813\":\"fnut-08-669155.pdf\",\"814\":\"fnut-08-669155.pdf\",\"815\":\"fnut-08-669155.pdf\",\"816\":\"fnut-08-669155.pdf\",\"817\":\"fnut-08-669155.pdf\",\"818\":\"fnut-08-669155.pdf\",\"819\":\"fnut-08-669155.pdf\",\"820\":\"fnut-08-669155.pdf\",\"821\":\"fnut-08-669155.pdf\",\"822\":\"fnut-08-669155.pdf\",\"823\":\"fnut-08-669155.pdf\",\"824\":\"fnut-08-669155.pdf\",\"825\":\"fnut-08-669155.pdf\",\"826\":\"fnut-08-669155.pdf\",\"827\":\"fnut-08-669155.pdf\",\"828\":\"fnut-08-669155.pdf\",\"829\":\"fnut-08-669155.pdf\",\"830\":\"fnut-08-669155.pdf\",\"831\":\"fnut-08-669155.pdf\",\"832\":\"fnut-08-669155.pdf\",\"833\":\"fnut-08-669155.pdf\",\"834\":\"fnut-08-669155.pdf\",\"835\":\"fnut-08-669155.pdf\",\"836\":\"fnut-08-669155.pdf\",\"837\":\"fnut-08-669155.pdf\",\"838\":\"fnut-08-669155.pdf\",\"839\":\"fnut-08-669155.pdf\",\"840\":\"fnut-08-669155.pdf\",\"841\":\"fnut-08-669155.pdf\",\"842\":\"fnut-08-669155.pdf\",\"843\":\"fnut-08-669155.pdf\",\"844\":\"fnut-08-669155.pdf\",\"845\":\"fnut-08-669155.pdf\",\"846\":\"fnut-08-669155.pdf\",\"847\":\"fnut-08-669155.pdf\",\"848\":\"fnut-08-669155.pdf\",\"849\":\"fnut-08-669155.pdf\",\"850\":\"fnut-08-669155.pdf\",\"851\":\"fnut-08-669155.pdf\",\"852\":\"fnut-08-669155.pdf\",\"853\":\"fnut-08-669155.pdf\",\"854\":\"fnut-08-669155.pdf\",\"855\":\"fnut-08-669155.pdf\",\"856\":\"fnut-08-669155.pdf\",\"857\":\"fnut-08-669155.pdf\",\"858\":\"fnut-08-669155.pdf\",\"859\":\"fnut-08-669155.pdf\",\"860\":\"fnut-08-669155.pdf\",\"861\":\"fnut-08-669155.pdf\",\"862\":\"fnut-08-669155.pdf\",\"863\":\"fnut-08-669155.pdf\",\"864\":\"fnut-08-669155.pdf\",\"865\":\"fnut-08-669155.pdf\",\"866\":\"fnut-08-669155.pdf\",\"867\":\"fnut-08-669155.pdf\",\"868\":\"fnut-08-669155.pdf\",\"869\":\"fnut-08-669155.pdf\",\"870\":\"fnut-08-669155.pdf\",\"871\":\"fnut-08-669155.pdf\",\"872\":\"fnut-08-669155.pdf\",\"873\":\"fnut-08-669155.pdf\",\"874\":\"fnut-08-669155.pdf\",\"875\":\"fnut-08-669155.pdf\",\"876\":\"fnut-08-669155.pdf\",\"877\":\"fnut-08-669155.pdf\",\"878\":\"fnut-08-669155.pdf\",\"879\":\"fnut-08-669155.pdf\",\"880\":\"fnut-08-669155.pdf\",\"881\":\"fnut-08-669155.pdf\",\"882\":\"fnut-08-669155.pdf\",\"883\":\"fnut-08-669155.pdf\",\"884\":\"fnut-08-669155.pdf\",\"885\":\"fnut-08-669155.pdf\",\"886\":\"fnut-08-669155.pdf\",\"887\":\"fnut-08-669155.pdf\",\"888\":\"fnut-08-669155.pdf\",\"889\":\"fnut-08-669155.pdf\",\"890\":\"fnut-08-669155.pdf\",\"891\":\"fnut-08-669155.pdf\",\"892\":\"fnut-08-669155.pdf\",\"893\":\"fnut-08-669155.pdf\",\"894\":\"fnut-08-669155.pdf\",\"895\":\"fnut-08-669155.pdf\",\"896\":\"fnut-08-669155.pdf\",\"897\":\"fnut-08-669155.pdf\",\"898\":\"fnut-08-669155.pdf\",\"899\":\"fnut-08-669155.pdf\",\"900\":\"fnut-08-669155.pdf\",\"901\":\"fnut-08-669155.pdf\",\"902\":\"fnut-08-669155.pdf\",\"903\":\"fnut-08-669155.pdf\",\"904\":\"fnut-08-669155.pdf\",\"905\":\"fnut-08-669155.pdf\",\"906\":\"fnut-08-669155.pdf\",\"907\":\"fnut-08-669155.pdf\",\"908\":\"fnut-08-669155.pdf\",\"909\":\"fnut-08-669155.pdf\",\"910\":\"fnut-08-669155.pdf\",\"911\":\"fnut-08-669155.pdf\",\"912\":\"fnut-08-669155.pdf\",\"913\":\"fnut-08-669155.pdf\",\"914\":\"fnut-08-669155.pdf\",\"915\":\"fnut-08-669155.pdf\",\"916\":\"fnut-08-669155.pdf\",\"917\":\"fnut-08-669155.pdf\",\"918\":\"fnut-08-669155.pdf\",\"919\":\"fnut-08-669155.pdf\",\"920\":\"fnut-08-669155.pdf\",\"921\":\"fnut-08-669155.pdf\",\"922\":\"fnut-08-669155.pdf\",\"923\":\"fnut-08-669155.pdf\",\"924\":\"fnut-08-669155.pdf\",\"925\":\"fnut-08-669155.pdf\",\"926\":\"fnut-08-669155.pdf\",\"927\":\"fnut-08-669155.pdf\",\"928\":\"fnut-08-669155.pdf\",\"929\":\"fnut-08-669155.pdf\",\"930\":\"fnut-08-669155.pdf\",\"931\":\"fnut-08-669155.pdf\",\"932\":\"fnut-08-669155.pdf\",\"933\":\"fnut-08-669155.pdf\",\"934\":\"fnut-08-669155.pdf\",\"935\":\"fnut-08-669155.pdf\",\"936\":\"fnut-08-669155.pdf\",\"937\":\"fnut-08-669155.pdf\",\"938\":\"fnut-08-669155.pdf\",\"939\":\"fnut-08-669155.pdf\",\"940\":\"fnut-08-669155.pdf\",\"941\":\"fnut-08-669155.pdf\",\"942\":\"fnut-08-669155.pdf\",\"943\":\"fnut-08-669155.pdf\",\"944\":\"fnut-08-669155.pdf\",\"945\":\"fnut-08-669155.pdf\",\"946\":\"fnut-08-669155.pdf\",\"947\":\"fnut-08-669155.pdf\",\"948\":\"fnut-08-669155.pdf\",\"949\":\"fnut-08-669155.pdf\",\"950\":\"fnut-08-669155.pdf\",\"951\":\"fnut-08-669155.pdf\",\"952\":\"fnut-08-669155.pdf\",\"953\":\"fnut-08-669155.pdf\",\"954\":\"fnut-08-669155.pdf\",\"955\":\"fnut-08-669155.pdf\",\"956\":\"fnut-08-669155.pdf\",\"957\":\"fnut-08-669155.pdf\",\"958\":\"fnut-08-669155.pdf\",\"959\":\"fnut-08-669155.pdf\",\"960\":\"fnut-08-669155.pdf\",\"961\":\"fnut-08-669155.pdf\",\"962\":\"fnut-08-669155.pdf\",\"963\":\"fnut-08-669155.pdf\",\"964\":\"fnut-08-669155.pdf\",\"965\":\"fnut-08-669155.pdf\",\"966\":\"fnut-08-669155.pdf\",\"967\":\"fnut-08-669155.pdf\",\"968\":\"fnut-08-669155.pdf\",\"969\":\"fnut-08-669155.pdf\",\"970\":\"fnut-08-669155.pdf\",\"971\":\"fnut-08-669155.pdf\",\"972\":\"fnut-08-669155.pdf\",\"973\":\"fnut-08-669155.pdf\",\"974\":\"fnut-08-669155.pdf\",\"975\":\"fnut-08-669155.pdf\",\"976\":\"fnut-08-669155.pdf\",\"977\":\"fnut-08-669155.pdf\",\"978\":\"fnut-08-669155.pdf\",\"979\":\"fnut-08-669155.pdf\",\"980\":\"fnut-08-669155.pdf\",\"981\":\"fnut-08-669155.pdf\",\"982\":\"fnut-08-669155.pdf\",\"983\":\"fnut-08-669155.pdf\",\"984\":\"fnut-08-669155.pdf\",\"985\":\"fnut-08-669155.pdf\",\"986\":\"fnut-08-669155.pdf\",\"987\":\"fnut-08-669155.pdf\",\"988\":\"fnut-08-669155.pdf\",\"989\":\"fnut-08-669155.pdf\",\"990\":\"fnut-08-669155.pdf\",\"991\":\"fnut-08-669155.pdf\",\"992\":\"fnut-08-669155.pdf\",\"993\":\"fnut-08-669155.pdf\",\"994\":\"fnut-08-669155.pdf\",\"995\":\"fnut-08-669155.pdf\",\"996\":\"fnut-08-669155.pdf\",\"997\":\"fnut-08-669155.pdf\",\"998\":\"fnut-08-669155.pdf\",\"999\":\"fnut-08-669155.pdf\",\"1000\":\"fnut-08-669155.pdf\",\"1001\":\"fnut-08-669155.pdf\",\"1002\":\"fnut-08-669155.pdf\",\"1003\":\"fnut-08-669155.pdf\",\"1004\":\"fnut-08-669155.pdf\",\"1005\":\"fnut-08-669155.pdf\",\"1006\":\"fnut-08-669155.pdf\",\"1007\":\"fnut-08-669155.pdf\",\"1008\":\"fnut-08-669155.pdf\",\"1009\":\"fnut-08-669155.pdf\",\"1010\":\"fnut-08-669155.pdf\",\"1011\":\"fnut-08-669155.pdf\",\"1012\":\"fnut-08-669155.pdf\",\"1013\":\"fnut-08-669155.pdf\",\"1014\":\"fnut-08-669155.pdf\",\"1015\":\"fnut-08-669155.pdf\",\"1016\":\"fnut-08-669155.pdf\",\"1017\":\"fnut-08-669155.pdf\",\"1018\":\"fnut-08-669155.pdf\",\"1019\":\"fnut-08-669155.pdf\",\"1020\":\"fnut-08-669155.pdf\",\"1021\":\"fnut-08-669155.pdf\",\"1022\":\"fnut-08-669155.pdf\",\"1023\":\"fnut-08-669155.pdf\",\"1024\":\"fnut-08-669155.pdf\",\"1025\":\"fnut-08-669155.pdf\",\"1026\":\"fnut-08-669155.pdf\",\"1027\":\"fnut-08-669155.pdf\",\"1028\":\"fnut-08-669155.pdf\",\"1029\":\"fnut-08-669155.pdf\",\"1030\":\"fnut-08-669155.pdf\",\"1031\":\"fnut-08-669155.pdf\",\"1032\":\"fnut-08-669155.pdf\",\"1033\":\"fnut-08-669155.pdf\",\"1034\":\"fnut-08-669155.pdf\",\"1035\":\"fnut-08-669155.pdf\",\"1036\":\"fnut-08-669155.pdf\",\"1037\":\"fnut-08-669155.pdf\",\"1038\":\"fnut-08-669155.pdf\",\"1039\":\"fnut-08-669155.pdf\",\"1040\":\"fnut-08-669155.pdf\",\"1041\":\"fnut-08-669155.pdf\",\"1042\":\"fnut-08-669155.pdf\",\"1043\":\"fnut-08-669155.pdf\",\"1044\":\"fnut-08-669155.pdf\",\"1045\":\"fnut-08-669155.pdf\",\"1046\":\"fnut-08-669155.pdf\",\"1047\":\"fnut-08-669155.pdf\",\"1048\":\"fnut-08-669155.pdf\",\"1049\":\"fnut-08-669155.pdf\",\"1050\":\"fnut-08-669155.pdf\",\"1051\":\"fnut-08-669155.pdf\",\"1052\":\"fnut-08-669155.pdf\",\"1053\":\"fnut-08-669155.pdf\",\"1054\":\"fnut-08-669155.pdf\",\"1055\":\"fnut-08-669155.pdf\",\"1056\":\"fnut-08-669155.pdf\",\"1057\":\"fnut-08-669155.pdf\",\"1058\":\"fnut-08-669155.pdf\",\"1059\":\"fnut-08-669155.pdf\",\"1060\":\"fnut-08-669155.pdf\",\"1061\":\"fnut-08-669155.pdf\",\"1062\":\"fnut-08-669155.pdf\",\"1063\":\"fnut-08-669155.pdf\",\"1064\":\"fnut-08-669155.pdf\",\"1065\":\"fnut-08-669155.pdf\",\"1066\":\"fnut-08-669155.pdf\",\"1067\":\"fnut-08-669155.pdf\",\"1068\":\"fnut-08-669155.pdf\",\"1069\":\"fnut-08-669155.pdf\",\"1070\":\"fnut-08-669155.pdf\",\"1071\":\"fnut-08-669155.pdf\",\"1072\":\"fnut-08-669155.pdf\",\"1073\":\"fnut-08-669155.pdf\",\"1074\":\"fnut-08-669155.pdf\",\"1075\":\"fnut-08-669155.pdf\",\"1076\":\"fnut-08-669155.pdf\",\"1077\":\"fnut-08-669155.pdf\",\"1078\":\"fnut-08-669155.pdf\",\"1079\":\"fnut-08-669155.pdf\",\"1080\":\"fnut-08-669155.pdf\",\"1081\":\"fnut-08-669155.pdf\",\"1082\":\"fnut-08-669155.pdf\",\"1083\":\"fnut-08-669155.pdf\",\"1084\":\"fnut-08-669155.pdf\",\"1085\":\"fnut-08-669155.pdf\",\"1086\":\"fnut-08-669155.pdf\",\"1087\":\"fnut-08-669155.pdf\",\"1088\":\"fnut-08-669155.pdf\",\"1089\":\"fnut-08-669155.pdf\",\"1090\":\"fnut-08-669155.pdf\",\"1091\":\"fnut-08-669155.pdf\",\"1092\":\"fnut-08-669155.pdf\",\"1093\":\"fnut-08-669155.pdf\",\"1094\":\"fnut-08-669155.pdf\",\"1095\":\"fnut-08-669155.pdf\",\"1096\":\"fnut-08-669155.pdf\",\"1097\":\"fnut-08-669155.pdf\",\"1098\":\"fnut-08-669155.pdf\",\"1099\":\"fnut-08-669155.pdf\",\"1100\":\"fnut-08-669155.pdf\",\"1101\":\"fnut-08-669155.pdf\",\"1102\":\"fnut-08-669155.pdf\",\"1103\":\"fnut-08-669155.pdf\",\"1104\":\"fnut-08-669155.pdf\",\"1105\":\"fnut-08-669155.pdf\",\"1106\":\"fnut-08-669155.pdf\",\"1107\":\"fnut-08-669155.pdf\",\"1108\":\"fnut-08-669155.pdf\",\"1109\":\"fnut-08-669155.pdf\",\"1110\":\"fnut-08-669155.pdf\",\"1111\":\"fnut-08-669155.pdf\",\"1112\":\"fnut-08-669155.pdf\",\"1113\":\"fnut-08-669155.pdf\",\"1114\":\"fnut-08-669155.pdf\",\"1115\":\"fnut-08-669155.pdf\",\"1116\":\"fnut-08-669155.pdf\",\"1117\":\"fnut-08-669155.pdf\",\"1118\":\"fnut-08-669155.pdf\",\"1119\":\"fnut-08-669155.pdf\",\"1120\":\"fnut-08-669155.pdf\",\"1121\":\"fnut-08-669155.pdf\",\"1122\":\"fnut-08-669155.pdf\",\"1123\":\"fnut-08-669155.pdf\",\"1124\":\"fnut-08-669155.pdf\",\"1125\":\"fnut-08-669155.pdf\",\"1126\":\"fnut-08-669155.pdf\",\"1127\":\"fnut-08-669155.pdf\",\"1128\":\"fnut-08-669155.pdf\",\"1129\":\"fnut-08-669155.pdf\",\"1130\":\"fnut-08-669155.pdf\",\"1131\":\"fnut-08-669155.pdf\",\"1132\":\"fnut-08-669155.pdf\",\"1133\":\"fnut-08-669155.pdf\",\"1134\":\"fnut-08-669155.pdf\",\"1135\":\"fnut-08-669155.pdf\",\"1136\":\"fnut-08-669155.pdf\",\"1137\":\"Obesity based on Decision Tree.pdf\",\"1138\":\"Obesity based on Decision Tree.pdf\",\"1139\":\"Obesity based on Decision Tree.pdf\",\"1140\":\"Obesity based on Decision Tree.pdf\",\"1141\":\"Obesity based on Decision Tree.pdf\",\"1142\":\"Obesity based on Decision Tree.pdf\",\"1143\":\"Obesity based on Decision Tree.pdf\",\"1144\":\"Obesity based on Decision Tree.pdf\",\"1145\":\"Obesity based on Decision Tree.pdf\",\"1146\":\"Obesity based on Decision Tree.pdf\",\"1147\":\"Obesity based on Decision Tree.pdf\",\"1148\":\"Obesity based on Decision Tree.pdf\",\"1149\":\"Obesity based on Decision Tree.pdf\",\"1150\":\"Obesity based on Decision Tree.pdf\",\"1151\":\"Obesity based on Decision Tree.pdf\",\"1152\":\"Obesity based on Decision Tree.pdf\",\"1153\":\"Obesity based on Decision Tree.pdf\",\"1154\":\"Obesity based on Decision Tree.pdf\",\"1155\":\"Obesity based on Decision Tree.pdf\",\"1156\":\"Obesity based on Decision Tree.pdf\",\"1157\":\"Obesity based on Decision Tree.pdf\",\"1158\":\"Obesity based on Decision Tree.pdf\",\"1159\":\"Obesity based on Decision Tree.pdf\",\"1160\":\"Obesity based on Decision Tree.pdf\",\"1161\":\"Obesity based on Decision Tree.pdf\",\"1162\":\"Obesity based on Decision Tree.pdf\",\"1163\":\"Obesity based on Decision Tree.pdf\",\"1164\":\"Obesity based on Decision Tree.pdf\",\"1165\":\"Obesity based on Decision Tree.pdf\",\"1166\":\"Obesity based on Decision Tree.pdf\",\"1167\":\"Obesity based on Decision Tree.pdf\",\"1168\":\"Obesity based on Decision Tree.pdf\",\"1169\":\"Obesity based on Decision Tree.pdf\",\"1170\":\"Obesity based on Decision Tree.pdf\",\"1171\":\"Obesity based on Decision Tree.pdf\",\"1172\":\"Obesity based on Decision Tree.pdf\",\"1173\":\"Obesity based on Decision Tree.pdf\",\"1174\":\"Obesity based on Decision Tree.pdf\",\"1175\":\"Obesity based on Decision Tree.pdf\",\"1176\":\"Obesity based on Decision Tree.pdf\",\"1177\":\"Obesity based on Decision Tree.pdf\",\"1178\":\"Obesity based on Decision Tree.pdf\",\"1179\":\"Obesity based on Decision Tree.pdf\",\"1180\":\"Obesity based on Decision Tree.pdf\",\"1181\":\"Obesity based on Decision Tree.pdf\",\"1182\":\"Obesity based on Decision Tree.pdf\",\"1183\":\"Obesity based on Decision Tree.pdf\",\"1184\":\"Obesity based on Decision Tree.pdf\",\"1185\":\"Obesity based on Decision Tree.pdf\",\"1186\":\"Obesity based on Decision Tree.pdf\",\"1187\":\"Obesity based on Decision Tree.pdf\",\"1188\":\"Obesity based on Decision Tree.pdf\",\"1189\":\"Obesity based on Decision Tree.pdf\",\"1190\":\"Obesity based on Decision Tree.pdf\",\"1191\":\"Obesity based on Decision Tree.pdf\",\"1192\":\"Obesity based on Decision Tree.pdf\",\"1193\":\"Obesity based on Decision Tree.pdf\",\"1194\":\"Obesity based on Decision Tree.pdf\",\"1195\":\"Obesity based on Decision Tree.pdf\",\"1196\":\"Obesity based on Decision Tree.pdf\",\"1197\":\"Obesity based on Decision Tree.pdf\",\"1198\":\"Obesity based on Decision Tree.pdf\",\"1199\":\"Obesity based on Decision Tree.pdf\",\"1200\":\"Obesity based on Decision Tree.pdf\",\"1201\":\"Obesity based on Decision Tree.pdf\",\"1202\":\"Obesity based on Decision Tree.pdf\",\"1203\":\"Obesity based on Decision Tree.pdf\",\"1204\":\"Obesity based on Decision Tree.pdf\",\"1205\":\"Obesity based on Decision Tree.pdf\",\"1206\":\"Obesity based on Decision Tree.pdf\",\"1207\":\"Obesity based on Decision Tree.pdf\",\"1208\":\"Obesity based on Decision Tree.pdf\",\"1209\":\"Obesity based on Decision Tree.pdf\",\"1210\":\"Obesity based on Decision Tree.pdf\",\"1211\":\"Obesity based on Decision Tree.pdf\",\"1212\":\"Obesity based on Decision Tree.pdf\",\"1213\":\"Obesity based on Decision Tree.pdf\",\"1214\":\"Obesity based on Decision Tree.pdf\",\"1215\":\"Obesity based on Decision Tree.pdf\",\"1216\":\"Obesity based on Decision Tree.pdf\",\"1217\":\"Obesity based on Decision Tree.pdf\",\"1218\":\"Obesity based on Decision Tree.pdf\",\"1219\":\"Obesity based on Decision Tree.pdf\",\"1220\":\"Obesity based on Decision Tree.pdf\",\"1221\":\"Obesity based on Decision Tree.pdf\",\"1222\":\"Obesity based on Decision Tree.pdf\",\"1223\":\"Obesity based on Decision Tree.pdf\",\"1224\":\"Obesity based on Decision Tree.pdf\",\"1225\":\"Obesity based on Decision Tree.pdf\",\"1226\":\"Obesity based on Decision Tree.pdf\",\"1227\":\"Obesity based on Decision Tree.pdf\",\"1228\":\"Obesity based on Decision Tree.pdf\",\"1229\":\"Obesity based on Decision Tree.pdf\",\"1230\":\"Obesity based on Decision Tree.pdf\",\"1231\":\"Obesity based on Decision Tree.pdf\",\"1232\":\"Obesity based on Decision Tree.pdf\",\"1233\":\"Obesity based on Decision Tree.pdf\",\"1234\":\"Obesity based on Decision Tree.pdf\",\"1235\":\"Obesity based on Decision Tree.pdf\",\"1236\":\"Obesity based on Decision Tree.pdf\",\"1237\":\"Obesity based on Decision Tree.pdf\",\"1238\":\"Obesity based on Decision Tree.pdf\",\"1239\":\"Obesity based on Decision Tree.pdf\",\"1240\":\"Obesity based on Decision Tree.pdf\",\"1241\":\"Obesity based on Decision Tree.pdf\",\"1242\":\"Obesity based on Decision Tree.pdf\",\"1243\":\"Obesity based on Decision Tree.pdf\",\"1244\":\"Obesity based on Decision Tree.pdf\",\"1245\":\"Obesity based on Decision Tree.pdf\",\"1246\":\"Obesity based on Decision Tree.pdf\",\"1247\":\"Obesity based on Decision Tree.pdf\",\"1248\":\"Obesity based on Decision Tree.pdf\",\"1249\":\"Obesity based on Decision Tree.pdf\",\"1250\":\"Obesity based on Decision Tree.pdf\",\"1251\":\"Obesity based on Decision Tree.pdf\",\"1252\":\"Obesity based on Decision Tree.pdf\",\"1253\":\"Obesity based on Decision Tree.pdf\",\"1254\":\"Obesity based on Decision Tree.pdf\",\"1255\":\"Obesity based on Decision Tree.pdf\",\"1256\":\"Obesity based on Decision Tree.pdf\",\"1257\":\"Obesity based on Decision Tree.pdf\",\"1258\":\"Obesity based on Decision Tree.pdf\",\"1259\":\"Obesity based on Decision Tree.pdf\",\"1260\":\"Obesity based on Decision Tree.pdf\",\"1261\":\"Obesity based on Decision Tree.pdf\",\"1262\":\"Obesity based on Decision Tree.pdf\",\"1263\":\"Obesity based on Decision Tree.pdf\",\"1264\":\"Obesity based on Decision Tree.pdf\",\"1265\":\"Obesity based on Decision Tree.pdf\",\"1266\":\"Obesity based on Decision Tree.pdf\",\"1267\":\"Obesity based on Decision Tree.pdf\",\"1268\":\"Obesity based on Decision Tree.pdf\",\"1269\":\"Obesity based on Decision Tree.pdf\",\"1270\":\"Obesity based on Decision Tree.pdf\",\"1271\":\"Obesity based on Decision Tree.pdf\",\"1272\":\"Obesity based on Decision Tree.pdf\",\"1273\":\"Obesity based on Decision Tree.pdf\",\"1274\":\"Obesity based on Decision Tree.pdf\",\"1275\":\"Obesity based on Decision Tree.pdf\",\"1276\":\"Obesity based on Decision Tree.pdf\",\"1277\":\"Obesity based on Decision Tree.pdf\",\"1278\":\"Obesity based on Decision Tree.pdf\",\"1279\":\"Obesity based on Decision Tree.pdf\",\"1280\":\"Obesity based on Decision Tree.pdf\",\"1281\":\"Obesity based on Decision Tree.pdf\",\"1282\":\"Obesity based on Decision Tree.pdf\",\"1283\":\"Obesity based on Decision Tree.pdf\",\"1284\":\"Obesity based on Decision Tree.pdf\",\"1285\":\"Obesity based on Decision Tree.pdf\",\"1286\":\"Obesity based on Decision Tree.pdf\",\"1287\":\"Obesity based on Decision Tree.pdf\",\"1288\":\"Obesity based on Decision Tree.pdf\",\"1289\":\"Obesity based on Decision Tree.pdf\",\"1290\":\"Obesity based on Decision Tree.pdf\",\"1291\":\"Obesity based on Decision Tree.pdf\",\"1292\":\"Obesity based on Decision Tree.pdf\",\"1293\":\"Obesity based on Decision Tree.pdf\",\"1294\":\"Obesity based on Decision Tree.pdf\",\"1295\":\"Obesity based on Decision Tree.pdf\",\"1296\":\"Obesity based on Decision Tree.pdf\",\"1297\":\"Obesity based on Decision Tree.pdf\",\"1298\":\"Obesity based on Decision Tree.pdf\",\"1299\":\"Obesity based on Decision Tree.pdf\",\"1300\":\"Obesity based on Decision Tree.pdf\",\"1301\":\"Obesity based on Decision Tree.pdf\",\"1302\":\"Obesity based on Decision Tree.pdf\",\"1303\":\"Obesity based on Decision Tree.pdf\",\"1304\":\"Obesity based on Decision Tree.pdf\",\"1305\":\"Obesity based on Decision Tree.pdf\",\"1306\":\"Obesity based on Decision Tree.pdf\",\"1307\":\"Obesity based on Decision Tree.pdf\",\"1308\":\"Obesity based on Decision Tree.pdf\",\"1309\":\"Obesity based on Decision Tree.pdf\",\"1310\":\"Obesity based on Decision Tree.pdf\",\"1311\":\"Obesity based on Decision Tree.pdf\",\"1312\":\"Obesity based on Decision Tree.pdf\",\"1313\":\"Obesity based on Decision Tree.pdf\",\"1314\":\"Obesity based on Decision Tree.pdf\",\"1315\":\"Obesity based on Decision Tree.pdf\",\"1316\":\"Obesity based on Decision Tree.pdf\",\"1317\":\"Obesity based on Decision Tree.pdf\",\"1318\":\"Obesity based on Decision Tree.pdf\",\"1319\":\"Obesity based on Decision Tree.pdf\",\"1320\":\"Obesity based on Decision Tree.pdf\",\"1321\":\"Obesity based on Decision Tree.pdf\",\"1322\":\"Obesity based on Decision Tree.pdf\",\"1323\":\"Obesity based on Decision Tree.pdf\",\"1324\":\"Obesity based on Decision Tree.pdf\",\"1325\":\"Obesity based on Decision Tree.pdf\",\"1326\":\"Obesity based on Decision Tree.pdf\",\"1327\":\"Obesity based on Decision Tree.pdf\",\"1328\":\"Obesity based on Decision Tree.pdf\",\"1329\":\"Obesity based on Decision Tree.pdf\",\"1330\":\"Obesity based on Decision Tree.pdf\",\"1331\":\"Obesity based on Decision Tree.pdf\",\"1332\":\"Obesity based on Decision Tree.pdf\",\"1333\":\"Obesity based on Decision Tree.pdf\",\"1334\":\"Obesity based on Decision Tree.pdf\",\"1335\":\"Obesity based on Decision Tree.pdf\",\"1336\":\"Obesity based on Decision Tree.pdf\",\"1337\":\"Obesity based on Decision Tree.pdf\",\"1338\":\"Obesity based on Decision Tree.pdf\",\"1339\":\"Obesity based on Decision Tree.pdf\",\"1340\":\"Obesity based on Decision Tree.pdf\",\"1341\":\"Obesity based on Decision Tree.pdf\",\"1342\":\"Obesity based on Decision Tree.pdf\",\"1343\":\"Obesity based on Decision Tree.pdf\",\"1344\":\"Obesity based on Decision Tree.pdf\",\"1345\":\"Obesity based on Decision Tree.pdf\",\"1346\":\"Obesity based on Decision Tree.pdf\",\"1347\":\"Obesity based on Decision Tree.pdf\",\"1348\":\"Obesity based on Decision Tree.pdf\",\"1349\":\"Obesity based on Decision Tree.pdf\",\"1350\":\"Obesity based on Decision Tree.pdf\",\"1351\":\"Obesity based on Decision Tree.pdf\",\"1352\":\"Obesity based on Decision Tree.pdf\",\"1353\":\"Obesity based on Decision Tree.pdf\",\"1354\":\"Obesity based on Decision Tree.pdf\",\"1355\":\"Obesity based on Decision Tree.pdf\",\"1356\":\"Obesity based on Decision Tree.pdf\",\"1357\":\"Obesity based on Decision Tree.pdf\",\"1358\":\"Obesity based on Decision Tree.pdf\",\"1359\":\"Obesity based on Decision Tree.pdf\",\"1360\":\"Obesity based on Decision Tree.pdf\",\"1361\":\"Obesity based on Decision Tree.pdf\",\"1362\":\"Obesity based on Decision Tree.pdf\",\"1363\":\"Obesity based on Decision Tree.pdf\",\"1364\":\"Obesity based on Decision Tree.pdf\",\"1365\":\"Obesity based on Decision Tree.pdf\",\"1366\":\"Obesity based on Decision Tree.pdf\",\"1367\":\"Obesity based on Decision Tree.pdf\",\"1368\":\"Obesity based on Decision Tree.pdf\",\"1369\":\"Obesity based on Decision Tree.pdf\",\"1370\":\"Obesity based on Decision Tree.pdf\",\"1371\":\"Obesity based on Decision Tree.pdf\",\"1372\":\"Obesity based on Decision Tree.pdf\",\"1373\":\"Obesity based on Decision Tree.pdf\",\"1374\":\"Obesity based on Decision Tree.pdf\",\"1375\":\"Obesity based on Decision Tree.pdf\",\"1376\":\"Obesity based on Decision Tree.pdf\",\"1377\":\"Obesity based on Decision Tree.pdf\",\"1378\":\"Obesity based on Decision Tree.pdf\",\"1379\":\"Obesity based on Decision Tree.pdf\",\"1380\":\"Obesity based on Decision Tree.pdf\",\"1381\":\"Obesity based on Decision Tree.pdf\",\"1382\":\"Obesity based on Decision Tree.pdf\",\"1383\":\"Obesity based on Decision Tree.pdf\",\"1384\":\"Obesity based on Decision Tree.pdf\",\"1385\":\"Obesity based on Decision Tree.pdf\",\"1386\":\"Obesity based on Decision Tree.pdf\",\"1387\":\"Obesity based on Decision Tree.pdf\",\"1388\":\"Obesity based on Decision Tree.pdf\",\"1389\":\"Obesity based on Data mining.pdf\",\"1390\":\"Obesity based on Data mining.pdf\",\"1391\":\"Obesity based on Data mining.pdf\",\"1392\":\"Obesity based on Data mining.pdf\",\"1393\":\"Obesity based on Data mining.pdf\",\"1394\":\"Obesity based on Data mining.pdf\",\"1395\":\"Obesity based on Data mining.pdf\",\"1396\":\"Obesity based on Data mining.pdf\",\"1397\":\"Obesity based on Data mining.pdf\",\"1398\":\"Obesity based on Data mining.pdf\",\"1399\":\"Obesity based on Data mining.pdf\",\"1400\":\"Obesity based on Data mining.pdf\",\"1401\":\"Obesity based on Data mining.pdf\",\"1402\":\"Obesity based on Data mining.pdf\",\"1403\":\"Obesity based on Data mining.pdf\",\"1404\":\"Obesity based on Data mining.pdf\",\"1405\":\"Obesity based on Data mining.pdf\",\"1406\":\"Obesity based on Data mining.pdf\",\"1407\":\"Obesity based on Data mining.pdf\",\"1408\":\"Obesity based on Data mining.pdf\",\"1409\":\"Obesity based on Data mining.pdf\",\"1410\":\"Obesity based on Data mining.pdf\",\"1411\":\"Obesity based on Data mining.pdf\",\"1412\":\"Obesity based on Data mining.pdf\",\"1413\":\"Obesity based on Data mining.pdf\",\"1414\":\"Obesity based on Data mining.pdf\",\"1415\":\"Obesity based on Data mining.pdf\",\"1416\":\"Obesity based on Data mining.pdf\",\"1417\":\"Obesity based on Data mining.pdf\",\"1418\":\"Obesity based on Data mining.pdf\",\"1419\":\"Obesity based on Data mining.pdf\",\"1420\":\"Obesity based on Data mining.pdf\",\"1421\":\"Obesity based on Data mining.pdf\",\"1422\":\"Obesity based on Data mining.pdf\",\"1423\":\"Obesity based on Data mining.pdf\",\"1424\":\"Obesity based on Data mining.pdf\",\"1425\":\"Obesity based on Data mining.pdf\",\"1426\":\"Obesity based on Data mining.pdf\",\"1427\":\"Obesity based on Data mining.pdf\",\"1428\":\"Obesity based on Data mining.pdf\",\"1429\":\"Obesity based on Data mining.pdf\",\"1430\":\"Obesity based on Data mining.pdf\",\"1431\":\"Obesity based on Data mining.pdf\",\"1432\":\"Obesity based on Data mining.pdf\",\"1433\":\"Obesity based on Data mining.pdf\",\"1434\":\"Obesity based on Data mining.pdf\",\"1435\":\"Obesity based on Data mining.pdf\",\"1436\":\"Obesity based on Data mining.pdf\",\"1437\":\"Obesity based on Data mining.pdf\",\"1438\":\"Obesity based on Data mining.pdf\",\"1439\":\"Obesity based on Data mining.pdf\",\"1440\":\"Obesity based on Data mining.pdf\",\"1441\":\"Obesity based on Data mining.pdf\",\"1442\":\"Obesity based on Data mining.pdf\",\"1443\":\"Obesity based on Data mining.pdf\",\"1444\":\"Obesity based on Data mining.pdf\",\"1445\":\"Obesity based on Data mining.pdf\",\"1446\":\"Obesity based on Data mining.pdf\",\"1447\":\"Obesity based on Data mining.pdf\",\"1448\":\"Obesity based on Data mining.pdf\",\"1449\":\"Obesity based on Data mining.pdf\",\"1450\":\"Obesity based on Data mining.pdf\",\"1451\":\"Obesity based on Data mining.pdf\",\"1452\":\"Obesity based on Data mining.pdf\",\"1453\":\"Obesity based on Data mining.pdf\",\"1454\":\"Obesity based on Data mining.pdf\",\"1455\":\"Obesity based on Data mining.pdf\",\"1456\":\"Obesity based on Data mining.pdf\",\"1457\":\"Obesity based on Data mining.pdf\",\"1458\":\"Obesity based on Data mining.pdf\",\"1459\":\"Obesity based on Data mining.pdf\",\"1460\":\"Obesity based on Data mining.pdf\",\"1461\":\"Obesity based on Data mining.pdf\",\"1462\":\"Obesity based on Data mining.pdf\",\"1463\":\"Obesity based on Data mining.pdf\",\"1464\":\"Obesity based on Data mining.pdf\",\"1465\":\"Obesity based on Data mining.pdf\",\"1466\":\"Obesity based on Data mining.pdf\",\"1467\":\"Obesity based on Data mining.pdf\",\"1468\":\"Obesity based on Data mining.pdf\",\"1469\":\"Obesity based on Data mining.pdf\",\"1470\":\"Obesity based on Data mining.pdf\",\"1471\":\"Obesity based on Data mining.pdf\",\"1472\":\"Obesity based on Data mining.pdf\",\"1473\":\"Obesity based on Data mining.pdf\",\"1474\":\"Obesity based on Data mining.pdf\",\"1475\":\"Obesity based on Data mining.pdf\",\"1476\":\"Obesity based on Data mining.pdf\",\"1477\":\"Obesity based on Data mining.pdf\",\"1478\":\"Obesity based on Data mining.pdf\",\"1479\":\"Obesity based on Data mining.pdf\",\"1480\":\"Obesity based on Data mining.pdf\",\"1481\":\"Obesity based on Data mining.pdf\",\"1482\":\"Obesity based on Data mining.pdf\",\"1483\":\"Obesity based on Data mining.pdf\",\"1484\":\"Obesity based on Data mining.pdf\",\"1485\":\"Obesity based on Data mining.pdf\",\"1486\":\"Obesity based on Data mining.pdf\",\"1487\":\"Obesity based on Data mining.pdf\",\"1488\":\"Obesity based on Data mining.pdf\",\"1489\":\"Obesity based on Data mining.pdf\",\"1490\":\"Obesity based on Data mining.pdf\",\"1491\":\"Obesity based on Data mining.pdf\",\"1492\":\"Obesity based on Data mining.pdf\",\"1493\":\"Obesity based on Data mining.pdf\",\"1494\":\"Obesity based on Data mining.pdf\",\"1495\":\"Obesity based on Data mining.pdf\",\"1496\":\"Obesity based on Data mining.pdf\",\"1497\":\"Obesity based on Data mining.pdf\",\"1498\":\"Obesity based on Data mining.pdf\",\"1499\":\"Obesity based on Data mining.pdf\",\"1500\":\"Obesity based on Data mining.pdf\",\"1501\":\"Obesity based on Data mining.pdf\",\"1502\":\"Obesity based on Data mining.pdf\",\"1503\":\"Obesity based on Data mining.pdf\",\"1504\":\"Obesity based on Data mining.pdf\",\"1505\":\"Obesity based on Data mining.pdf\",\"1506\":\"Obesity based on Data mining.pdf\",\"1507\":\"Obesity based on Data mining.pdf\",\"1508\":\"Obesity based on Data mining.pdf\",\"1509\":\"Obesity based on Data mining.pdf\",\"1510\":\"Obesity based on Data mining.pdf\",\"1511\":\"Obesity based on Data mining.pdf\",\"1512\":\"Obesity based on Data mining.pdf\",\"1513\":\"Obesity based on Data mining.pdf\",\"1514\":\"Obesity based on Data mining.pdf\",\"1515\":\"Obesity based on Data mining.pdf\",\"1516\":\"Obesity based on Data mining.pdf\",\"1517\":\"Obesity based on Data mining.pdf\",\"1518\":\"Obesity based on Data mining.pdf\",\"1519\":\"Obesity based on Data mining.pdf\",\"1520\":\"Obesity based on Data mining.pdf\",\"1521\":\"Obesity based on Data mining.pdf\",\"1522\":\"Obesity based on Data mining.pdf\",\"1523\":\"Obesity based on Data mining.pdf\",\"1524\":\"Obesity based on Data mining.pdf\",\"1525\":\"Obesity based on Data mining.pdf\",\"1526\":\"Obesity based on Data mining.pdf\",\"1527\":\"Obesity based on Data mining.pdf\",\"1528\":\"Obesity based on Data mining.pdf\",\"1529\":\"Obesity based on Data mining.pdf\",\"1530\":\"Obesity based on Data mining.pdf\",\"1531\":\"Obesity based on Data mining.pdf\",\"1532\":\"Obesity based on Data mining.pdf\",\"1533\":\"Obesity based on Data mining.pdf\",\"1534\":\"Obesity based on Data mining.pdf\",\"1535\":\"Obesity based on Data mining.pdf\",\"1536\":\"Obesity based on Data mining.pdf\",\"1537\":\"Obesity based on Data mining.pdf\",\"1538\":\"Obesity based on Data mining.pdf\",\"1539\":\"Obesity based on Data mining.pdf\",\"1540\":\"Obesity based on Data mining.pdf\",\"1541\":\"Obesity based on Data mining.pdf\",\"1542\":\"Obesity based on Data mining.pdf\",\"1543\":\"Obesity based on Data mining.pdf\",\"1544\":\"Obesity based on Data mining.pdf\",\"1545\":\"Obesity based on Data mining.pdf\",\"1546\":\"Obesity based on Data mining.pdf\",\"1547\":\"Obesity based on Data mining.pdf\",\"1548\":\"Obesity based on Data mining.pdf\",\"1549\":\"Obesity based on Data mining.pdf\",\"1550\":\"Obesity based on Data mining.pdf\",\"1551\":\"Obesity based on Data mining.pdf\",\"1552\":\"Obesity based on Data mining.pdf\",\"1553\":\"Obesity based on Data mining.pdf\",\"1554\":\"Obesity based on Data mining.pdf\",\"1555\":\"Obesity based on Data mining.pdf\",\"1556\":\"Obesity based on Data mining.pdf\",\"1557\":\"Obesity based on Data mining.pdf\",\"1558\":\"Obesity based on Data mining.pdf\",\"1559\":\"Obesity based on Data mining.pdf\",\"1560\":\"Obesity based on Data mining.pdf\",\"1561\":\"Obesity based on Data mining.pdf\",\"1562\":\"Obesity based on Data mining.pdf\",\"1563\":\"Obesity based on Data mining.pdf\",\"1564\":\"Obesity based on Data mining.pdf\",\"1565\":\"Obesity based on Data mining.pdf\",\"1566\":\"Obesity based on Data mining.pdf\",\"1567\":\"Obesity based on Data mining.pdf\",\"1568\":\"Obesity based on Data mining.pdf\",\"1569\":\"Obesity based on Data mining.pdf\",\"1570\":\"Obesity based on Data mining.pdf\",\"1571\":\"Obesity based on Data mining.pdf\",\"1572\":\"Obesity based on Data mining.pdf\",\"1573\":\"Obesity based on Data mining.pdf\",\"1574\":\"Obesity based on Data mining.pdf\",\"1575\":\"Obesity based on Data mining.pdf\",\"1576\":\"Obesity based on Data mining.pdf\",\"1577\":\"Obesity based on Data mining.pdf\",\"1578\":\"Obesity based on Data mining.pdf\",\"1579\":\"Obesity based on Data mining.pdf\",\"1580\":\"Obesity based on Data mining.pdf\",\"1581\":\"Obesity based on Data mining.pdf\",\"1582\":\"Obesity based on Data mining.pdf\",\"1583\":\"Obesity based on Data mining.pdf\",\"1584\":\"Obesity based on Data mining.pdf\",\"1585\":\"Obesity based on Data mining.pdf\",\"1586\":\"Obesity based on Data mining.pdf\",\"1587\":\"Obesity based on Data mining.pdf\",\"1588\":\"Obesity based on Data mining.pdf\",\"1589\":\"Obesity based on Data mining.pdf\",\"1590\":\"Obesity based on Data mining.pdf\",\"1591\":\"Obesity based on Data mining.pdf\",\"1592\":\"Obesity based on Data mining.pdf\",\"1593\":\"Obesity based on Data mining.pdf\",\"1594\":\"Obesity based on Data mining.pdf\",\"1595\":\"Obesity based on Data mining.pdf\",\"1596\":\"Obesity based on Data mining.pdf\",\"1597\":\"Obesity based on Data mining.pdf\",\"1598\":\"Obesity based on Data mining.pdf\",\"1599\":\"Obesity based on Data mining.pdf\",\"1600\":\"Obesity based on Data mining.pdf\",\"1601\":\"Obesity based on Data mining.pdf\",\"1602\":\"Obesity based on Data mining.pdf\",\"1603\":\"Obesity based on Data mining.pdf\",\"1604\":\"Obesity based on Data mining.pdf\",\"1605\":\"Obesity based on Data mining.pdf\",\"1606\":\"Obesity based on Data mining.pdf\",\"1607\":\"Obesity based on Data mining.pdf\",\"1608\":\"Obesity based on Data mining.pdf\",\"1609\":\"Obesity based on Data mining.pdf\",\"1610\":\"Obesity based on Data mining.pdf\",\"1611\":\"Obesity based on Data mining.pdf\",\"1612\":\"Obesity based on Data mining.pdf\",\"1613\":\"Obesity based on Data mining.pdf\",\"1614\":\"Obesity based on Data mining.pdf\",\"1615\":\"Obesity based on Data mining.pdf\",\"1616\":\"Obesity based on Data mining.pdf\",\"1617\":\"Obesity based on Data mining.pdf\",\"1618\":\"Obesity based on Data mining.pdf\",\"1619\":\"Obesity based on Data mining.pdf\",\"1620\":\"Obesity based on Data mining.pdf\",\"1621\":\"Obesity based on Data mining.pdf\",\"1622\":\"Obesity based on Data mining.pdf\",\"1623\":\"Obesity based on Data mining.pdf\",\"1624\":\"Obesity based on Data mining.pdf\",\"1625\":\"Obesity based on Data mining.pdf\",\"1626\":\"Obesity based on Data mining.pdf\",\"1627\":\"Obesity based on Data mining.pdf\",\"1628\":\"Obesity based on Data mining.pdf\",\"1629\":\"Obesity based on Data mining.pdf\",\"1630\":\"Obesity based on Data mining.pdf\",\"1631\":\"Obesity based on Data mining.pdf\",\"1632\":\"Obesity based on Data mining.pdf\",\"1633\":\"Obesity based on Data mining.pdf\",\"1634\":\"Obesity based on Data mining.pdf\",\"1635\":\"Obesity based on Data mining.pdf\",\"1636\":\"Obesity based on Data mining.pdf\",\"1637\":\"Obesity based on Data mining.pdf\",\"1638\":\"Obesity based on Data mining.pdf\",\"1639\":\"Obesity based on Data mining.pdf\",\"1640\":\"Obesity based on Data mining.pdf\",\"1641\":\"Obesity based on Data mining.pdf\",\"1642\":\"Obesity based on Data mining.pdf\",\"1643\":\"Obesity based on Data mining.pdf\",\"1644\":\"Obesity based on Data mining.pdf\",\"1645\":\"Obesity based on Data mining.pdf\",\"1646\":\"Obesity based on Data mining.pdf\",\"1647\":\"Obesity based on Data mining.pdf\",\"1648\":\"Obesity based on Data mining.pdf\",\"1649\":\"Obesity based on Data mining.pdf\",\"1650\":\"Obesity based on Data mining.pdf\",\"1651\":\"Obesity based on Data mining.pdf\"},\"sentence\":{\"0\":0,\"1\":1,\"2\":2,\"3\":3,\"4\":4,\"5\":5,\"6\":6,\"7\":7,\"8\":8,\"9\":9,\"10\":10,\"11\":11,\"12\":12,\"13\":13,\"14\":14,\"15\":15,\"16\":16,\"17\":17,\"18\":18,\"19\":19,\"20\":20,\"21\":21,\"22\":22,\"23\":23,\"24\":24,\"25\":25,\"26\":26,\"27\":27,\"28\":28,\"29\":29,\"30\":30,\"31\":31,\"32\":32,\"33\":33,\"34\":34,\"35\":35,\"36\":36,\"37\":37,\"38\":38,\"39\":39,\"40\":40,\"41\":41,\"42\":42,\"43\":43,\"44\":44,\"45\":45,\"46\":46,\"47\":47,\"48\":48,\"49\":49,\"50\":50,\"51\":51,\"52\":52,\"53\":53,\"54\":54,\"55\":55,\"56\":56,\"57\":57,\"58\":58,\"59\":59,\"60\":60,\"61\":61,\"62\":62,\"63\":63,\"64\":64,\"65\":65,\"66\":66,\"67\":67,\"68\":68,\"69\":69,\"70\":70,\"71\":71,\"72\":72,\"73\":73,\"74\":74,\"75\":75,\"76\":76,\"77\":77,\"78\":78,\"79\":79,\"80\":80,\"81\":81,\"82\":82,\"83\":83,\"84\":84,\"85\":85,\"86\":86,\"87\":87,\"88\":88,\"89\":89,\"90\":90,\"91\":91,\"92\":92,\"93\":93,\"94\":94,\"95\":95,\"96\":96,\"97\":97,\"98\":98,\"99\":99,\"100\":100,\"101\":101,\"102\":102,\"103\":103,\"104\":104,\"105\":105,\"106\":106,\"107\":107,\"108\":108,\"109\":109,\"110\":110,\"111\":111,\"112\":112,\"113\":113,\"114\":114,\"115\":115,\"116\":116,\"117\":117,\"118\":118,\"119\":119,\"120\":120,\"121\":121,\"122\":122,\"123\":123,\"124\":124,\"125\":125,\"126\":126,\"127\":127,\"128\":128,\"129\":129,\"130\":130,\"131\":131,\"132\":132,\"133\":133,\"134\":134,\"135\":135,\"136\":136,\"137\":137,\"138\":138,\"139\":139,\"140\":140,\"141\":141,\"142\":142,\"143\":143,\"144\":144,\"145\":145,\"146\":146,\"147\":147,\"148\":148,\"149\":149,\"150\":150,\"151\":151,\"152\":152,\"153\":153,\"154\":154,\"155\":155,\"156\":156,\"157\":157,\"158\":158,\"159\":159,\"160\":160,\"161\":161,\"162\":162,\"163\":163,\"164\":164,\"165\":165,\"166\":166,\"167\":167,\"168\":168,\"169\":169,\"170\":170,\"171\":171,\"172\":172,\"173\":173,\"174\":174,\"175\":175,\"176\":176,\"177\":177,\"178\":178,\"179\":179,\"180\":180,\"181\":181,\"182\":182,\"183\":183,\"184\":184,\"185\":185,\"186\":186,\"187\":187,\"188\":188,\"189\":189,\"190\":190,\"191\":191,\"192\":192,\"193\":193,\"194\":194,\"195\":195,\"196\":196,\"197\":197,\"198\":198,\"199\":199,\"200\":200,\"201\":201,\"202\":202,\"203\":203,\"204\":204,\"205\":205,\"206\":206,\"207\":207,\"208\":208,\"209\":209,\"210\":210,\"211\":211,\"212\":212,\"213\":213,\"214\":214,\"215\":215,\"216\":216,\"217\":217,\"218\":218,\"219\":219,\"220\":220,\"221\":221,\"222\":222,\"223\":223,\"224\":224,\"225\":225,\"226\":226,\"227\":227,\"228\":228,\"229\":229,\"230\":230,\"231\":231,\"232\":232,\"233\":233,\"234\":234,\"235\":235,\"236\":236,\"237\":237,\"238\":238,\"239\":239,\"240\":240,\"241\":241,\"242\":242,\"243\":243,\"244\":244,\"245\":245,\"246\":246,\"247\":247,\"248\":248,\"249\":249,\"250\":250,\"251\":251,\"252\":252,\"253\":253,\"254\":254,\"255\":255,\"256\":256,\"257\":257,\"258\":258,\"259\":259,\"260\":260,\"261\":261,\"262\":262,\"263\":263,\"264\":264,\"265\":265,\"266\":266,\"267\":267,\"268\":268,\"269\":269,\"270\":270,\"271\":271,\"272\":272,\"273\":273,\"274\":274,\"275\":0,\"276\":1,\"277\":2,\"278\":3,\"279\":4,\"280\":5,\"281\":6,\"282\":7,\"283\":8,\"284\":9,\"285\":10,\"286\":11,\"287\":12,\"288\":13,\"289\":14,\"290\":15,\"291\":16,\"292\":17,\"293\":18,\"294\":19,\"295\":20,\"296\":21,\"297\":22,\"298\":23,\"299\":24,\"300\":25,\"301\":26,\"302\":27,\"303\":28,\"304\":29,\"305\":30,\"306\":31,\"307\":32,\"308\":33,\"309\":34,\"310\":35,\"311\":36,\"312\":37,\"313\":38,\"314\":39,\"315\":40,\"316\":41,\"317\":42,\"318\":43,\"319\":44,\"320\":45,\"321\":46,\"322\":47,\"323\":48,\"324\":49,\"325\":50,\"326\":51,\"327\":52,\"328\":53,\"329\":54,\"330\":55,\"331\":56,\"332\":57,\"333\":58,\"334\":59,\"335\":60,\"336\":61,\"337\":62,\"338\":63,\"339\":64,\"340\":65,\"341\":66,\"342\":67,\"343\":68,\"344\":69,\"345\":70,\"346\":71,\"347\":72,\"348\":73,\"349\":74,\"350\":75,\"351\":76,\"352\":77,\"353\":78,\"354\":79,\"355\":80,\"356\":81,\"357\":82,\"358\":83,\"359\":84,\"360\":85,\"361\":86,\"362\":87,\"363\":88,\"364\":89,\"365\":90,\"366\":91,\"367\":92,\"368\":93,\"369\":94,\"370\":95,\"371\":96,\"372\":97,\"373\":98,\"374\":99,\"375\":100,\"376\":101,\"377\":102,\"378\":103,\"379\":104,\"380\":105,\"381\":106,\"382\":107,\"383\":108,\"384\":109,\"385\":110,\"386\":111,\"387\":112,\"388\":113,\"389\":114,\"390\":115,\"391\":116,\"392\":117,\"393\":118,\"394\":119,\"395\":120,\"396\":121,\"397\":122,\"398\":123,\"399\":124,\"400\":125,\"401\":126,\"402\":127,\"403\":128,\"404\":129,\"405\":130,\"406\":131,\"407\":132,\"408\":133,\"409\":134,\"410\":135,\"411\":136,\"412\":137,\"413\":138,\"414\":139,\"415\":140,\"416\":141,\"417\":142,\"418\":143,\"419\":144,\"420\":145,\"421\":146,\"422\":147,\"423\":148,\"424\":149,\"425\":150,\"426\":151,\"427\":152,\"428\":153,\"429\":154,\"430\":155,\"431\":156,\"432\":157,\"433\":158,\"434\":159,\"435\":160,\"436\":161,\"437\":162,\"438\":163,\"439\":164,\"440\":165,\"441\":166,\"442\":167,\"443\":168,\"444\":169,\"445\":170,\"446\":171,\"447\":172,\"448\":173,\"449\":174,\"450\":175,\"451\":176,\"452\":177,\"453\":178,\"454\":179,\"455\":180,\"456\":181,\"457\":182,\"458\":183,\"459\":184,\"460\":185,\"461\":186,\"462\":187,\"463\":188,\"464\":189,\"465\":190,\"466\":191,\"467\":192,\"468\":193,\"469\":194,\"470\":195,\"471\":196,\"472\":197,\"473\":198,\"474\":199,\"475\":200,\"476\":201,\"477\":202,\"478\":203,\"479\":204,\"480\":205,\"481\":206,\"482\":207,\"483\":208,\"484\":209,\"485\":210,\"486\":211,\"487\":212,\"488\":213,\"489\":214,\"490\":215,\"491\":216,\"492\":217,\"493\":218,\"494\":219,\"495\":220,\"496\":221,\"497\":222,\"498\":223,\"499\":224,\"500\":225,\"501\":226,\"502\":227,\"503\":228,\"504\":229,\"505\":230,\"506\":231,\"507\":232,\"508\":233,\"509\":234,\"510\":235,\"511\":236,\"512\":237,\"513\":238,\"514\":239,\"515\":240,\"516\":241,\"517\":242,\"518\":243,\"519\":244,\"520\":245,\"521\":246,\"522\":247,\"523\":248,\"524\":249,\"525\":250,\"526\":251,\"527\":252,\"528\":253,\"529\":254,\"530\":255,\"531\":256,\"532\":257,\"533\":258,\"534\":259,\"535\":260,\"536\":261,\"537\":262,\"538\":263,\"539\":264,\"540\":265,\"541\":266,\"542\":267,\"543\":268,\"544\":269,\"545\":270,\"546\":271,\"547\":272,\"548\":273,\"549\":274,\"550\":275,\"551\":276,\"552\":277,\"553\":278,\"554\":279,\"555\":280,\"556\":281,\"557\":282,\"558\":283,\"559\":284,\"560\":285,\"561\":286,\"562\":287,\"563\":288,\"564\":289,\"565\":290,\"566\":291,\"567\":292,\"568\":293,\"569\":294,\"570\":295,\"571\":296,\"572\":297,\"573\":298,\"574\":299,\"575\":300,\"576\":301,\"577\":302,\"578\":303,\"579\":304,\"580\":305,\"581\":306,\"582\":307,\"583\":308,\"584\":309,\"585\":310,\"586\":311,\"587\":312,\"588\":313,\"589\":314,\"590\":315,\"591\":316,\"592\":317,\"593\":318,\"594\":319,\"595\":320,\"596\":321,\"597\":322,\"598\":323,\"599\":324,\"600\":325,\"601\":326,\"602\":327,\"603\":328,\"604\":329,\"605\":330,\"606\":331,\"607\":332,\"608\":333,\"609\":334,\"610\":335,\"611\":336,\"612\":337,\"613\":338,\"614\":339,\"615\":340,\"616\":341,\"617\":342,\"618\":343,\"619\":344,\"620\":345,\"621\":346,\"622\":347,\"623\":348,\"624\":349,\"625\":350,\"626\":351,\"627\":352,\"628\":353,\"629\":354,\"630\":355,\"631\":356,\"632\":357,\"633\":358,\"634\":359,\"635\":360,\"636\":361,\"637\":362,\"638\":363,\"639\":364,\"640\":365,\"641\":366,\"642\":367,\"643\":368,\"644\":369,\"645\":370,\"646\":371,\"647\":372,\"648\":373,\"649\":374,\"650\":375,\"651\":376,\"652\":377,\"653\":378,\"654\":379,\"655\":380,\"656\":381,\"657\":382,\"658\":383,\"659\":384,\"660\":385,\"661\":386,\"662\":387,\"663\":388,\"664\":389,\"665\":390,\"666\":391,\"667\":392,\"668\":393,\"669\":394,\"670\":395,\"671\":396,\"672\":397,\"673\":398,\"674\":0,\"675\":1,\"676\":2,\"677\":3,\"678\":4,\"679\":5,\"680\":6,\"681\":7,\"682\":8,\"683\":9,\"684\":10,\"685\":11,\"686\":12,\"687\":13,\"688\":14,\"689\":15,\"690\":16,\"691\":17,\"692\":18,\"693\":19,\"694\":20,\"695\":21,\"696\":22,\"697\":23,\"698\":24,\"699\":25,\"700\":26,\"701\":27,\"702\":28,\"703\":29,\"704\":30,\"705\":31,\"706\":32,\"707\":33,\"708\":34,\"709\":35,\"710\":36,\"711\":37,\"712\":38,\"713\":39,\"714\":40,\"715\":41,\"716\":42,\"717\":43,\"718\":44,\"719\":45,\"720\":46,\"721\":47,\"722\":48,\"723\":49,\"724\":50,\"725\":51,\"726\":52,\"727\":53,\"728\":54,\"729\":55,\"730\":56,\"731\":57,\"732\":58,\"733\":59,\"734\":60,\"735\":61,\"736\":62,\"737\":63,\"738\":64,\"739\":65,\"740\":66,\"741\":67,\"742\":68,\"743\":69,\"744\":70,\"745\":71,\"746\":72,\"747\":73,\"748\":74,\"749\":75,\"750\":76,\"751\":77,\"752\":78,\"753\":79,\"754\":80,\"755\":81,\"756\":82,\"757\":83,\"758\":84,\"759\":85,\"760\":86,\"761\":87,\"762\":88,\"763\":89,\"764\":90,\"765\":91,\"766\":92,\"767\":93,\"768\":94,\"769\":95,\"770\":96,\"771\":97,\"772\":98,\"773\":99,\"774\":100,\"775\":101,\"776\":102,\"777\":103,\"778\":104,\"779\":105,\"780\":106,\"781\":107,\"782\":108,\"783\":109,\"784\":110,\"785\":111,\"786\":112,\"787\":113,\"788\":114,\"789\":115,\"790\":116,\"791\":117,\"792\":118,\"793\":119,\"794\":120,\"795\":121,\"796\":122,\"797\":123,\"798\":124,\"799\":125,\"800\":126,\"801\":127,\"802\":128,\"803\":129,\"804\":130,\"805\":131,\"806\":132,\"807\":133,\"808\":134,\"809\":135,\"810\":136,\"811\":137,\"812\":138,\"813\":139,\"814\":140,\"815\":141,\"816\":142,\"817\":143,\"818\":144,\"819\":145,\"820\":146,\"821\":147,\"822\":148,\"823\":149,\"824\":150,\"825\":151,\"826\":152,\"827\":153,\"828\":154,\"829\":155,\"830\":156,\"831\":157,\"832\":158,\"833\":159,\"834\":160,\"835\":161,\"836\":162,\"837\":163,\"838\":164,\"839\":165,\"840\":166,\"841\":167,\"842\":168,\"843\":169,\"844\":170,\"845\":171,\"846\":172,\"847\":173,\"848\":174,\"849\":175,\"850\":176,\"851\":177,\"852\":178,\"853\":179,\"854\":180,\"855\":181,\"856\":182,\"857\":183,\"858\":184,\"859\":185,\"860\":186,\"861\":187,\"862\":188,\"863\":189,\"864\":190,\"865\":191,\"866\":192,\"867\":193,\"868\":194,\"869\":195,\"870\":196,\"871\":197,\"872\":198,\"873\":199,\"874\":200,\"875\":201,\"876\":202,\"877\":203,\"878\":204,\"879\":205,\"880\":206,\"881\":207,\"882\":208,\"883\":209,\"884\":210,\"885\":211,\"886\":212,\"887\":213,\"888\":214,\"889\":215,\"890\":216,\"891\":217,\"892\":218,\"893\":219,\"894\":220,\"895\":221,\"896\":222,\"897\":223,\"898\":224,\"899\":225,\"900\":226,\"901\":227,\"902\":228,\"903\":229,\"904\":230,\"905\":231,\"906\":232,\"907\":233,\"908\":234,\"909\":235,\"910\":236,\"911\":237,\"912\":238,\"913\":239,\"914\":240,\"915\":241,\"916\":242,\"917\":243,\"918\":244,\"919\":245,\"920\":246,\"921\":247,\"922\":248,\"923\":249,\"924\":250,\"925\":251,\"926\":252,\"927\":253,\"928\":254,\"929\":255,\"930\":256,\"931\":257,\"932\":258,\"933\":259,\"934\":260,\"935\":261,\"936\":262,\"937\":263,\"938\":264,\"939\":265,\"940\":266,\"941\":267,\"942\":268,\"943\":269,\"944\":270,\"945\":271,\"946\":272,\"947\":273,\"948\":274,\"949\":275,\"950\":276,\"951\":277,\"952\":278,\"953\":279,\"954\":280,\"955\":281,\"956\":282,\"957\":283,\"958\":284,\"959\":285,\"960\":286,\"961\":287,\"962\":288,\"963\":289,\"964\":290,\"965\":291,\"966\":292,\"967\":293,\"968\":294,\"969\":295,\"970\":296,\"971\":297,\"972\":298,\"973\":299,\"974\":300,\"975\":301,\"976\":302,\"977\":303,\"978\":304,\"979\":305,\"980\":306,\"981\":307,\"982\":308,\"983\":309,\"984\":310,\"985\":311,\"986\":312,\"987\":313,\"988\":314,\"989\":315,\"990\":316,\"991\":317,\"992\":318,\"993\":319,\"994\":320,\"995\":321,\"996\":322,\"997\":323,\"998\":324,\"999\":325,\"1000\":326,\"1001\":327,\"1002\":328,\"1003\":329,\"1004\":330,\"1005\":331,\"1006\":332,\"1007\":333,\"1008\":334,\"1009\":335,\"1010\":336,\"1011\":337,\"1012\":338,\"1013\":339,\"1014\":340,\"1015\":341,\"1016\":342,\"1017\":343,\"1018\":344,\"1019\":345,\"1020\":346,\"1021\":347,\"1022\":348,\"1023\":349,\"1024\":350,\"1025\":351,\"1026\":352,\"1027\":353,\"1028\":354,\"1029\":355,\"1030\":356,\"1031\":357,\"1032\":358,\"1033\":359,\"1034\":360,\"1035\":361,\"1036\":362,\"1037\":363,\"1038\":364,\"1039\":365,\"1040\":366,\"1041\":367,\"1042\":368,\"1043\":369,\"1044\":370,\"1045\":371,\"1046\":372,\"1047\":373,\"1048\":374,\"1049\":375,\"1050\":376,\"1051\":377,\"1052\":378,\"1053\":379,\"1054\":380,\"1055\":381,\"1056\":382,\"1057\":383,\"1058\":384,\"1059\":385,\"1060\":386,\"1061\":387,\"1062\":388,\"1063\":389,\"1064\":390,\"1065\":391,\"1066\":392,\"1067\":393,\"1068\":394,\"1069\":395,\"1070\":396,\"1071\":397,\"1072\":398,\"1073\":399,\"1074\":400,\"1075\":401,\"1076\":402,\"1077\":403,\"1078\":404,\"1079\":405,\"1080\":406,\"1081\":407,\"1082\":408,\"1083\":409,\"1084\":410,\"1085\":411,\"1086\":412,\"1087\":413,\"1088\":414,\"1089\":415,\"1090\":416,\"1091\":417,\"1092\":418,\"1093\":419,\"1094\":420,\"1095\":421,\"1096\":422,\"1097\":423,\"1098\":424,\"1099\":425,\"1100\":426,\"1101\":427,\"1102\":428,\"1103\":429,\"1104\":430,\"1105\":431,\"1106\":432,\"1107\":433,\"1108\":434,\"1109\":435,\"1110\":436,\"1111\":437,\"1112\":438,\"1113\":439,\"1114\":440,\"1115\":441,\"1116\":442,\"1117\":443,\"1118\":444,\"1119\":445,\"1120\":446,\"1121\":447,\"1122\":448,\"1123\":449,\"1124\":450,\"1125\":451,\"1126\":452,\"1127\":453,\"1128\":454,\"1129\":455,\"1130\":456,\"1131\":457,\"1132\":458,\"1133\":459,\"1134\":460,\"1135\":461,\"1136\":462,\"1137\":0,\"1138\":1,\"1139\":2,\"1140\":3,\"1141\":4,\"1142\":5,\"1143\":6,\"1144\":7,\"1145\":8,\"1146\":9,\"1147\":10,\"1148\":11,\"1149\":12,\"1150\":13,\"1151\":14,\"1152\":15,\"1153\":16,\"1154\":17,\"1155\":18,\"1156\":19,\"1157\":20,\"1158\":21,\"1159\":22,\"1160\":23,\"1161\":24,\"1162\":25,\"1163\":26,\"1164\":27,\"1165\":28,\"1166\":29,\"1167\":30,\"1168\":31,\"1169\":32,\"1170\":33,\"1171\":34,\"1172\":35,\"1173\":36,\"1174\":37,\"1175\":38,\"1176\":39,\"1177\":40,\"1178\":41,\"1179\":42,\"1180\":43,\"1181\":44,\"1182\":45,\"1183\":46,\"1184\":47,\"1185\":48,\"1186\":49,\"1187\":50,\"1188\":51,\"1189\":52,\"1190\":53,\"1191\":54,\"1192\":55,\"1193\":56,\"1194\":57,\"1195\":58,\"1196\":59,\"1197\":60,\"1198\":61,\"1199\":62,\"1200\":63,\"1201\":64,\"1202\":65,\"1203\":66,\"1204\":67,\"1205\":68,\"1206\":69,\"1207\":70,\"1208\":71,\"1209\":72,\"1210\":73,\"1211\":74,\"1212\":75,\"1213\":76,\"1214\":77,\"1215\":78,\"1216\":79,\"1217\":80,\"1218\":81,\"1219\":82,\"1220\":83,\"1221\":84,\"1222\":85,\"1223\":86,\"1224\":87,\"1225\":88,\"1226\":89,\"1227\":90,\"1228\":91,\"1229\":92,\"1230\":93,\"1231\":94,\"1232\":95,\"1233\":96,\"1234\":97,\"1235\":98,\"1236\":99,\"1237\":100,\"1238\":101,\"1239\":102,\"1240\":103,\"1241\":104,\"1242\":105,\"1243\":106,\"1244\":107,\"1245\":108,\"1246\":109,\"1247\":110,\"1248\":111,\"1249\":112,\"1250\":113,\"1251\":114,\"1252\":115,\"1253\":116,\"1254\":117,\"1255\":118,\"1256\":119,\"1257\":120,\"1258\":121,\"1259\":122,\"1260\":123,\"1261\":124,\"1262\":125,\"1263\":126,\"1264\":127,\"1265\":128,\"1266\":129,\"1267\":130,\"1268\":131,\"1269\":132,\"1270\":133,\"1271\":134,\"1272\":135,\"1273\":136,\"1274\":137,\"1275\":138,\"1276\":139,\"1277\":140,\"1278\":141,\"1279\":142,\"1280\":143,\"1281\":144,\"1282\":145,\"1283\":146,\"1284\":147,\"1285\":148,\"1286\":149,\"1287\":150,\"1288\":151,\"1289\":152,\"1290\":153,\"1291\":154,\"1292\":155,\"1293\":156,\"1294\":157,\"1295\":158,\"1296\":159,\"1297\":160,\"1298\":161,\"1299\":162,\"1300\":163,\"1301\":164,\"1302\":165,\"1303\":166,\"1304\":167,\"1305\":168,\"1306\":169,\"1307\":170,\"1308\":171,\"1309\":172,\"1310\":173,\"1311\":174,\"1312\":175,\"1313\":176,\"1314\":177,\"1315\":178,\"1316\":179,\"1317\":180,\"1318\":181,\"1319\":182,\"1320\":183,\"1321\":184,\"1322\":185,\"1323\":186,\"1324\":187,\"1325\":188,\"1326\":189,\"1327\":190,\"1328\":191,\"1329\":192,\"1330\":193,\"1331\":194,\"1332\":195,\"1333\":196,\"1334\":197,\"1335\":198,\"1336\":199,\"1337\":200,\"1338\":201,\"1339\":202,\"1340\":203,\"1341\":204,\"1342\":205,\"1343\":206,\"1344\":207,\"1345\":208,\"1346\":209,\"1347\":210,\"1348\":211,\"1349\":212,\"1350\":213,\"1351\":214,\"1352\":215,\"1353\":216,\"1354\":217,\"1355\":218,\"1356\":219,\"1357\":220,\"1358\":221,\"1359\":222,\"1360\":223,\"1361\":224,\"1362\":225,\"1363\":226,\"1364\":227,\"1365\":228,\"1366\":229,\"1367\":230,\"1368\":231,\"1369\":232,\"1370\":233,\"1371\":234,\"1372\":235,\"1373\":236,\"1374\":237,\"1375\":238,\"1376\":239,\"1377\":240,\"1378\":241,\"1379\":242,\"1380\":243,\"1381\":244,\"1382\":245,\"1383\":246,\"1384\":247,\"1385\":248,\"1386\":249,\"1387\":250,\"1388\":251,\"1389\":0,\"1390\":1,\"1391\":2,\"1392\":3,\"1393\":4,\"1394\":5,\"1395\":6,\"1396\":7,\"1397\":8,\"1398\":9,\"1399\":10,\"1400\":11,\"1401\":12,\"1402\":13,\"1403\":14,\"1404\":15,\"1405\":16,\"1406\":17,\"1407\":18,\"1408\":19,\"1409\":20,\"1410\":21,\"1411\":22,\"1412\":23,\"1413\":24,\"1414\":25,\"1415\":26,\"1416\":27,\"1417\":28,\"1418\":29,\"1419\":30,\"1420\":31,\"1421\":32,\"1422\":33,\"1423\":34,\"1424\":35,\"1425\":36,\"1426\":37,\"1427\":38,\"1428\":39,\"1429\":40,\"1430\":41,\"1431\":42,\"1432\":43,\"1433\":44,\"1434\":45,\"1435\":46,\"1436\":47,\"1437\":48,\"1438\":49,\"1439\":50,\"1440\":51,\"1441\":52,\"1442\":53,\"1443\":54,\"1444\":55,\"1445\":56,\"1446\":57,\"1447\":58,\"1448\":59,\"1449\":60,\"1450\":61,\"1451\":62,\"1452\":63,\"1453\":64,\"1454\":65,\"1455\":66,\"1456\":67,\"1457\":68,\"1458\":69,\"1459\":70,\"1460\":71,\"1461\":72,\"1462\":73,\"1463\":74,\"1464\":75,\"1465\":76,\"1466\":77,\"1467\":78,\"1468\":79,\"1469\":80,\"1470\":81,\"1471\":82,\"1472\":83,\"1473\":84,\"1474\":85,\"1475\":86,\"1476\":87,\"1477\":88,\"1478\":89,\"1479\":90,\"1480\":91,\"1481\":92,\"1482\":93,\"1483\":94,\"1484\":95,\"1485\":96,\"1486\":97,\"1487\":98,\"1488\":99,\"1489\":100,\"1490\":101,\"1491\":102,\"1492\":103,\"1493\":104,\"1494\":105,\"1495\":106,\"1496\":107,\"1497\":108,\"1498\":109,\"1499\":110,\"1500\":111,\"1501\":112,\"1502\":113,\"1503\":114,\"1504\":115,\"1505\":116,\"1506\":117,\"1507\":118,\"1508\":119,\"1509\":120,\"1510\":121,\"1511\":122,\"1512\":123,\"1513\":124,\"1514\":125,\"1515\":126,\"1516\":127,\"1517\":128,\"1518\":129,\"1519\":130,\"1520\":131,\"1521\":132,\"1522\":133,\"1523\":134,\"1524\":135,\"1525\":136,\"1526\":137,\"1527\":138,\"1528\":139,\"1529\":140,\"1530\":141,\"1531\":142,\"1532\":143,\"1533\":144,\"1534\":145,\"1535\":146,\"1536\":147,\"1537\":148,\"1538\":149,\"1539\":150,\"1540\":151,\"1541\":152,\"1542\":153,\"1543\":154,\"1544\":155,\"1545\":156,\"1546\":157,\"1547\":158,\"1548\":159,\"1549\":160,\"1550\":161,\"1551\":162,\"1552\":163,\"1553\":164,\"1554\":165,\"1555\":166,\"1556\":167,\"1557\":168,\"1558\":169,\"1559\":170,\"1560\":171,\"1561\":172,\"1562\":173,\"1563\":174,\"1564\":175,\"1565\":176,\"1566\":177,\"1567\":178,\"1568\":179,\"1569\":180,\"1570\":181,\"1571\":182,\"1572\":183,\"1573\":184,\"1574\":185,\"1575\":186,\"1576\":187,\"1577\":188,\"1578\":189,\"1579\":190,\"1580\":191,\"1581\":192,\"1582\":193,\"1583\":194,\"1584\":195,\"1585\":196,\"1586\":197,\"1587\":198,\"1588\":199,\"1589\":200,\"1590\":201,\"1591\":202,\"1592\":203,\"1593\":204,\"1594\":205,\"1595\":206,\"1596\":207,\"1597\":208,\"1598\":209,\"1599\":210,\"1600\":211,\"1601\":212,\"1602\":213,\"1603\":214,\"1604\":215,\"1605\":216,\"1606\":217,\"1607\":218,\"1608\":219,\"1609\":220,\"1610\":221,\"1611\":222,\"1612\":223,\"1613\":224,\"1614\":225,\"1615\":226,\"1616\":227,\"1617\":228,\"1618\":229,\"1619\":230,\"1620\":231,\"1621\":232,\"1622\":233,\"1623\":234,\"1624\":235,\"1625\":236,\"1626\":237,\"1627\":238,\"1628\":239,\"1629\":240,\"1630\":241,\"1631\":242,\"1632\":243,\"1633\":244,\"1634\":245,\"1635\":246,\"1636\":247,\"1637\":248,\"1638\":249,\"1639\":250,\"1640\":251,\"1641\":252,\"1642\":253,\"1643\":254,\"1644\":255,\"1645\":256,\"1646\":257,\"1647\":258,\"1648\":259,\"1649\":260,\"1650\":261,\"1651\":262},\"text\":{\"0\":\"Machine learning techniques to predict overweight or obesity Elias Rodr\\u00edgueza , Elen Rodr\\u00edgueza , Luiz Nascimentoa,b , Aneirson da Silvaa and Fernando Marinsa a S\\u00e3o Paulo State University (UNESP), Av. Dr. Ariberto Pereira da Cunha, 333, Guaratinguet\\u00e1\\/SP, 12516-410, Brazil b University of Taubat\\u00e9 (UNITAU), Av. Professor Walter Taumaturgo, 739, Taubat\\u00e9\\/SP, 12030-040, Brazil.\",\"1\":\"Abstract Overweight and obesity are considered a public health problem, as they are related to the risk of various diseases, and also to the risk of increased morbidity and mortality.\",\"2\":\"The main objective of this work was to apply machine learning techniques for the development of a predictive model for the identification of people with obesity or overweight.\",\"3\":\"The model developed was based on data related to the physical condition and eating habits.\",\"4\":\"Furthermore, the machine learning classification algorithms that were tested were: decision tree,support vector machines, k-nearest neighbors, gaussian naive bayes, multilayer perceptron, random forest, gradient boosting, and extreme gradient boosting.\",\"5\":\"Model hyperparameters were tuned to improve accuracy, resulting in that the model with the best performance was a random forest with 78% accuracy, 79% precision, 78% recall, and 78% F1-score.\",\"6\":\"Finally, the potential of using machine learning models to identify people who are overweight or obese was demonstrated.\",\"7\":\"The practical use of the model developed will allow specialists in the health area to use it as an advantage for decision-making.\",\"8\":\"Keywords 1 Overweight and obesity, machine learning, classification models, body mass index 1.\",\"9\":\"Introduction Overweight and obesity, according to the World Health Organization (WHO), can be defined as the excessive accumulation of fat in different parts of the body [1] , and is recognized as an important public health problem as it is related to various diseases, and even morbidity and mortality [2].\",\"10\":\"Some diseases associated with obesity are: type 2 diabetes mellitus, hypertension, stroke, osteoarthritis, depression, Alzheimer's, and some types of cancer such as breast, prostate, kidney, ovary, liver, and colon cancer, among others [1, 3].\",\"11\":\"In this context, an adult is overweight when he has a Body Mass Index (BMI) \\u2265 of 25 kg\\/m2 and is obese when a BMI \\u2265 of 30 kg\\/m2 [1, 4].\",\"12\":\"In addition, according to WHO analyzes, over the years, the prevalence of obesity worldwide has almost tripled [1], becoming not only a problem in developed countries but also in developing countries [5, 6].\",\"13\":\"Figure 1 illustrates the evolution of the prevalence of overweight (a) and obesity (b) globally and by region.\",\"14\":\"Regarding overweight, the global prevalence in 1975 was 20.2%, and by 2016 the prevalence increased to 39.1% (Figure 1(A)).\",\"15\":\"The regions with the highest prevalence of overweight were Europe and America, with values of 40.0% and 35.0% in 1975, and the prevalence values increased to 62.3% and 63.3% in 2016, respectively [7].\",\"16\":\"IDDM-2021: 4th International Conference on Informatics & Data-Driven Medicine, November 19\\u201321, 2021, Valencia, Spain EMAIL: elias.aguirre@unesp.br (E. Rodr\\u00edguez); elen.aguirre@unesp.br (E. Rodr\\u00edguez); fernando.nascimento@unesp.br (L. Nascimento); aneirson.silva@unesp.br (A. da Silva); fernando.marins@unesp.br (F. Marins) ORCID: 0000-0003-1120-1708 (E. Rodr\\u00edguez); 0000-0002-3829-4118 (E. Rodr\\u00edguez); 0000-0001-9793-750X (L. Nascimento); 0000-00022215-0734 (A. da Silva); 0000-0001-6510-9187 (F. Marins) \\u00a9\\ufe0f 2021 Copyright for this paper by its authors.\",\"17\":\"Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).\",\"18\":\"CEUR Workshop Proceedings (CEUR-WS.org) \\fGlobal South-East Asia Western Pacific Europe Americas Eastern Mediterranean Africa (A) Prevalence of overweight (B) Prevalence of obesity Figure 1: Prevalence of overweight and obesity globally and by region Concerning obesity, the global prevalence in 1975 was 4.3%, and the increase in prevalence was greater for 2016, with a value equal to 13.2% (Figure 1(B)).\",\"19\":\"Similarly, the regions with the highest prevalence of obesity were also Europe and America, with values of 10.1% and 9.0% in 1975, and in 2016 the prevalence of overweight values increased to 25.3% and 29.0%, respectively [7].\",\"20\":\"On the other hand, if the growing trend of the prevalence of obesity continues, it is estimated that by 2030 about 50% of the global population will be overweight or obese [8, 9].\",\"21\":\"Some studies affirm that the increase in the prevalence of obesity and overweight at a global level is due to complex changes in the population, concerning lifestyle, increased calorie consumption, decreased physical activity, and other factors such as urbanization, environmental changes, socioeconomic status, and genetic changes [8, 10].\",\"22\":\"Therefore, preventing obesity is complex, since it requires changes in the physical activity and eating habits of the population, in addition to the collective support from the government, industry, and the scientific and medical community [10], to minimize overweight by enabling the population to make sensible decisions regarding their lifestyle [11].\",\"23\":\"In this sense, in the literature, various studies can be found in which the development of technological tools is proposed, such as the application of machine learning [12, 13, 14], to support decision-making for specialists in the area, to reduce the prevalence of obesity and overweight.\",\"24\":\"Machine Learning can be defined as the study of computational methods for the identification of complex patterns in millions of data in order to build predictive models [15].\",\"25\":\"In addition, machine learning techniques in the health area have been gaining popularity in recent years [16].\",\"26\":\"This article aims to develop a predictive model using machine learning techniques with data collected through a survey to identify people with obesity and overweight and to make timely decisions.\",\"27\":\"20.2 39.1 0 10 20 30 40 50 60 70 0 5 10 15 20 25 30 35 40 45 4.3 13.2 0 5 10 15 20 25 30 35 0 2 4 6 8 10 12 14 \\fThe data collected for the development of the model are related to the physical condition and eating habits.\",\"28\":\"The work is organized as follows: Section 2 maps the publications in the literature on machine learning related to obesity or overweight; Section 3 describes the methodology and dataset used for the study; Section 4 presents the results and discussion; and finally, Section 5 brings the conclusions of this work, followed by the bibliographic references.\",\"29\":\"2.\",\"30\":\"Machine learning in overweight and obesity The number of publications where machine learning techniques were used in health problems is increasing, and the approach about the overweight and obesity is no exception.\",\"31\":\"Thus, this section presents an analysis of the publications in SCOPUS about the application of machine learning techniques with data related to obesity or overweight.\",\"32\":\"Table 1 presents the number of documents published with the keywords \\u2018Obesity\\u2019 AND\\/OR \\u2018Overweight\\u2019 AND \\u2018Machine Learning\\u2019.\",\"33\":\"The collection of the dataset for the analysis was refined by consulting published academic documents, including only articles and review articles, published from 1997 to 2021 (until the month of August).\",\"34\":\"Table 1 Results of the Scopus search Keywords Type Publications Citations Impact fator h-index (\\u2018Obesity\\u2019 OR \\u2018Overweight\\u2019) AND \\u2018Machine Learning\\u2019 Complete 508 6,649 13.09 36 (\\u2018Obesity\\u2019 OR \\u2018Overweight\\u2019) AND \\u2018Machine Learning\\u2019 Title 26 186 7.15 7 From Table 1, it is evident that the combination of the keywords \\u2018Obesity\\u2019, \\u2018Overweight\\u2019 and \\u2018Machine Learning\\u2019 refined by 'Article title, Abstract, Keywords\\\" results in a considerable number of publications (508) and citations (6,649), which is much greater than the number of publications (26) with the refined search just by 'Article title', which has 186 citations.\",\"35\":\"Figure 2 shows the time series of the distribution of articles published and the number of citations per year.\",\"36\":\"(A) Search result for 'Article title, Abstract, Keywords' (B) Search result for 'Article title' Figure 2: Number of publications and citations per year In both cases (Figure 2 (A) and (B)), it is shown that there has been an increase in the number of publications, which indicates that there is a growing interest in the application of machine learning techniques in problems related to obesity.\",\"37\":\"In addition, 70% and 81% of the documents found were published in the 2019-2021 period, as shown in Figure 2 (A) and (B) respectively.\",\"38\":\"Table 2 shows the description of some articles found in this analysis, which are related to this work.\",\"39\":\"0 500 1000 1500 2000 2500 0 50 100 150 200 ARTICLE CITED 0 10 20 30 40 50 0 2 4 6 8 10 12 ARTICLE CITED \\fTable 2 Articles related to this research Author Title Data Machine learning methods Final model Thamrin et al., 2021 [17] Predicting Obesity in Adults Using Machine Learning Techniques: An Analysis of Indonesian Basic Health Research 2018.\",\"40\":\"Data from an Indonesian national scale survey, with information from 300,000 families.\",\"41\":\"Logistic Regression, Classification and Regression Trees (CART), and Na\\u00efve Bayes.\",\"42\":\"The Logistic Regression model with 72% accuracy, 71% specificity, and 69% precision.\",\"43\":\"Dunstan et al., 2020[18] Predicting nationwide obesity from food sales using machine learning.\",\"44\":\"Data was collected from 79 countries, with variables related to food and beverage sales, and the prevalence of obesity in adults.\",\"45\":\"Support vector machine, random forest, and extreme gradient boosting.\",\"46\":\"The random forest model with 0.057 root mean square error.\",\"47\":\"MachorroCano et al., 2019 [19] PISIoT: A machine learning and IoT-based smart health platform for overweight and obesity control.\",\"48\":\"The dataset was collected by monitoring 40 elderly, of which a wearable device was assigned to each to obtain the biomedical variables.\",\"49\":\"Random forest, and the CART and J48 decision tree algorithms.\",\"50\":\"The J48 model.\",\"51\":\"Wang et al., 2018 [20] Machine learningbased method for obesity risk evaluation using single-nucleotide polymorphisms derived from next-generation sequencing.\",\"52\":\"Data were collected with the informed consent of 139 recruited, with 74 obese and 65 nonobese individuals.\",\"53\":\"Support vector machine, k-nearest neighbor, and decision tree.\",\"54\":\"The SVM model with 70.77% accuracy, 80.09% sensitivity, and 63.02% specificity.\",\"55\":\"Dugan et al., 2015 [12] Machine learning techniques for prediction of early childhood obesity.\",\"56\":\"Data collected from a pediatric clinical decision support system.\",\"57\":\"RandomTree, RandomForest, J48, ID3, Na\\u00efve Bayes, and Bayes trained.\",\"58\":\"The ID3 model with 85% accuracy and 89% sensitivity.\",\"59\":\"3.\",\"60\":\"Material and Methods Based on the purpose of this work, Figure 3 shows the pipeline diagram of the prediction model for the identification of obese or overweight people, based on the data collected in the survey, with the development of the predictive model (training and testing) and the selection of the final model.\",\"61\":\"Figure 3: Pipeline diagram of the prediction model for the identification of obese or overweight people Identify the problem \\uf0b7 Definition of objectives.\",\"62\":\"\\uf0b7 Collected data.\",\"63\":\"Training and Testing \\uf0b7 Model training with cross validation.\",\"64\":\"Data preprocessing \\uf0b7 Data cleaning.\",\"65\":\"\\uf0b7 Descriptive statistics.\",\"66\":\"\\uf0b7 Transformation \\uf0b7 Normalization Model selection \\uf0b7 Performance metrics.\",\"67\":\"3.1.\",\"68\":\"Database Collection The data set for this study was collected through a survey, in which 16 questions related to the interviewees' dietary habits and physical condition were applied.\",\"69\":\"Table 3 presents the survey questions and dataset features.\",\"70\":\"Table 3 Survey questions and features n\\u00b0 Feature Questions Answers Physical description features 1 n_gender What is your gender?\",\"71\":\"Female\\/ Male 2 n_age What is your age?\",\"72\":\"Numeric 3 n_height What is your height?\",\"73\":\"Numeric (m) 4 n_weight What is your weight?\",\"74\":\"Numeric (kg) 5 c_FMOW Has a family member suffered or suffers from overweight?\",\"75\":\"Yes\\/ No Features of dietary habits 6 c_ECFF Do you eat high caloric food frequently?\",\"76\":\"Yes\\/ No 7 c_EVM Do you usually eat vegetables in your meals?\",\"77\":\"Never\\/ Sometimes\\/ Always 8 c_MMHD How many main meals do you have daily?\",\"78\":\"Between 1 or 2\\/ Three\\/ More than three 9 c_EFBM Do you eat any food between meals?\",\"79\":\"Never\\/ Sometimes\\/ Frequently\\/ Always 10 c_SMOKE Do you smoke?\",\"80\":\"Yes\\/ No 11 c_WDRD How much water do you drink daily?\",\"81\":\"Less than a liter\\/Between 1 and 2 L\\/ More than 2 L 12 c_DRAL How often do you drink alcohol?\",\"82\":\"I do not drink\\/ Sometimes\\/ Frequently\\/ Always Physical condition features 13 c_MCED Do you monitor the calories you eat daily?\",\"83\":\"Yes\\/ No 14 c_HPHA How often do you have physical activity?\",\"84\":\"Never\\/1 or 2 days\\/2 or 4 days\\/4 or 5 days 15 c_TTEC How long do you use technological devices?\",\"85\":\"0\\u20132 hours\\/ 3\\u20135 hours\\/ More than 5 hours 16 c_TRANSP What type of transportation do you usually use?\",\"86\":\"Automobile\\/ Motorbike\\/ Bike\\/ Public Transportation\\/ Walking As shown in Table 3, the 16 features of the dataset can be grouped into three categories: (a) physical description features, (b) features of dietary habits, and (c) physical condition features.\",\"87\":\"Physical description Features.\",\"88\":\"Includes features such as gender, age, height, weight and the existence of overweight relatives (c_FMOW).\",\"89\":\"Features of eating habits.\",\"90\":\"Includes the features of consumer foods high in calorie (c_ECFF), vegetable consumption (c_EVM), number of main meals (c_MMHD), food between meals (c_EFBM), water consumption (c_WDRD), alcohol consumption (c_DRAL) and tobacco consumption (c_SMOKE).\",\"91\":\"Physical condition Features.\",\"92\":\"Includes calorie consumption (c_MCED), physical activity (c_HPHA), use of technology devices (c_TTEC), and type of transport used (c_TRANSP).\",\"93\":\"The target feature was of the categorical type, and was calculated through the data labeling process, in which, for each instance of the dataset, the BMI was calculated using the weight (measured in kilograms) and height (measured in meters) information, according to Equation (1): \\ud835\\udc35\\ud835\\udc40\\ud835\\udc3c = \\ud835\\udc4a\\ud835\\udc52\\ud835\\udc56\\ud835\\udc54\\u210e\\ud835\\udc61(\\ud835\\udc58\\ud835\\udc54. ) \\ud835\\udc3b\\ud835\\udc52\\ud835\\udc56\\ud835\\udc54\\u210e\\ud835\\udc61(\\ud835\\udc5a. ) \\u00d7 \\ud835\\udc3b\\ud835\\udc52\\ud835\\udc56\\ud835\\udc54\\u210e\\ud835\\udc61(\\ud835\\udc5a. ) (1) In the identification of classes for data labeling, the classification table of BMI values was used (Table 4), which is made available by the World Health Organization (WHO) [4].\",\"94\":\"Table 4 Body mass index classification Classification BMI Underweight Below 18.5 Normal weight 18.5 \\u2013 24.9 Pre-obesity 25.0 \\u2013 29.9 Obesity class I 30.0 \\u2013 34.9 Obesity class II 35.0 \\u2013 39.9 Obesity class III Above 40 3.2.\",\"95\":\"Data transformation and normalization 3.2.1.\",\"96\":\"Dataset balancing Dataset balancing: Classification models trained with unbalanced data tend to make biased predictions with wrong results, so in many cases, the classes with fewer instances are not enough for the model, and it is necessary to apply a sub-process so that the data is balanced [21].\",\"97\":\"In this case, the classes in the collected dataset were unbalanced, so the \\\"oversampling\\\" technique was used to balance the minority classes in the training dataset.\",\"98\":\"3.2.2.\",\"99\":\"Categorical data encoding In the database used, about 80% of the variables were categorical, so data transformation techniques were used since some of the machine learning algorithms do not allow the use of non-numerical data [21].\",\"100\":\"The features of c_MMHD, c_WDRD, c_HPHA, c_TTEC and c_TRANSP were transformed with the one hot encoding technique, and the features of c_gender, c_FMOW, c_ECFF, c_SMOKE, c_MCED, c_EVM, c_DRAL, and c_EFBM with the ordinal encoding technique.\",\"101\":\"The label encoding technique was used to transform the classes of the target feature.\",\"102\":\"3.2.3.\",\"103\":\"Data normalization Data normalization helps to ensure that features with different ranges do not affect the trained model.\",\"104\":\"In MIN-MAX normalization, the data is scaled in the range of [0 \\u2212 1] or [0.0 \\u2212 1.0] [22], and is calculated according to Equation (2): where \\ud835\\udc65\\u2032 is the normalized value, x is the original value, and \\ud835\\udc65\\ud835\\udc5a\\ud835\\udc4e\\ud835\\udc65 and \\ud835\\udc65\\ud835\\udc5a\\ud835\\udc56\\ud835\\udc5b are the minimum and maximum values, respectively [22].\",\"105\":\"\\ud835\\udc65\\u2032 = \\ud835\\udc65 \\u2212 \\ud835\\udc65\\ud835\\udc5a\\ud835\\udc56\\ud835\\udc5b \\ud835\\udc65\\ud835\\udc5a\\ud835\\udc4e\\ud835\\udc65 \\u2212 \\ud835\\udc65\\ud835\\udc5a\\ud835\\udc56\\ud835\\udc5b (2) \\f3.3.\",\"106\":\"Classification in supervised machine learning The main task of supervised learning is to learn the behavior of a function \\ud835\\udcb4 = \\ud835\\udc53(\\ud835\\udcb3, \\u03b2) based on the features \\ud835\\udcb3 \\u00d7 \\ud835\\udcb4, belonging to the training dataset \\ud835\\udcaf, where \\ud835\\udcb3 = (\\ud835\\udc651, \\ud835\\udc652, \\u2026 \\ud835\\udc65\\ud835\\udc51) \\u2208 \\u211d\\ud835\\udc51 , each \\ud835\\udc65\\ud835\\udc51 is a feature, and \\ud835\\udcb4 \\ud835\\udf16 \\ud835\\udc36 with \\ud835\\udc36 = (\\ud835\\udc501, \\ud835\\udc502, \\u2026 , \\ud835\\udc50\\ud835\\udc57), \\ud835\\udc57 labels [23].\",\"107\":\"In classification problems, the objective of the learned categorical function \\ud835\\udc53(\\ud835\\udcb3) is the mapping of the input variables, to predict a new label \\ud835\\udcb4 [24].\",\"108\":\"The classification models used in this work are described below: - Decision Tree (DT).\",\"109\":\"DT is very popular for its simple structure, ease of interpretation, and for its efficiency [26].\",\"110\":\"The construction of the tree presents an iterative process, starting from a training dataset (\\ud835\\udcaf) with \\ud835\\udc5b observations, recursively partitioned, thus dividing into increasingly homogeneous data subsets [24, 25].\",\"111\":\"- Support Vector Machines (SVM).\",\"112\":\"SVM construct optimal separation limits between variables, applying the input data in a larger nonlinear space, called characteristic space [27].\",\"113\":\"Furthermore, the algorithm uses different kernel functions to model different degrees of nonlinearity and efficiency [25].\",\"114\":\"- K-Nearest Neighbors (KNN).\",\"115\":\"The main objective of the KNN classifier is to predict the closest value using distance as a basis is a widely used technique the euclidean distance [23].\",\"116\":\"The classification of the input data is based mainly on the selection of the majority class among its nearest neighbors [28].\",\"117\":\"- Gaussian Naive Bayes (GNB).\",\"118\":\"GNB classifier is considered a powerful probabilistic algorithm, based on Bayes Theorem, in which it ignores the possible dependencies between characteristics, reducing the multivariate problem to a univariate problem [23, 24, 28].\",\"119\":\"- Multilayer Perceptron (MLP).\",\"120\":\"MLP is a nonparametric estimator, which has the structure of an artificial neural network and is formed by one or more interconnected layers [24].\",\"121\":\"This algorithm uses the backpropagation technique to improve the prediction of the model, in which the gradient is calculated using the error function and the neural network weights, and each node in the model uses a non-linear activation function [25].\",\"122\":\"- Random Forest (RF).\",\"123\":\"RF is a flexible algorithm and is an expansion of the Decision Tree.\",\"124\":\"This algorithm creates randomness from a dataset and trains each of its trees with different random data, then the trees are grouped, and by combining their results the errors are calculated to have a more accurate prediction [23].\",\"125\":\"- Gradient Boosting (GB).\",\"126\":\"GB is a robust classifier that combines several sequential classifiers, each classifier has a different weight, and the error calculated by each classifier is used to improve the prediction value [23, 27].\",\"127\":\"- Extreme Gradient Boosting (XGB).\",\"128\":\"XGB method is an improved version of Gradient Boosting, in which this algorithm uses a split search approach for existing sparse patterns in the data to make the training of the model more efficient, and the risk of overfitting the model is controlled [23, 24].\",\"129\":\"3.4.\",\"130\":\"Cross Validation and performance measures Cross validation is used for the evaluation of machine learning models, where the dataset \\ud835\\udcb3, used for the development of the model, is partitioned into \\ud835\\udc58 subsets (k-folds) of data of equal size (\\ud835\\udcb3\\ud835\\udc56 , where \\ud835\\udc56 = 1, 2, \\u2026 , \\ud835\\udc58) [23,24].\",\"131\":\"In the division of the dataset, \\ud835\\udc58 \\u2212 1 is used for model training \\ud835\\udcaf, and the remainder is used for model validation \\ud835\\udcb1, as shown in Equation (3): \\ud835\\udcb11 = \\ud835\\udcb31 \\ud835\\udcaf 1 = \\ud835\\udcb32 \\u222a \\ud835\\udcb33 \\u222a \\u22ef \\u222a \\ud835\\udcb3\\ud835\\udc58 \\ud835\\udcb12 = \\ud835\\udcb32 \\u22ee \\ud835\\udcb1\\ud835\\udc58 = \\ud835\\udcb3\\ud835\\udc58 \\ud835\\udcaf 2 = \\ud835\\udcb31 \\u222a \\ud835\\udcb33 \\u222a \\u22ef \\u222a \\ud835\\udcb3\\ud835\\udc58 \\u22ee \\ud835\\udcaf \\ud835\\udc58 = \\ud835\\udcb31 \\u222a \\ud835\\udcb32 \\u222a \\u22ef \\u222a \\ud835\\udcb3\\ud835\\udc58\\u22121 (3) The main advantage of the k-fold method is that each subset is used in the testing process only once, reducing the possibility of biased training [23].\",\"132\":\"On the other hand, the models are evaluated, assuming that the validation data (\\ud835\\udcb1) follow the same distribution as the training dataset (\\ud835\\udcaf).\",\"133\":\"In the literature, there are several evaluation metrics, however, a standard metric to measure the efficiency of prediction models has not yet been established [17].\",\"134\":\"In \\fthis work, the performance of the tested models is evaluated based on the comparison of different metrics.\",\"135\":\"According to Marsland [23], the following lines describe the performance metrics used in this work: - Confusion matrix.\",\"136\":\"It helps to evaluate the quality of the classification model and is represented by a matrix, which allows visualizing the performance of each class of the prediction model, as illustrated in the following matrix: Predicted Actual Positive Negative Total Positive TP FP TP + FP Negative FN TN FN + TN Total TP + FN FP + TN - Accuracy.\",\"137\":\"Defined as the sum of the total of true positives and true negatives divided by the total number of results, Equation (4): \\ud835\\udc34\\ud835\\udc50\\ud835\\udc50\\ud835\\udc62\\ud835\\udc5f\\ud835\\udc4e\\ud835\\udc50\\ud835\\udc66 = \\ud835\\udc5b\\u00b0 \\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc5b\\u00b0 \\ud835\\udc39\\ud835\\udc43 \\ud835\\udc5b\\u00b0 \\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc5b\\u00b0 \\ud835\\udc39\\ud835\\udc43 + \\ud835\\udc5b\\u00b0 \\ud835\\udc39\\ud835\\udc41 + \\ud835\\udc5b\\u00b0 \\ud835\\udc47\\ud835\\udc41 (4) - Precision.\",\"138\":\"Defined as the ratio of the number of correctly predicted true positives to the total number of predicted positives, according to Equation (5): \\ud835\\udc43\\ud835\\udc5f\\ud835\\udc52\\ud835\\udc50\\ud835\\udc56\\ud835\\udc60\\ud835\\udc56\\ud835\\udc5c\\ud835\\udc5b = \\ud835\\udc5b\\u00b0 \\ud835\\udc47\\ud835\\udc43 \\ud835\\udc5b\\u00b0 \\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc5b\\u00b0 \\ud835\\udc39\\ud835\\udc43 (5) - Recall.\",\"139\":\"It is also known as the true positives rate.\",\"140\":\"Defined as the ratio of the number of correct positives to the total predictions classified as positives, as was shown in Equation (6): \\ud835\\udc45\\ud835\\udc52\\ud835\\udc50\\ud835\\udc4e\\ud835\\udc59\\ud835\\udc59 = \\ud835\\udc5b\\u00b0 \\ud835\\udc47\\ud835\\udc43 \\ud835\\udc5b\\u00b0 \\ud835\\udc47\\ud835\\udc43 + \\ud835\\udc5b\\u00b0 \\ud835\\udc39\\ud835\\udc41 (6) - F1-score.\",\"141\":\"A single measure that combines the sensitivity and precision value of the prediction model, according to Equation (7): \\ud835\\udc391 \\u2212 \\ud835\\udc60\\ud835\\udc50\\ud835\\udc5c\\ud835\\udc5f\\ud835\\udc52 = 2 \\u00d7 \\ud835\\udc43\\ud835\\udc5f\\ud835\\udc52\\ud835\\udc50\\ud835\\udc56\\ud835\\udc60\\ud835\\udc56\\ud835\\udc5c\\ud835\\udc5b \\u00d7 \\ud835\\udc45\\ud835\\udc52\\ud835\\udc50\\ud835\\udc4e\\ud835\\udc59\\ud835\\udc59 \\ud835\\udc43\\ud835\\udc5f\\ud835\\udc52\\ud835\\udc50\\ud835\\udc56\\ud835\\udc60\\ud835\\udc56\\ud835\\udc5c\\ud835\\udc5b + \\ud835\\udc45\\ud835\\udc52\\ud835\\udc50\\ud835\\udc4e\\ud835\\udc59\\ud835\\udc59 (7) 4.\",\"142\":\"Results and discussion This section presents the exploratory analysis of the collected data and the main results of the experiments performed in the model development process.\",\"143\":\"4.1.\",\"144\":\"Exploratory Analysis The age, weight, and height features are quantitative of the rational type.\",\"145\":\"Table 5 presents the descriptive statistics of the features.\",\"146\":\"Table 5 Descriptive statictics Statictics Mean S.D.a Minb Q1c Q2d Q3e Maxf Age 24.31 6.35 14.00 19.95 22.78 26.00 61.00 Height 1.70 0.09 1.45 1.63 1.70 1.77 1.98 Weight 86.59 26.19 39.00 65.47 83.00 107.43 173.00 a) S.D.: Standard deviation, b) MIN: Minimun, c) Q1: First quartile, d) Q2: Second quartile (median), e) Q3: Third quartile, f) MAX: Maximun.\",\"147\":\"Additionally, Figure 4 shows the data distribution of the numerical features.\",\"148\":\"(A) Age (B) Height (C) Weight Figure 4: Distribution of the numerical features The age data used for this work ranged from 14 to 61 years of age, with a mean age of 24 years.\",\"149\":\"The mean height of the data collected was 1.7 (m.), the range was 1.45 (m.) as a minimum and 1.98 (m.) as a maximum.\",\"150\":\"The data collected related to weight ranged from 39.00 (kg.)\",\"151\":\"to 173.00 (kg.\",\"152\":\"), and the mean weight was 86.59 (kg.\",\"153\":\"), Table 5.\",\"154\":\"The target feature of the classes was calculated using the weight and height of each instance with Equation (1).\",\"155\":\"Figure 5 shows the distribution of the calculated BMI values.\",\"156\":\"BMI Figure 5: Distribution of the BMI The calculated BMI values ranged from 13.00 to 50.81, with a mean equal to 29.70 and a standard deviation of 8.01.\",\"157\":\"In Figure 6 of the number of instances per class of the target feature, it is observed that the classes of the collected dataset were unbalanced, as the pre-obesity class (26.8%) has the largest number of instances.\",\"158\":\"Figure 6: Target feature classes 4.2.\",\"159\":\"Experiments and evaluation The experiments were carried out with 14 features of the data set, variables such as: n_gender, n_age, c_FMOW, c_ECFF, c_EVM, c_MMHD, c_EFBM, c_SMOKE, c_WDRD, c_DRAL, c_MCED, c_HPHA, c_TTEC, and c_TRANSP (Table 3).\",\"160\":\"The weight and height features were used to calculate the BMI, and also to classify each instance.\",\"161\":\"In the data transformation process, the characteristics of c_MMHD, c_WDRD, c_HPHA, c_TTEC and c_TRANSP were decomposed into dummy variables.\",\"162\":\"The age feature was normalized so that the 0 200 400 600 800 1000 19 23 28 33 38 42 47 52 56 61 0 100 200 300 400 1.50 1.56 1.61 1.66 1.72 1.77 1.82 1.87 1.93 1.98 0 100 200 300 400 52.4 65.8 79.2 92.6 106.0 119.4 132.8 146.2 159.6 173.0 0 200 400 16.8 20.6 24.3 28.1 31.9 35.7 39.5 43.2 47.0 50.8 268 338 368 566 300 271 0 100 200 300 400 500 600 Obesity class III Obesity class II Obesity class I Pre-obesity Normal weight Underweight \\fdifference between the ranges of each feature does not affect the performance of the model.\",\"163\":\"Furthermore, class balancing was only applied in the training set, since the target feature has 6 unbalanced classes (see Table 4 and Figure 6).\",\"164\":\"In the training and evaluation process, eight machine learning methods were tested (subsection 3.3).\",\"165\":\"The prediction of the tested models were internally validated by 10-fold cross-validation.\",\"166\":\"On the other hand, the Random Search method was used to find the best combinations of hyperparameters for each of the tested models.\",\"167\":\"Table 6 presents the optimal hyperparameters for each model.\",\"168\":\"Table 6 Hyperparameters of the models Models Hyperparameters Decision tree splitter: 'best', min_samples_split: 2, min_samples_leaf: 1, criterion: 'entropy' Support vector machines C: 90.11, break_ties: True, kernel: 'linear', probability: False, shrinking: True, tol: 0.51 K-Nearest Neighbors weights: 'distance', p: 1, n_neighbors: 2, leaf_size: 8, algorithm: 'kd_tree' Gaussian Naive Bayes var_smoothing: 0.0009 Multilayer Perceptron tol: 0.01, solver: 'lbfgs', shuffle: True, max_iter: 530, learning_rate_init: 0.30, learning_rate: 'invscaling', alpha': 0.69, activation: 'relu' Random forest n_estimators: 390, min_samples_split: 8, min_samples_leaf: 1, criterion: 'gini', bootstrap: False Gradient Boosting loss: 'deviance', criterion: 'mse' Extreme Gradient Boosting 'booster': 'gbtree', 'eta': 0.0033752879456183816, gamma: 1, predictor: 'cpu_predictor', tree_method: 'approx' Figure 7 shows the performance behavior in each fold, according to the metrics of accuracy, precision, recovery, and F1-score.\",\"169\":\"DT SVM KNN GNB MLP RF GB XGB (A) Accuracy (B) Precision (C) Recall (D) F1-score Figure 7: Performance of models tested with cross-validation (10-folds) 35 45 55 65 75 85 1 2 3 4 5 6 7 8 9 10 45 55 65 75 85 1 2 3 4 5 6 7 8 9 10 45 55 65 75 85 1 2 3 4 5 6 7 8 9 10 40 50 60 70 80 90 1 2 3 4 5 6 7 8 9 10 \\fFigure 7 shows that each model generated with cross-validation showed a different behavior, according to each subset of data from each fold.\",\"170\":\"The models that presented a greater variation in their performance values in each fold, according to the metrics considered, were the gaussian naive bayes (GNB) and multilayer perceptron (MLP) models.\",\"171\":\"Additionally, Table 7 present the mean performance values of the trained models.\",\"172\":\"Table 7 Mean performance values of the models Models Accuracy (CI95% a ) Precision (CI95%) Recall (CI95%) F1-score (CI95%) Decision Tree 72.62 (\\u00b11.49) 73.33 (\\u00b11.49) 73.43 (\\u00b11.49) 73.11 (\\u00b11.47) Support Vector Machines 59.45 (\\u00b11.03) 62.55 (\\u00b11.44) 64.24 (\\u00b10.94) 60.83 (\\u00b10.94) K-Nearest Neighbors 67.69 (\\u00b11.67) 68.37 (\\u00b12.23) 66.70 (\\u00b11.66) 66.44 (\\u00b11.53) Gaussian Naive Bayes 46.24 (\\u00b12.48) 51.70 (\\u00b12.84) 53.33 (\\u00b12.41) 45.55 (\\u00b12.58) Multilayer Perceptron 63.77 (\\u00b14.65) 65.11 (\\u00b14.66) 66.60 (\\u00b14.17) 65.05 (\\u00b14.69) Random Forest 77.69 (\\u00b11.52) 78.53 (\\u00b11.25) 78.15 (\\u00b11.69) 78.09 (\\u00b11.52) Gradient Boosting 73.43 (\\u00b11.88) 74.34 (\\u00b11.85) 75.67 (\\u00b11.85) 74.45 (\\u00b11.69) Extreme Gradient Boosting 70.06 (\\u00b11.21) 71.10 (\\u00b11.34) 73.51 (\\u00b11.23) 71.37 (\\u00b11.11) (a) CI95%: Confidence interval The results of Table 7 show that the gaussian naive bayes model presented the lowest performance values, compared to the other models.\",\"173\":\"On the other hand, the extreme gradient boosting, decision tree, gradient boosting, and gradient boosting models showed better performance, with values higher than 70% in the evaluated metrics.\",\"174\":\"The model with the best performance in all the metrics evaluated was the random forest (final model selected), with 77.69% (\\u00b11.52) accuracy, 78.53% (\\u00b11.25) precision, 78.15% (\\u00b11.69) recall, and 78.09% (\\u00b11.52) F1-score.\",\"175\":\"The random forest model selected even obtained values that surpass the results obtained in other similar researches where obesity was analysed with features associated with eating habits and physical condition, such as the study by Tharmin et al. [17] who selected the logistic regression model as the best, generating 72% accuracy and 69% precision, and Wang et al. [20] with 70.77% accuracy in the SVM model selected.\",\"176\":\"Finally, the final model was tested with real data, to identify people with obesity or overweight.\",\"177\":\"Figure 8 shows each of the data entered in the final model and its respective prediction for each query made.\",\"178\":\"(A) First query with real data (B) Second query with real data Figure 8: Model predictions with real data.\",\"179\":\"The BMI for each interviewee was calculated manually, to check the classes predicted by the classification model.\",\"180\":\"From Figure 8(A), the weight and height of the 53-year-old interviewee were 65 kg and 1.57 m, respectively.\",\"181\":\"The BMI of the first interviewee was 26.37 kg\\/m2 , which according to \\fTable 4 is classified as pre-obesity.\",\"182\":\"The weight and height of the 31-year-old interviewee were 75 kg and 1.74 m respectively, and the BMI = 24.77 kg\\/m2 , which is classified as normal weight (Figure 8(B)).\",\"183\":\"Therefore, these results show that the values obtained with the model and those calculated manually were the same.\",\"184\":\"5.\",\"185\":\"Conclusion Overweight and obesity are considered an epidemiological problem since it is related to various diseases such as hypertension, type 2 diabetes mellitus, osteoarthritis, stroke, some types of cancer, and even death.\",\"186\":\"At the global level, the prevalence of overweight and obesity has increased considerably, and it is estimated that by 2030 the global prevalence of overweight will increase to around 50%.\",\"187\":\"Preventing obesity is not an easy task as it requires the intervention of government, industry, and specialists in the area.\",\"188\":\"Thus, curbing overweight and its effects requires important changes in the population's lifestyle, mainly in physical activity and eating habits.\",\"189\":\"In this context, thanks to technological advances, there are currently tools such as artificial intelligence and machine learning that can be used as support for the prevention and identification of people with overweight and obesity.\",\"190\":\"Machine learning models can be used as an advantage in the medical field since specialists in the area can make use of these tools as a support tool for decisionmaking.\",\"191\":\"In this work, eight machine learning models were tested, such as decision tree, support vector machines, k-nearest neighbors, gaussian naive bayes, multilayer perceptron, random forest, gradient boosting, and extreme gradient boosting, to develop an intelligent model for the identification of people with obesity or overweight, which will serve as support in the decision-making to specialists in the area.\",\"192\":\"On the other hand, the data used for the development of the model were collected through a survey, in which information related to the eating habits and physical activity of the interviewees was collected.\",\"193\":\"The database labeling was performed based on the BMI classification table, in which the weight and height of each instance were used.\",\"194\":\"Furthermore, 10-fold cross-validation was used and the hyperparameters of the tested models were optimized.\",\"195\":\"The results showed that the random forest model obtained the best results in the performance metrics, with 77.69% accuracy, 78.53% precision, 78.15% recall, and 78.09% F1-score.\",\"196\":\"Other tested models that obtained values in the performance metrics higher than 70% were extreme gradient boosting (70.06% accuracy), decision tree (72.62% accuracy), and gradient boosting (73.43% accuracy).\",\"197\":\"Finally, machine learning models showed good performance for BMI classification, even when data related to diet and eating habits were used.\",\"198\":\"The models developed demonstrated that machine learning is a powerful tool that can be used in the medical field to make decisions for timely treatment for people at risk of obesity.\",\"199\":\"6.\",\"200\":\"Acknowledgements This research was supported by the Coordination for the Improvement of Higher Education Personnel [CAPES - 001].\",\"201\":\"7.\",\"202\":\"References [1] World Health Organization (WHO), Obesity and overweight, 2021. URL: https:\\/\\/www.who.int\\/news-room\\/fact-sheets\\/detail\\/obesity-and-overweight.\",\"203\":\"[2] H. Rosen, \\u201cIs Obesity A Disease or A Behavior Abnormality?\",\"204\":\"Did the AMA Get It Right?\\u201d.\",\"205\":\"Missouri medicine, 111(2014): 104\\u2013108.\",\"206\":\"[3] M. Bl\\u00fcher, \\u201cObesity: global epidemiology and pathogenesis\\u201d.\",\"207\":\"Nature Reviews Endocrinology, 15(2019): 288\\u2013298.\",\"208\":\"doi: 10.1038\\/s41574-019-0176-8.\",\"209\":\"[4] World Health Organization (WHO), Body mass index\\u2013BMI, 2020. URL: https:\\/\\/www.euro.who.int\\/en\\/health-topics\\/disease-prevention\\/nutrition\\/a-healthy-lifestyle\\/bodymass-index-bmi \\f[5] T. Bhurosy, R. Jeewon, \\u201cOverweight and obesity epidemic in developing countries: a problem with diet, physical activity, or socioeconomic status?\\u201d.\",\"210\":\"The Scientific World Journal, (2014).\",\"211\":\"doi:10.1155\\/2014\\/964236.\",\"212\":\"[6] A. Alami, A. Jafari, Z. Hosseini, \\u201cDifferences in overweight\\/obesity prevalence by demographic characteristics and self-weight misperception status\\u201d.\",\"213\":\"Clinical Nutrition ESPEN, 41(2021): 249\\u2013 253.\",\"214\":\"doi:10.1016\\/j.clnesp.2020.12.005.\",\"215\":\"[7] World Health Organization (WHO), NCD risk factors: Overweight \\/ Obesity, 2021. URL:https:\\/\\/www.who.int\\/data\\/gho\\/data\\/themes\\/topics\\/indicator-groups\\/indicator-groupdetails\\/GHO\\/overweight-obesity.\",\"216\":\"[8] T. Kelly, W. Yang, C.-S. Chen, K. Reynolds, J. He, \\u201cGlobal burden of obesity in 2005 and projections to 2030\\u201d.\",\"217\":\"International Journal of Obesity, 32(2008): 1431\\u20131437.\",\"218\":\"[9] R. Mehrzad, \\u201cDefinition and introduction to epidemiology of obesity\\u201d.\",\"219\":\"Obesity, (2020): 1\\u20136.\",\"220\":\"doi:10.1016\\/b978-0-12-818839-2.00001-6.\",\"221\":\"[10] Y.C. Chooi, C. Ding, F. Magkos, \\u201cThe epidemiology of obesity\\u201d.\",\"222\":\"Metabolism, 96(2018):6\\u201310.\",\"223\":\"doi: 10.1016\\/j.metabol.2018.09.005 [11] The Lancet Diabetes and Endocrinology, \\u201c Tackling obesity in 2020\\u2014with a great resolution comes shared responsibility\\u201d.\",\"224\":\"The Lancet Diabetes & Endocrinology, (2020).\",\"225\":\"doi:10.1016\\/s22138587(20)30001-2.\",\"226\":\"[12] T.M. Dugan, S. Mukhopadhyay, A. Carroll, S. Downs, \\u201cMachine learning techniques for prediction of early childhood obesity\\u201d.\",\"227\":\"A pplied Clinical Informatics, 6(2015):506\\u2013520.\",\"228\":\"doi: 10.4338\\/ACI-2015-03-RA-0036.\",\"229\":\"[13] K.W. DeGregory et al., \\u201cA review of machine learning in obesity\\u201d.\",\"230\":\"Obesity Reviews, 19(2018):668\\u2013685.\",\"231\":\"doi: 10.1111\\/obr.12667.\",\"232\":\"[14] E. De-La-Hoz-Correa et al., \\u201cObesity Level Estimation Software based on Decision Trees\\u201d.\",\"233\":\"Journal of Computer Science, 15 (2019): 67\\u201377.\",\"234\":\"doi:10.3844\\/jcssp.2019.67.77.\",\"235\":\"[15] M.I. Jordan, T.M., \\u201cMitchell, Machine learning: Trends, perspectives, and prospects\\u201d.\",\"236\":\"Science, 349(2015):255\\u2013260.\",\"237\":\"doi: 10.1126\\/science.aaa8415.\",\"238\":\"[16] S.N. Kumar, P. Saxena, R. Patel, A. Sharma, D. Pradhan, H. Singh et al., \\u201cPredicting risk of low birth weight offspring from maternal features and blood polycyclic aromatic hydrocarbon concentration\\u201d.\",\"239\":\"Reproductive Toxicology, 94(2020):92\\u2013100.\",\"240\":\"doi: 10.1016\\/j.reprotox.2020.03.009.\",\"241\":\"[17] S.A. Thamrin, D.S. Arsyad, H. Kuswanto, A. Lawi, S. Nasir, \\u201cPredicting Obesity in Adults Using Machine Learning Techniques: An Analysis of Indonesian Basic Health Research 2018\\u201d.\",\"242\":\"Frontiers in Nutrition, 8(2021).\",\"243\":\"doi:10.3389\\/fnut.2021.669155.\",\"244\":\"[18] J. Dunstan, M. Aguirre, M. Bast\\u00edas, C. Nau, T.A. Glass, F. Tobar, \\u201cPredicting nationwide obesity from food sales using machine learning\\u201d.\",\"245\":\"Health Informatics Journal, 26(2020):652\\u2013663.\",\"246\":\"doi:10.1177\\/1460458219845959.\",\"247\":\"[19] I. Machorro-Cano, G. Alor-Hern\\u00e1ndez, M.A. Paredes-Valverde, U. Ramos-Deonati, J.L. S\\u00e1nchezC ervantes, L. Rodr\\u00edguez-Mazahua, \\u201cPISIoT: A machine learning and IoT-based smart health platform for overweight and obesity control\\u201d.\",\"248\":\"Applied Sciences, 9(2019).\",\"249\":\"doi: 10.3390\\/app9153037.\",\"250\":\"[20] H.-Y. Wang et al. \\u201cMachine learning-based method for obesity risk evaluation using singlenucleotide polymorphisms derived from next-generation sequencing\\u201d.\",\"251\":\"Journal of Computational Biology, 25(2018):1347\\u20131360.\",\"252\":\"doi:10.1089\\/cmb.2018.0002.\",\"253\":\"[21] V. Kotu and B. Deshpande, \\u201cChapter 3 - data exploration,\\u201d in Data Science (Second Edition), second edition ed., V. Kotu and B. Deshpande, Eds.\",\"254\":\"Morgan Kaufmann, 2019:39\\u201364.\",\"255\":\"[22] S. Jain, S. Shukla, and R. Wadhvani, \\u201cDynamic selection of normalization techniques using data complexity measures\\u201d.\",\"256\":\"Expert Systems with Applications, 106(2018):252\\u2013262.\",\"257\":\"doi:10.1016\\/j.eswa.2018.04.008.\",\"258\":\"[23] S. Marsland, Machine Learning: An Algorithmic Perspective, 2015.\",\"259\":\"6000 Broken Sound Parkway NW, Suite 300, Boca Raton: Taylor and Francis Group, LLC.\",\"260\":\"[24] E. Alpaydim, Introduction to Machine Learning, 2004.\",\"261\":\"Cambridge, Massachusetts, London, England: The MIT Press.\",\"262\":\"[25] S. Dreiseitl and L. Ohno-Machado, \\u201cLogistic regression and artificial neural network classification models: a methodology review\\u201d.\",\"263\":\"Journal of Biomedical Informatics, 25(2002), 352\\u2013359.\",\"264\":\"doi:10.1016\\/S1532-0464(03)00034-0.\",\"265\":\"[26] M. Bublyka, V. Lytvyna, V. Vysotskaa, L. Chyrunb, Y. Matseliukha, N. Sokulskac , \\u201cThe Decision Tree Usage for the Results Analysis of the Psychophysiological Testing\\u201d.\",\"266\":\"The 3rd Conference on Informatics and Data-Driven Medicine (IDDM 2020), 2753(2020): 458\\u2013472.\",\"267\":\"[27] J. Wu, J. Roy, and W. F. Stewart, \\u201cPrediction modeling using EHR data: challenges, strategies, and a comparison of machine learning approaches\\u201d.\",\"268\":\"Medical Care, 48(2010):S106\\u2013S113.\",\"269\":\"doi: 10.1097\\/MLR.0b013e3181de9e17.\",\"270\":\"[28] N. Boyko, K. Boksho, \\u201cApplication of the Naive Bayesian Classifier in Work on Sentimental Analysis of Medical Data\\u201d.\",\"271\":\"The 3rd Conference on Informatics and Data-Driven Medicine (IDDM 2020), 2753(2020): 230\\u2013239.\",\"272\":\"[29] G. Li and J. Shi, \\u201cOn comparing three artificial neural networks for wind speed forecasting\\u201d.\",\"273\":\"Applied Energy, 87(2010): 2313\\u20132320.\",\"274\":\"doi: 10.1016\\/j.apenergy.2009.12.013.\",\"275\":\"Using Machine Learning to Predict Obesity Based on Genome-Wide and Epigenome-Wide Gene\\u2013Gene and Gene\\u2013Diet Interactions Yu-Chi Lee1 , Jacob J. Christensen2 , Laurence D. Parnell1 , Caren E. Smith3 , Jonathan Shao4 , Nicola M. McKeown5,6 , Jos\\u00e9 M. Ordov\\u00e1s3,7,8 and Chao-Qiang Lai1 * 1 USDA ARS, Nutrition and Genomics Laboratory, JM-USDA Human Nutrition Research Center on Aging at Tufts University, Boston, MA, United States, 2 Department of Nutrition, Norwegian National Advisory Unit on FH, Oslo University Hospital, University of Oslo, Oslo, Norway, 3 Nutrition and Genomics Laboratory, JM-USDA Human Nutrition Research Center on Aging at Tufts University, Boston, MA, United States, 4 Statistical and Bioinformatics Group, Northeast Area, USDA ARS, Beltsville, MD, United States, 5 Nutritional Epidemiology Laboratory, JM-USDA Human Nutrition Research Center on Aging at Tufts University, Boston, MA, United States, 6 Friedman School of Nutrition Science and Policy, Tufts University, Boston, MA, United States, 7 CEI UAM + CSIC, IMDEA Food Institute, Madrid, Spain, 8 Centro Nacional de Investigaciones Cardiovasculares (CNIC), Madrid, Spain Obesity is associated with many chronic diseases that impair healthy aging and is governed by genetic, epigenetic, and environmental factors and their complex interactions.\",\"276\":\"This study aimed to develop a model that predicts an individual\\u2019s risk of obesity by better characterizing these complex relations and interactions focusing on dietary factors.\",\"277\":\"For this purpose, we conducted a combined genome-wide and epigenome-wide scan for body mass index (BMI) and up to three-way interactions among 402,793 single nucleotide polymorphisms (SNPs), 415,202 DNA methylation sites (DMSs), and 397 dietary and lifestyle factors using the generalized multifactor dimensionality reduction (GMDR) method.\",\"278\":\"The training set consisted of 1,573 participants in exam 8 of the Framingham Offspring Study (FOS) cohort.\",\"279\":\"After identifying genetic, epigenetic, and dietary factors that passed statistical signi\\ufb01cance, we applied machine learning (ML) algorithms to predict participants\\u2019 obesity status in the test set, taken as a subset of independent samples (n \\u0001 394) from the same cohort.\",\"280\":\"The quality and accuracy of prediction models were evaluated using the area under the receiver operating characteristic curve (ROC-AUC).\",\"281\":\"GMDR identi\\ufb01ed 213 SNPs, 530 DMSs, and 49 dietary and lifestyle factors as signi\\ufb01cant predictors of obesity.\",\"282\":\"Comparing several ML algorithms, we found that the stochastic gradient boosting model provided the best prediction accuracy for obesity with an overall accuracy of 70%, with ROC-AUC of 0.72 in test set samples.\",\"283\":\"Top predictors of the best-\\ufb01t model were 21 SNPs, 230 DMSs in genes such as CPT1A, ABCG1, SLC7A11, RNF145, and SREBF1, and 26 dietary factors, including processed meat, diet soda, French fries, high-fat dairy, arti\\ufb01cial sweeteners, alcohol intake, and speci\\ufb01c nutrients and food components, such as calcium and \\ufb02avonols.\",\"284\":\"In conclusion, we developed an integrated approach with ML to predict obesity using omics and dietary data.\",\"285\":\"This extends our knowledge of the drivers of obesity, which can inform precision nutrition strategies for the prevention and treatment of obesity.\",\"286\":\"Edited by: Rosita Gabbianelli, University of Camerino, Italy Reviewed by: Irma Silva-Zolezzi, Nestl\\u00e9 Research Center, Singapore Jim Kaput, Independent researcher, Singapore *Correspondence: Chao-Qiang Lai chaoqiang.lai@usda.gov Specialty section: This article was submitted to Nutrigenomics, a section of the journal Frontiers in Genetics Received: 27 September 2021 Accepted: 29 November 2021 Published: 03 January 2022 Citation: Lee Y-C, Christensen JJ, Parnell LD, Smith CE, Shao J, McKeown NM, Ordov\\u00e1s JM and Lai C-Q (2022) Using Machine Learning to Predict Obesity Based on Genome-Wide and Epigenome-Wide Gene\\u2013Gene and Gene\\u2013Diet Interactions.\",\"287\":\"Front.\",\"288\":\"Genet.\",\"289\":\"12:783845.\",\"290\":\"doi: 10.3389\\/fgene.2021.783845 Frontiers in Genetics | www.frontiersin.org January 2022 | Volume 12 | Article 783845 1 ORIGINAL RESEARCH published: 03 January 2022 doi: 10.3389\\/fgene.2021.783845 \\fClinical Trial Registration: [www.ClinicalTrials.gov], the Framingham Heart Study (FHS), [NCT00005121].\",\"291\":\"Keywords: obesity, machine learning, genomics, DNA methylation, diet, GxE interaction, precision nutrition INTRODUCTION Overweight and obesity are primary risk factors for many chronic diseases and health conditions, including cardiovascular diseases, type 2 diabetes (T2D), hypertension, and cancers (GBD 2015 Obesity Collaborators, 2017).\",\"292\":\"The prevalence of obesity has increased greatly over the last decades.\",\"293\":\"According to the World Health Organization (WHO), 39% and 13% of the worldwide adult population was overweight and obese, respectively, in 2016 (World Health Organization, 2021).\",\"294\":\"Up to this point, studies have shown that obesity is determined by genetic, epigenetic, and environmental factors, such as diet and lifestyle, and their complex interactions (Albuquerque et al., 2017).\",\"295\":\"On one hand, candidate gene approaches that consider physiological and molecular development of obesity, genome-wide association studies (GWAS) (Locke et al., 2015), and polygenetic risk scores (PRS) (Belsky et al., 2013) have been utilized to determine the genetic predisposition to obesity.\",\"296\":\"On the other hand, diet and lifestyle behaviors, such as physical activity, are critically modi\\ufb01able factors in determining obesity (Hruby et al., 2016) and are used to develop prevention and treatment strategies.\",\"297\":\"In addition, much nutrigenetics research has been showing the impact of gene-by-environment (GxE) interaction studies in candidate genes, GWAS-identi\\ufb01ed genes (Corella et al., 2007; Corella, 2009; Parnell et al., 2014), or PRS (Qi et al., 2012; Casas-Agustench et al., 2014).\",\"298\":\"The overall goals of this research \\ufb01eld are to predict obesity with precision, to identify modi\\ufb01able factors that change the risk of obesity, and \\ufb01nally to develop effective approaches to prevent and treat obesity.\",\"299\":\"Effective prediction tools are needed to attain these goals.\",\"300\":\"GxE interaction refers to modi\\ufb01cation by an environmental factor of the effect of a genetic variant on a phenotypic trait.\",\"301\":\"GxE interactions can ameliorate the adverse effects of a risk allele to reduce risk or exacerbate the genotype-phenotype relationship and increase risk (Parnell et al., 2014).\",\"302\":\"Incorporating E factors into genetic and epigenetic studies to explore interactions provides potential advantages, such as reducing missing heritability (Visscher et al., 2008; Manolio et al., 2009).\",\"303\":\"GxE research also has highlighted the individual\\u2019s variation in response to interventions by changing environmental factors to prevent or treat obesity.\",\"304\":\"Perhaps, more importantly, examining GxE interactions could support the development of precision medicine.\",\"305\":\"Identifying strategies for modifying E factors that are tailored to an individual\\u2019s speci\\ufb01c genetic background could enhance the effectiveness of interventions that improve health phenotypes.\",\"306\":\"In addition, epigenomic markers, such as DNA methylation, can be interpreted as footprints of environmental exposures (Kadayifci et al., 2018).\",\"307\":\"We included gene (as genotype)-by-DNA methylation site (DMS) interactions in the present study because this can be considered as another type of GxE interactions on a broader scale.\",\"308\":\"The evolution of omics technology and data, such as GWAS (Locke et al., 2015) and epigenome-wide association studies (EWAS) (Sayols-Baixeras et al., 2017; Wahl et al., 2017), not only has generated a vast amount of data but also deepened our characterization of complex diseases, including obesity and its related traits.\",\"309\":\"Furthermore, applying machine learning (ML) methods to largeand high-dimensional data provided an opportunity to explore the complex data patterns and structure and to predict disease phenotypes (Degregory et al., 2018; Dogan et al., 2018), and such research is still emerging.\",\"310\":\"Thus, this study aimed to develop an integrated ML approach to incorporate omics data, lifestyle features with consideration of their interactions, i.e., GxG and GxE, to predict any individual\\u2019s overweight and obesity status using data collected in exam 8 of the Framingham Heart Study Offspring (FOS) cohort.\",\"311\":\"MATERIALS AND METHODS Study Samples: Framingham Offspring Study (FOS) Exam 8 Cohort The Framingham Heart Study (FHS) has been described at http:\\/\\/ www.framinghamheartstudy.org\\/about\\/milestones.html.\",\"312\":\"The FHS is a community-based longitudinal study; it recruited participants, who self-identi\\ufb01ed as having European ancestry, in Framingham, MA, beginning in 1948 (Dawber et al., 1951).\",\"313\":\"In 1971, the FOS then recruited the original FHS participants\\u2019 children and spouses (Kannel et al., 1979) and re-interviewed them about every 4\\u20138 years thereafter.\",\"314\":\"In the current study, we utilized data from participants who attended the eighth examination cycle (2005\\u20132008) of the FOS (Generation 2).\",\"315\":\"Participants completed dietary and health assessment questionnaires at that time.\",\"316\":\"These data were obtained from dbGaP (https:\\/\\/dbgap.ncbi.nlm.nih.gov, study accession: phs000007.v25.p9 and phs000007.v28.p10; downloaded on September 27, 2017).\",\"317\":\"The age used was the age of an individual at exam 8.\",\"318\":\"Genome-Wide Genotype Data Genome-wide single nucleotide polymorphism (SNP) genotype and imputed data from FHS were downloaded from dbGaP (accession: phs000342.v18.p11) with initial quality control (QC).\",\"319\":\"In brief, \\u223c500,000 SNPs were genotyped on the Affymetrix GeneChip\\u00ae Human Mapping 500K Array (Santa Clara, CA) and \\ufb01ltered at the sample and SNP level.\",\"320\":\"QC steps have been described in detail (Liu et al., 2020).\",\"321\":\"SNP IDs, loci, and allelic information were annotated using the 1,000 Genomes Phase 3 downloaded from dbSNP (downloaded date: April 13, 2018) and human genome build GRCh37\\/hg19.\",\"322\":\"After these QC steps, 1,967 individuals and 402,793 SNPs remained.\",\"323\":\"Data were processed using PLINK 1.9 (URL: www.cog-genomics.org\\/plink\\/ 1.9\\/) and 2.0 (URL: www.cog-genomics.org\\/plink\\/2.0\\/) (Chang et al., 2015) and Golden Helix\\u00ae, and genotypes were coded as 0, 1, or 2.\",\"324\":\"The dosages of imputed SNPs were also categorized as tertile categories and coded as 0, 1, and 2 when used as input data during Frontiers in Genetics | www.frontiersin.org January 2022 | Volume 12 | Article 783845 2 Lee et al. Obesity Prediction Using Machine Learning \\fthe feature selection step, i.e., generalized multifactor dimensionality reduction (GMDR).\",\"325\":\"For ML model training and testing, we used original values.\",\"326\":\"Genome-Wide DNA Methylation Data Genome-wide DNA methylation was pro\\ufb01led using Illumina In\\ufb01nium\\u00ae HumanMethylation450 BeadChip (San Diego, CA) in whole blood DNA.\",\"327\":\"DNA methylation data were downloaded from dbGaP (accession: phs000724.v9.p13).\",\"328\":\"Raw IDAT \\ufb01les were processed for QC as described (Lai et al., 2018).\",\"329\":\"A \\u03b2 score (proportion of the total methylation-speci\\ufb01c signal) was used to measure the methylation signal at each methylation site, and the detection p-value was the probability that the total intensity for a given probe fell within the background signal intensity.\",\"330\":\"We excluded any CpG probe with a detection p-value > 0.01 and missing sample percentage >1.5% or >10% of samples lacking suf\\ufb01cient intensity.\",\"331\":\"We adjusted batch effects across samples and normalized the \\u03b2 scores using the ComBat function in the ChAMP package in R (Morris et al., 2014).\",\"332\":\"To account for the heterogeneity of different cell types across samples, \\u03b2 scores of all \\ufb01ltered autosomal CpG sites were used to calculate principal components, using the prcomp function in R (v12.12.1), and the \\ufb01rst \\ufb01ve principal components were used in all subsequent analyses.\",\"333\":\"This method was used and is similar to a previous study (Irvin et al., 2014).\",\"334\":\"After these QC steps, 1,967 individuals and 415,202 DMSs remained.\",\"335\":\"The normalized \\u03b2 scores of all DMSs were categorized as tertile categories and coded as 0 (lowest), 1, and 2 (highest) when used as input data during the feature reduction step, i.e., GMDR.\",\"336\":\"For ML model training and testing, we used original values.\",\"337\":\"The annotation was based on human genome build GRCh37\\/hg19.\",\"338\":\"BMI and Categorization of Weight Status We used body mass index (BMI) to classify overweight and obesity in adults.\",\"339\":\"It is de\\ufb01ned as a person\\u2019s weight in kilograms divided by the square of the height in meters (kg\\/ m2 ).\",\"340\":\"BMI \\u226525 kg\\/m2 was de\\ufb01ned and coded as overweight or obesity (n \\u0001 1,403; 71% of n \\u0001 1,967) and BMI \\u226530 kg\\/m2 as obesity (n \\u0001 591; 30% of n \\u0001 1,967).\",\"341\":\"Dietary and Other Lifestyle Factors Measurement Usual dietary intake for the previous year was assessed among 2,245 adult men and women in the FOS.\",\"342\":\"Foods and nutrients were derived from the 126-item modi\\ufb01ed Willett semi-quantitative food frequency questionnaire (FFQ) at exam 8 of the FOS (Dawber et al., 1951; Rimm et al., 1992; Feskanich et al., 1993).\",\"343\":\"The FFQ allowed participants to name \\u22644 extra food items that were essential parts of their diets but were not offered among the 126 items.\",\"344\":\"Energy intake was considered implausible and excluded if a participant reported energy intake was <2.51 MJ\\/day (600 kcal\\/day) for men and women or >16.74 MJ\\/day (4,000 kcal\\/day) for women and >17.57 MJ\\/day (4,200 kcal\\/day) for men or if >12 food items were left blank, consistent with the criteria as previously published in the FHS.\",\"345\":\"The energy composition for macronutrients (% from total energy intake) was calculated, and the food items were summarized into 31 food groups.\",\"346\":\"Three diet quality indices were calculated to capture dietary patterns: (1) the Alternate Healthy Eating Index (AHEI) score identi\\ufb01ed by factor analysis, (2) the Mediterranean diet score (MDS), and (3) the Dietary Approaches to Stop Hypertension (DASH) diet score.\",\"347\":\"All lifestyle factors, such as alcohol drinking, smoking, and physical activity [through a standard exercise questionnaire (Kannel and Sorlie, 1979)], were available on individuals at exam 8 of the FOS.\",\"348\":\"A total of 397 dietary and lifestyle variables were converted into tertile categories and coded as 0 (lowest), 1, and 2 (highest) as input data during the feature reduction step, i.e., GMDR.\",\"349\":\"For ML model training and testing, we used original values.\",\"350\":\"Machine Learning We used supervised binary classi\\ufb01cation ML models to predict an outcome variable (e.g., overweight or obese yes or no; obese yes or no).\",\"351\":\"The overall \\ufb02owchart of ML procedures applied in the present study is illustrated in Figure 1.\",\"352\":\"Training and Testing Data Sets We derived a \\ufb01nal analytic data set of 1,967 Caucasian participants (45% women), aged 40\\u201392 years, who participated in the eighth examination visit of the FOS and had complete data for related demographic, anthropometric, clinical, genetic, epigenetic, dietary, and other lifestyle [alcohol, smoking, and physical activity (Kiely et al., 1994)] variables and covariates.\",\"353\":\"Missing values for some variables were \\ufb01lled using median imputation.\",\"354\":\"Samples were split into a training set (80%) and a test set (20%) by applying systematic random sampling.\",\"355\":\"The PROC SURVEYSELECT procedure and METHOD \\u0001 SYS (SAS 9.4 for Windows, SAS Institute Inc., Cary, NC, USA) were used to control values of BMI and age within the sex ratio, T2D, and use of lipid-lowering medication.\",\"356\":\"The demographics of individuals included in the training and testing data sets in this study are summarized in Table 1.\",\"357\":\"Feature Selection Using the Generalized Multifactor Dimensionality Reduction (GMDR) Method The GMDR method (GMDR software, Windows version) (Xu et al., 2016; Luo et al., 2017) was applied to the training data set to perform a genome-wide and epigenome-wide scan to detect main effects and three-way GxG and GxE interactions for determining BMI.\",\"358\":\"The GMDR training stage searched attribute combinations with the highest training accuracies.\",\"359\":\"Furthermore, this training performed permutation tests for selected attribute combinations and calculated p values based on testing accuracies.\",\"360\":\"This method was implemented to reduce high-dimensional features for subsequent ML steps (10-fold cross-validation (CV), n < 1,000, permutation testing p < 0.001).\",\"361\":\"Genotype, DNA methylation, and dietary and other lifestyle data were coded as 0, 1, and 2 as discrete input features to predict the BMI (as a continuous variable) using age, sex, and the \\ufb01rst \\ufb01ve principal components for DNA methylation as covariates.\",\"362\":\"We ran this procedure \\ufb01ve times and collected the union of selected features for the following ML steps.\",\"363\":\"Phenotype Prediction Using Machine Learning Methods Three sampling-based supervised ML classi\\ufb01cation algorithms were used to evaluate performance in classifying overweight and Frontiers in Genetics | www.frontiersin.org January 2022 | Volume 12 | Article 783845 3 Lee et al. Obesity Prediction Using Machine Learning \\fobesity: boot-strapped trees (treebag), random forest (ranger), and stochastic gradient boosting machines (gbm).\",\"364\":\"These algorithms were used to generalize the relationship between input features and the labeled examples (output) from the training data and to apply this learning to the prediction of class labels of unseen samples in the test set.\",\"365\":\"Using the same training data set, we built, tuned, and compared the following models using the caret package and other required packages in RStudio (version 1.3).\",\"366\":\"Caret-automated parameter tuning was used for selecting hyperparameters to establish for each classi\\ufb01er, and a grid of tuning parameters was de\\ufb01ned using the expand.grid function.\",\"367\":\"For ranger, mtry, min.node.size, and splitrule were used to set tuning parameters in an optimal range; for gbm, n.trees, interaction.depth, shrinkage, and n.minobsinode were set to search for the best model in the training set.\",\"368\":\"Undersampling, over-sampling, or synthetic minority oversampling technique (SMOTE) sampling methods were also introduced to address class imbalance.\",\"369\":\"Five repeats of 10-fold CV were set for building the model.\",\"370\":\"The best predictive models from each algorithm were assessed using the area under the curve of the receiver operating characteristic curve (ROC-AUC).\",\"371\":\"We compared different learning algorithms by using the resamples function using the training data set.\",\"372\":\"We then applied the best model to predict the binary overweight or obesity status in the test data set.\",\"373\":\"The confusion matrix was used to present the overall accuracy, sensitivity, and speci\\ufb01city observed in the testing set samples, which then evaluates the performance of each prediction model.\",\"374\":\"Accuracy is the total proportion of correct predictions of all the predicted data.\",\"375\":\"Sensitivity is the proportion of real positives that are predicted as positives; speci\\ufb01city is the proportion of real negatives that are predicted as negatives.\",\"376\":\"The sensitivity was plotted against 1-speci\\ufb01city to generate the ROC curve.\",\"377\":\"Network and Pathway Enrichment Analysis To identify the enriched pathways of nearby genes of selected SNPs and DMSs, the web-based protein association database STRING (version 11.5) (Szklarczyk et al., 2021) was used to explore possible functionalities of the GMDR-selected features.\",\"378\":\"This tool includes Gene Ontology (GO) enrichment and Kyoto Encyclopedia of Genes and Genomes (KEGG) pathway analyses.\",\"379\":\"RESULTS Cohort Characteristics Overall, 71.3% of the FOS study participants were either overweight or obese; 30% of study participants were obese in both training (n \\u0001 1,573) and test sets (n \\u0001 394) (Table 1).\",\"380\":\"The prevalence of obesity-related phenotypes was matched between the two data sets (Table 1).\",\"381\":\"For environmental factors, there were no statistically signi\\ufb01cant differences in the total energy intake and physical activity score (Table 1).\",\"382\":\"Features Selected Using the GMDR Method We used the GMDR method in the training set to conduct a combined genome-wide and epigenome-wide scan for main effects and up to three-way interactions (\\u223c5.5 \\u00d7 1017 combinations) among all pre-\\ufb01ltered 402,793 SNPs, 415,202 DMSs, and 397 dietary and lifestyle factors.\",\"383\":\"The GMDR method identi\\ufb01ed 213 SNPs, 530 DMSs, and 49 dietary and lifestyle factors that were signi\\ufb01cant predictors of obesity (permutation testing p < 0.001).\",\"384\":\"The complete list of selected features is presented in Supplementary Table S1.\",\"385\":\"Among 213 GMDR-selected SNP features, there were 131 independent clumped loci based on the PLINK 1.9 clumping function using the greedy algorithm for clumping with linkage FIGURE 1 | Phenotype prediction data analysis procedure (pipeline).\",\"386\":\"Frontiers in Genetics | www.frontiersin.org January 2022 | Volume 12 | Article 783845 4 Lee et al. Obesity Prediction Using Machine Learning \\fdisequilibrium (LD) (r2 < 0.5) and physical distance (>250 kb).\",\"387\":\"A total of 45 independent SNPs located in or near genes, such as STXBP6, BBX, PLXDC2, PCDH15, TPH2, PCDH15, CALN1, FGF14, LRRN1, ACTBP2, RBMXP1, and ZNF32, were previously reported to be associated with several obesity-related phenotypes and anthropometrics (Locke et al., 2015; Buniello et al., 2019).\",\"388\":\"Among 533 GMDR-selected DMS features, 520 were considered independent signals based on the physical distance and signal correlation.\",\"389\":\"A total of 60 DMS features were found to be associated with BMI and obesity-related phenotypes in other studies (Supplementary Table S1) (Battram et al., 2021).\",\"390\":\"Some DMSs were in proximity to genes, such as CPT1A, ABCG1, SLC7A11, RNF145, and SREBF1, (Mendelson et al., 2017; Wahl et al., 2017; Dhana et al., 2018; Lai et al., 2020) reported to be related to metabolic phenotypes.\",\"391\":\"When using a combined gene list of GMDR-selected SNPs and DMSs for predicting BMI to analyze pathway and network enrichments, protein-protein interaction enrichment was signi\\ufb01cant (p \\u0001 2.65 \\u00d7 10\\u20135 ; p \\u0001 0.00118 when using the top gene list from features of the best-performing model) based on the STRING database (Supplementary Figure S1).\",\"392\":\"Signi\\ufb01cant KEGG pathways, GO terms, and annotated keywords (UniPort) included Ras signaling pathways, Rap1 signaling pathways, and alternative splicing (Benjamini\\u2013Hochberg-adjusted p < 0.05).\",\"393\":\"Analyses of the data also showed associations between selected genes with the blood lipid and glucose metabolism that were identi\\ufb01ed in previous studies.\",\"394\":\"This is entirely plausible because obesity very often coexists with dysregulation of blood lipids and glucose.\",\"395\":\"Overweight and Obesity Prediction Using Different Machine Learning Algorithms\\/ Classi\\ufb01ers We used GMDR-selected features to build ML classi\\ufb01cation models using three different algorithms: boot-strapped trees (treebag), random forest (ranger), and stochastic gradient boosting machines (gbm).\",\"396\":\"After obtaining the best model in each algorithm, we recorded 50 model objects and compared the performance of these three algorithms using ROC, sensitivity, and speci\\ufb01city.\",\"397\":\"Overall, the stochastic gradient boosting machines (gbm) repeatedly showed the best performance for both overweight + obesity and obesity outcomes no matter which approaches were used to deal with class imbalance.\",\"398\":\"In general, the mean ROC value for stochastic gradient boosting machines (gbm) was \\u223c0.8 compared to \\u223c0.75 for random forest (ranger) and \\u223c0.70 for boot-strapped trees (treebag) in the training set.\",\"399\":\"Figure 2 shows the differences in the distribution of performance of 50 models among ML algorithms\\/classi\\ufb01ers when applying under-sampling for the obesity status.\",\"400\":\"Finally, we evaluated the overweight and obesity prediction models constructed using various machine learning algorithms in the test set using ROC-AUC, accuracy and sensitivity, and speci\\ufb01city.\",\"401\":\"The stochastic gradient boosting machines (gbm) remained the best model to predict overweight and obesity status in the separate test data set, with ROC-AUC and accuracy values of 0.72 and 0.67, respectively (Table 2 and Figure 3).\",\"402\":\"Depending on different sampling methods used to address class imbalance, the overall accuracy of all models was \\u223c70%.\",\"403\":\"Important Ranking and Annotation of Top Predictors of the Best-Performing Model Top predictors of the best-\\ufb01t model included both genetic and diet-related factors.\",\"404\":\"Compared to SNPs, DMS features predominantly contributed to the best-performing model.\",\"405\":\"In this example, 16 DMSs in genes, such as CPT1A (Mendelson et al., 2017; Wahl et al., 2017; Dhana et al., 2018), ABCG1 (Mendelson et al., 2017; Wahl et al., 2017; Dhana et al., 2018), SLC7A11 (Mendelson et al., 2017; Wahl et al., 2017), RNF145 (Mendelson et al., 2017; Wahl et al., 2017), and SREBF1 (Mendelson et al., 2017; Wahl et al., 2017; Dhana et al., 2018) were reported to be associated with obesity-related phenotypes.\",\"406\":\"Important diet-related factors were processed meat, diet soda, French fries (potato), high-fat dairy, arti\\ufb01cial sweeteners, alcohol intake, and speci\\ufb01c nutrients and food components, such as calcium and \\ufb02avonols.\",\"407\":\"We present the top 50 predictors for determining the overweight and obesity status in the test set using the best model of the stochastic gradient boosting machines algorithm (Table 3).\",\"408\":\"In the presence of individual foods and nutrients, dietary pattern variables did not emerge on top.\",\"409\":\"Prediction Using Simulated Data We further created simulated individual data with different levels of top dietary predictors to observe whether the prediction changes the status of overweight and obesity and at what level of critical predictors switches the prediction class.\",\"410\":\"By changing \\ufb01ve key dietary factors individually, we observed 1.5\\u201319.6% of subjects showing responses in changing obesity risk (Table 4).\",\"411\":\"Processed meat showed the greatest response and followed by high-fat dairy and calcium intake.\",\"412\":\"Overall, about 21.5% of subjects showed responses to at least one dietary change based on simulation.\",\"413\":\"TABLE 1 | General characteristics of the FOS.\",\"414\":\"FOS Training set Testing set N 1,573 394 Men\\/women, n (% in women) 700\\/873 (55.5%) 178\\/216 (54.8%) Age, y 66.3 \\u00b1 8.9 66.5 \\u00b1 8.7 BMI, kg\\/m2 28.1 \\u00b1 5.3 28.0 \\u00b1 5.2 Overweight and obesity, n (%) 1,122 (71.3%) 281 (71.3%) Obesity, n (%) 473 (30.1%) 118 (30.0%) Smoker, n (%) 115 (7.3%) 26 (6.6%) Drinker, n (%) 1,205 (76.6%) 321 (81.5%) Type 2 diabetes, n (%) 210 (13.4%) 53 (13.5%) Hypertension, n (%) 858 (54.5%) 221 (56.1%) Type 2 diabetes medication, n (%) 160 (10.2%) 39 (9.9%) Hypertension medication, n (%) 756 (48.1%) 196 (49.7%) Lipid-lowering medication, n (%) 682 (43.4%) 171 (43.4%) Total energy intake, kcal\\/d 1,873 \\u00b1 629 1,875 \\u00b1 636 Physical activity score 37.7 \\u00b1 6.4 37.6 \\u00b1 5.8 All continuous variables were presented as mean \\u00b1 SD. Frontiers in Genetics | www.frontiersin.org January 2022 | Volume 12 | Article 783845 5 Lee et al. Obesity Prediction Using Machine Learning \\fDISCUSSION We present an ML-based predictive method using genome-wide SNPs, DMSs, and dietary information including up to three-way interactions among these elements to predict obesity.\",\"415\":\"Among ML algorithms, the stochastic gradient boosting model provided the best prediction accuracy for obesity in the training set and overall accuracy of 70% and ROC-AUC of 0.72 in the test set.\",\"416\":\"In each model, predictors of overweight and obesity were identi\\ufb01ed.\",\"417\":\"To our knowledge, this is the \\ufb01rst study to predict obesity using ML approaches that integrate omics and dietary information in the \\ufb01eld of nutrigenetics.\",\"418\":\"While previous studies have used genomics and\\/or epigenomics to predict obesity or other diseases (Dogan et al., 2018; Cho et al., 2021), we further integrated lifestyle data with genomic and DNA methylation epigenomic data and considered their interactions by applying the GMDR method.\",\"419\":\"By identifying the predictors, our results extend our knowledge about the etiology of obesity.\",\"420\":\"More importantly, selected lifestyle features can inform precision FIGURE 2 | Receiver operating characteristic (ROC) curves and their corresponding AUC values for different machine learning algorithms using 50 sample model objects for obesity status in the training data set of the FOS (n \\u0001 1,573).\",\"421\":\"All models were based on continuous input variables and under-sampling approach.\",\"422\":\"TABLE 2 | Performance metrics of overweight and obesity prediction models constructed using various machine learning algorithms in the test data set of the FOS.\",\"423\":\"Model\\/algorithm ROC-AUC Sensitivity Speci\\ufb01city Accuracy Overweight and obesity Boot-strapped trees (treebag) 0.65 0.64 0.62 0.63 Random forest (ranger) 0.68 0.63 0.64 0.63 Stochastic gradient boosting machines (gbm) 0.72 0.65 0.71 0.67 Obesity Boot-strapped trees (treebag) 0.65 0.63 0.62 0.62 Random forest (ranger) 0.66 0.53 0.65 0.61 Stochastic gradient boosting machines (gbm) 0.67 0.51 0.68 0.63 All models were based on continuous input variables and under-sampling approach.\",\"424\":\"The best metrics in each column are shown in bold.\",\"425\":\"Frontiers in Genetics | www.frontiersin.org January 2022 | Volume 12 | Article 783845 6 Lee et al. Obesity Prediction Using Machine Learning \\fnutrition strategies for the prevention and treatment of obesity by offering options for lifestyle improvement that can be tailored to the individual.\",\"426\":\"We illustrated this concept using simulated data (Table 4).\",\"427\":\"Our results suggested that individuals would respond to different treatment approaches depending on the individuals\\u2019 genetic and epigenetic background.\",\"428\":\"With this in mind, it is conceivable that by modifying these top potential \\u201cobesogenic\\u201d predictors tailored to the individual\\u2019s genome and epigenome, the risk of obesity can be reduced at the level of the individual.\",\"429\":\"Genome-wide association and gene\\u2013lifestyle interaction studies made it clear that genetic factors predispose individuals to obesity, but such susceptibility can be attenuated by healthy lifestyle choices.\",\"430\":\"In the current study, we have identi\\ufb01ed diverse diet-related factors that contribute to predicting the overweight or obesity status.\",\"431\":\"Some factors such as processed meat, high-fat dairy, and diet soda (Mozaffarian et al., 2011) have been investigated for their relationship with obesity; while other factors such as the plant-based compounds \\ufb02avanols or anthocyanins require further research to de\\ufb01ne how these factors orchestrate with human genome and epigenome to contribute to obesity.\",\"432\":\"However, due to the larger number of loading features, the nature of complex interactions, and ML approaches used in the present study, further analyses in ML techniques are needed to de\\ufb01ne the roles of modi\\ufb01able lifestyle predictors when developing a prevention strategy to mitigate obesity.\",\"433\":\"This type of research will eventually contribute to precision nutrition strategies to maintain healthy weight through controlling diet and lifestyle behaviors.\",\"434\":\"In this study, individual food items and nutrients appeared to be more important than dietary pattern features.\",\"435\":\"This aligns with the concept of personalized nutrition.\",\"436\":\"The same level of dietary FIGURE 3 | Receiver operating characteristic (ROC) curve of the overweight and obesity prediction model using stochastic gradient boosting machine learning algorithms in the test data set of the FOS (n \\u0001 394).\",\"437\":\"This model was based on continuous input variables and under-sampling approach.\",\"438\":\"Frontiers in Genetics | www.frontiersin.org January 2022 | Volume 12 | Article 783845 7 Lee et al. Obesity Prediction Using Machine Learning \\fTABLE 3 | Top 50 predictive features of the best-performing model for predicting overweight\\/obesity status in the FOS.\",\"439\":\"Importance Feature Chr Position Gene 100.00 Food group\\u2014processed meat servings 69.43 cg06690548 4 139162808 SLC7A11 52.17 cg17061862 11 9590431 NA 40.14 cg15754660 7 34699393 NPSR1 40.03 cg00574958 11 68607622 CPT1A 36.52 Nutrient value\\u2014calcium 35.51 cg27243685 21 43642366 ABCG1 33.83 cg06560379 6 44231305 NFKBIE 32.88 Food group\\u2014diet soda servings 28.66 cg11024682 17 17730094 SREBF1 28.62 Nutrient value\\u2014proanthocyanidin, monomers USDA, 2007 28.49 cg05201185 6 30459139 HLA-E 28.19 Physical activity 28.00 cg17501210 6 166970252 RPS6KA2 25.80 cg26403843 5 158634085 RNF145 25.37 Food\\u2014low-calorie Cola, no caffeine 25.24 cg11998932 7 3901843 SDK1 24.77 cg26278103 7 124404244 GPR37 24.76 cg08677140 6 30582241 PPP1R10 23.40 Food group\\u2014high-fat dairy servings 22.75 cg01881899 21 43652704 ABCG1 22.34 rs1740322 22.20 cg26376241 2 65594021 SPRED2 21.62 rs4974985 4 38961449 TMEM156 20.35 cg03572859 8 22409634 SORBS3 18.97 cg00174508 12 107774298 BTBD11 18.86 cg06500161 21 43656587 ABCG1 18.02 cg14476101 1 120255992 PHGDH 17.88 cg18222913 12 128846838 TMEM132C 17.22 cg16341269 6 150213172 RAET1E 16.63 Nutrient value\\u2014proanthocyanidin, dimers USDA, 2007 16.58 Sex 16.02 cg06460869 10 17270094 VIM 15.75 cg22650271 22 39760165 SYNGR1 15.30 cg10426084 17 1640472 WDR81 15.21 cg08766211 15 79118175 NA 15.13 Nutrient value\\u2014isorhamnetin, \\ufb02avonol USDA, 2003 14.77 cg11963676 1 76540110 ST6GALNAC3 13.61 cg19978312 5 179634688 RASGEF1C 13.58 cg04582365 10 59155846 NA 13.52 Nutrient value\\u2014epicatechin, \\ufb02avan-3-ol USDA, 2003 13.24 cg07052041 10 135092104 NA 12.92 cg17901584 1 55353706 DHCR24 12.67 cg18034719 5 176860863 GRK6 12.51 Food\\u2014French fries 12.44 cg15448990 4 88411497 SPARCL1 12.30 cg02508743 8 56903623 LYN (Continued on following page) Frontiers in Genetics | www.frontiersin.org January 2022 | Volume 12 | Article 783845 8 Lee et al. Obesity Prediction Using Machine Learning \\fscore could be achieved by many ways of dietary intake, and our research suggested paying attention to individual food items or speci\\ufb01c nutrients which \\ufb01t each person\\u2019s genetic and epigenetic background.\",\"440\":\"Our data showed that processed meat and animal fat played more important roles than a certain dietary pattern or total fat intake in predicting obesity, but which food items to use in recommendations would depend on each individual.\",\"441\":\"Clinical trials are warranted to validate our \\ufb01ndings; in other words, to test the complex interactive relationships between genetic background by changing diet (or lifestyle) according to model outputs.\",\"442\":\"The eventual goal of our research is to understand an individual\\u2019s susceptibility to obesity and his or her responsiveness to personalized interventions in a clinical setting that utilizes such results to develop useful prediction and preventive or therapeutic strategies for obesity.\",\"443\":\"Comparing our performance of predicting overweight and obesity with previous research, our ROC value \\u223c0.70 is not greater than that of previous research (Mukhopadhyay et al., 2015; Montanez et al., 2017; Ferdowsy et al., 2021; Thamrin et al., 2021).\",\"444\":\"We wish to emphasize that we did not include any anthropometric and clinical phenotypes as predictive features and simply used genome-wide genotype and DNA methylation data in combination with dietary and a few other lifestyle factors without any pre-selection based on prior knowledge.\",\"445\":\"We consider our approach to be an agnostic scan.\",\"446\":\"Additionally, we incorporated interactions with modi\\ufb01able features in model building, providing insights into developing strategies for the prevention and treatment of obesity.\",\"447\":\"DNA methylation is an epigenetic process that regulates gene expression without changing the DNA sequence.\",\"448\":\"Genetic factors, modi\\ufb01able environmental factors (diet and lifestyle), and biological status (considered as an internal environment, such as adiposity status) are believed to in\\ufb02uence DNA methylation regulation, which can regulate gene expression and molecular and biological phenotypes.\",\"449\":\"Thus, it is not surprising that 230 DMSs were assessed as important contributors to the best-performing model for predicting obesity, vastly outnumbering the contribution from SNPs at just 21.\",\"450\":\"Notably, this concept can be further supported by our analyses that the functional enrichment was contributed mostly by nearby genes of selected DMSs instead of SNPs.\",\"451\":\"Interestingly, from those selected features, the enriched function in alternative splicing parallels observed correlations between DNA methylation and alternative splicing (Zhang et al., 2020).\",\"452\":\"This enrichment in alternative splicing indicates a potential regulatory mechanism between the genome and environment through DNA methylation (Lev Maor et al., 2015; Gi et al., 2020), possibly acting via recognition of energy intake (Rhoads et al., 2018).\",\"453\":\"Obesity is a complex disease that is caused by a combination of genetic, biological, socioeconomic, cultural, environmental, and behavioral determinants, and that complexity highlights some of the limitations and challenges in this study.\",\"454\":\"First, we presented one method to integrate different data types in this study, and the development of methods of how to effectively integrate diverse data sets is a focus of ongoing research.\",\"455\":\"Our \\ufb01ndings suggest that further investigation is needed in order to integrate multi-omics and modi\\ufb01able lifestyle factors and to select features to avoid over-\\ufb01tting from high-dimensional data.\",\"456\":\"Some of those factors are known or potential determinants of obesity, including microbiome data, which were not included in the current research due to a lack of information in our study population.\",\"457\":\"To develop more advanced prediction approaches, a more systematic study design is needed, one that collects data from the individual, environmental, and societal levels.\",\"458\":\"Second, the blood-derived DNA methylation pro\\ufb01les may not be perfectly correlated to expression levels in tissues more relevant to the phenotype under study, such as adipose tissue.\",\"459\":\"Third, although the current work was performed cross-sectionally, this method can be applied to longitudinal data and used to predict the risk of developing obesity.\",\"460\":\"In addition, this methodology can be used in future research to validate our approach of providing personalized nutrition and\\/or lifestyle recommendations using clinical trials.\",\"461\":\"In conclusion, we report an integrated approach to predict obesity status using omics and dietary information and ML.\",\"462\":\"Results such as these can inform further development of approaches for prediction models and applying precision nutrition strategies for the prevention and treatment of TABLE 3 | (Continued) Top 50 predictive features of the best-performing model for predicting overweight\\/obesity status in the FOS.\",\"463\":\"Importance Feature Chr Position Gene 12.29 cg26722769 4 170328730 NEK1 12.27 cg25999015 19 44037866 ZNF575 11.86 cg00945735 7 41982767 NA TABLE 4 | Predicted responses in overweight and obesity status of subjects with simulated dietary feature changes in the test data set of the FOS (n \\u0001 260).\",\"464\":\"Original status Modifying feature Overweight or obese Not overweight or obese Total Food group\\u2014processed meat servings 28 (10.8%) 23 (8.8%) 51 (19.6%) Food group\\u2014high-fat dairy servings 15 (5.8%) 3 (1.2%) 18 (6.9%) Food\\u2014French fries 0 4 (1.5%) 4 (1.5%) Nutrient value\\u2014calcium 8 (3.1%) 6 (2.3%) 14 (5.4%) Nutrient value\\u2014animal Fat 5 (1.9%) 1 (0.4%) 6 (2.3%) Frontiers in Genetics | www.frontiersin.org January 2022 | Volume 12 | Article 783845 9 Lee et al. Obesity Prediction Using Machine Learning \\fobesity.\",\"465\":\"We suggest that this current work can be further used to predict other health outcomes and inform modi\\ufb01able features to improve the status of health and diseases.\",\"466\":\"DATA AVAILABILITY STATEMENT The controlled access datasets were used in this study.\",\"467\":\"This data can be requested and available at dbGaP (https:\\/\\/dbgap.ncbi.nlm.\",\"468\":\"nih.gov) under the accession numbers, phs000007.v25.p9, phs000007.v28.p10, phs000342.v18.p11, and phs000724.v9.p13.\",\"469\":\"ETHICS STATEMENT The data through dbGaP were fully anonymized.\",\"470\":\"The participants provided written informed consent to FHS clinical staff to participate in this study.\",\"471\":\"Genome-wide genotyping and DNA methylation pro\\ufb01ling were performed on peripheral blood samples (Marioni et al., 2015) of the participants who consented to genetics research.\",\"472\":\"AUTHOR CONTRIBUTIONS C-QL contributed to the study concept and design; Y-CL, C-QL, and NM contributed to data acquisition; Y-CL, JC, and C-QL contributed to data analysis and results interpretation; Y-CL and C-QL contributed to the drafting of the manuscript; C-QL, JS, and JO contributed to funding and supervision; and all authors reviewed, edited, made intellectual contributions to the manuscript, and approved the \\ufb01nal manuscript.\",\"473\":\"FUNDING This research was funded by the United States Department of Agriculture (USDA), Agriculture Research Service (ARS) under agreement no.\",\"474\":\"8050-51000-107-000D.\",\"475\":\"Mention of trade names or commercial products in this publication is solely for the purpose of providing speci\\ufb01c information and does not imply recommendation or endorsement by the USDA.\",\"476\":\"The USDA is an equal opportunity provider and employer.\",\"477\":\"Any opinions, \\ufb01ndings, conclusions, or recommendations expressed in this publication are those of the authors and do not necessarily re\\ufb02ect the view of the USDA.\",\"478\":\"ACKNOWLEDGMENTS The authors would like to thank all study participants in the study.\",\"479\":\"SUPPLEMENTARY MATERIAL The Supplementary Material for this article can be found online at: https:\\/\\/www.frontiersin.org\\/articles\\/10.3389\\/fgene.2021.783845\\/ full#supplementary-material REFERENCES Albuquerque, D., N\\u00f3brega, C., Manco, L., and Padez, C. (2017).\",\"480\":\"The Contribution of Genetics and Environment to Obesity.\",\"481\":\"Br. Med. Bull.\",\"482\":\"123, 159\\u2013173.\",\"483\":\"doi:10.1093\\/bmb\\/ldx022 Battram, T., Youse\\ufb01, P., Crawford, G., Prince, C., Babei, M. S., Sharp, G., et al. (2021).\",\"484\":\"The EWAS Catalog: A Database of Epigenome-wide Association Studies.\",\"485\":\"Charlottesville, VA: OSF Preprints.\",\"486\":\"doi:10.31219\\/osf.io\\/837wn Belsky, D. W., Mof\\ufb01tt, T. E., Sugden, K., Williams, B., Houts, R., Mccarthy, J., et al. (2013).\",\"487\":\"Development and Evaluation of a Genetic Risk Score for Obesity.\",\"488\":\"Biodemography Soc.\",\"489\":\"Biol.\",\"490\":\"59, 85\\u2013100.\",\"491\":\"doi:10.1080\\/ 19485565.2013.774628 Buniello, A., Macarthur, J. a. L., Cerezo, M., Harris, L. W., Hayhurst, J., Malangone, C., et al. (2019).\",\"492\":\"The NHGRI-EBI GWAS Catalog of Published Genome-wide Association Studies, Targeted Arrays and Summary Statistics 2019.\",\"493\":\"Nucleic Acids Res. 47, D1005\\u2013D1012.\",\"494\":\"doi:10.1093\\/nar\\/gky1120 Casas-Agustench, P., Arnett, D. K., Smith, C. E., Lai, C. Q., Parnell, L. D., Borecki, I. B., et al. (2014).\",\"495\":\"Saturated Fat Intake Modulates the Association between an Obesity Genetic Risk Score and Body Mass index in Two US Populations.\",\"496\":\"J. Acad.\",\"497\":\"Nutr. Diet.\",\"498\":\"114, 1954\\u20131966.\",\"499\":\"doi:10.1016\\/j.jand.2014.03.014 Chang, C. C., Chow, C. C., Tellier, L. C., Vattikuti, S., Purcell, S. M., and Lee, J. J. (2015).\",\"500\":\"Second-generation PLINK: Rising to the challenge of Larger and Richer Datasets.\",\"501\":\"GigaScience 4.\",\"502\":\"doi:10.1186\\/s13742-015-0047-8 Cho, S., Lee, E. H., Kim, H., Lee, J. M., So, M. H., Ahn, J. J., et al. (2021).\",\"503\":\"Validation of BMI Genetic Risk Score and DNA Methylation in a Korean Population.\",\"504\":\"Int. J. Leg.\",\"505\":\"Med. 135, 1201\\u20131212.\",\"506\":\"doi:10.1007\\/s00414-021-02517-y Corella, D. (2009).\",\"507\":\"APOA2, Dietary Fat, and Body Mass Index.\",\"508\":\"Arch.\",\"509\":\"Intern.\",\"510\":\"Med. 169, 1897.\",\"511\":\"doi:10.1001\\/archinternmed.2009.343 Corella, D., Lai, C.-Q., Demissie, S., Cupples, L. A., Manning, A. K., Tucker, K. L., et al. (2007).\",\"512\":\"APOA5 Gene Variation Modulates the Effects of Dietary Fat Intake on Body Mass index and Obesity Risk in the Framingham Heart Study.\",\"513\":\"J. Mol. Med. 85, 119\\u2013128.\",\"514\":\"doi:10.1007\\/s00109-006-0147-0 Dawber, T. R., Meadors, G. F., and Moore, F. E. (1951).\",\"515\":\"Epidemiological Approaches to Heart Disease: The Framingham Study.\",\"516\":\"Am. J. Public Health Nations Health 41, 279\\u2013286.\",\"517\":\"doi:10.2105\\/ajph.41.3.279 Degregory, K. W., Kuiper, P., Desilvio, T., Pleuss, J. D., Miller, R., Roginski, J. W., et al. (2018).\",\"518\":\"A Review of Machine Learning in Obesity.\",\"519\":\"Obes.\",\"520\":\"Rev. 19, 668\\u2013685.\",\"521\":\"doi:10.1111\\/obr.12667 Dhana, K., Braun, K. V. E., Nano, J., Voortman, T., Demerath, E. W., Guan, W., et al. (2018).\",\"522\":\"An Epigenome-wide Association Study of Obesity-Related Traits.\",\"523\":\"Am. J. Epidemiol.\",\"524\":\"187, 1662\\u20131669.\",\"525\":\"doi:10.1093\\/aje\\/kwy025 Dogan, M. V., Grumbach, I. M., Michaelson, J. J., and Philibert, R. A.\",\"526\":\"(2018).\",\"527\":\"Integrated Genetic and Epigenetic Prediction of Coronary Heart Disease in the Framingham Heart Study.\",\"528\":\"PLOS ONE 13, e0190549.\",\"529\":\"doi:10.1371\\/ journal.pone.0190549 Ferdowsy, F., Rahi, K. S. A., Jabiullah, M. I., and Habib, M. T. (2021).\",\"530\":\"A Machine Learning Approach for Obesity Risk Prediction.\",\"531\":\"Curr.\",\"532\":\"Res. Behav.\",\"533\":\"Sci. 2, 100053.\",\"534\":\"doi:10.1016\\/j.crbeha.2021.100053 Feskanich, D., Rimm, E. B., Giovannucci, E. L., Colditz, G. A., Stampfer, M. J., Litin, L. B., et al. (1993).\",\"535\":\"Reproducibility and Validity of Food Intake Measurements from a Semiquantitative Food Frequency Questionnaire.\",\"536\":\"J. Am. Diet.\",\"537\":\"Assoc.\",\"538\":\"93, 790\\u2013796.\",\"539\":\"doi:10.1016\\/0002-8223(93)91754-e Gbd 2015 Obesity Collaborators (2017).\",\"540\":\"Health Effects of Overweight and Obesity in 195 Countries over 25 Years.\",\"541\":\"New Engl.\",\"542\":\"J. Med. 377, 13\\u201327.\",\"543\":\"doi:10.1056\\/ NEJMoa1614362 Gi, W. T., Haas, J., Sedaghat-Hamedani, F., Kayvanpour, E., Tappu, R., Lehmann, D. H., et al. (2020).\",\"544\":\"Epigenetic Regulation of Alternative mRNA Splicing in Dilated Cardiomyopathy.\",\"545\":\"J. Clin. Med. 9.\",\"546\":\"doi:10.3390\\/jcm9051499 Hruby, A., Manson, J. E., Qi, L., Malik, V. S., Rimm, E. B., Sun, Q., et al. (2016).\",\"547\":\"Determinants and Consequences of Obesity.\",\"548\":\"Am. J. Public Health 106, 1656\\u20131662.\",\"549\":\"doi:10.2105\\/ajph.2016.303326 Frontiers in Genetics | www.frontiersin.org January 2022 | Volume 12 | Article 783845 10 Lee et al. Obesity Prediction Using Machine Learning \\fIrvin, M. R., Zhi, D., Joehanes, R., Mendelson, M., Aslibekyan, S., Claas, S. A., et al. (2014).\",\"550\":\"Epigenome-wide Association Study of Fasting Blood Lipids in the Genetics of Lipid-Lowering Drugs and Diet Network Study.\",\"551\":\"Circulation 130, 565\\u2013572.\",\"552\":\"doi:10.1161\\/circulationaha.114.009158 Kadayifci, F. Z., Zheng, S., and Pan, Y.-X. (2018).\",\"553\":\"Molecular Mechanisms Underlying the Link between Diet and DNA Methylation.\",\"554\":\"Int. J. Mol. Sci. 19, 4055.\",\"555\":\"doi:10.3390\\/ijms19124055 Kannel, W. B., Feinleib, M., Mcnamara, P. M., Garrison, R. J., and Castelli, W. P. (1979).\",\"556\":\"An Investigation of Coronary Heart Disease in Families.\",\"557\":\"Am. J. Epidemiol.\",\"558\":\"110, 281\\u2013290.\",\"559\":\"doi:10.1093\\/oxfordjournals.aje.a112813 Kannel, W. B., and Sorlie, P. (1979).\",\"560\":\"Some Health Bene\\ufb01ts of Physical Activity.\",\"561\":\"The Framingham Study.\",\"562\":\"Arch.\",\"563\":\"Intern.\",\"564\":\"Med. 139, 857\\u2013861.\",\"565\":\"doi:10.1001\\/ archinte.1979.03630450011006 Kiely, D. K., Wolf, P. A., Cupples, L. A., Beiser, A. S., and Kannel, W. B. (1994).\",\"566\":\"Physical Activity and Stroke Risk: the Framingham Study.\",\"567\":\"Am. J. Epidemiol.\",\"568\":\"140, 608\\u2013620.\",\"569\":\"doi:10.1093\\/oxfordjournals.aje.a117298 Lai, C.-Q., Parnell, L. D., Smith, C. E., Guo, T., Sayols-Baixeras, S., Aslibekyan, S., et al. (2020).\",\"570\":\"Carbohydrate and Fat Intake Associated with Risk of Metabolic Diseases through Epigenetics of CPT1A.\",\"571\":\"Am. J. Clin. Nutr. 112, 1200\\u20131211.\",\"572\":\"doi:10.1093\\/ajcn\\/nqaa233 Lai, C.-Q., Smith, C. E., Parnell, L. D., Lee, Y.-C., Corella, D., Hopkins, P., et al. (2018).\",\"573\":\"Epigenomics and Metabolomics Reveal the Mechanism of the APOA2Saturated Fat Intake Interaction Affecting Obesity.\",\"574\":\"Am. J. Clin. Nutr. 108, 188\\u2013200.\",\"575\":\"doi:10.1093\\/ajcn\\/nqy081 Lev Maor, G., Yearim, A., and Ast, G. (2015).\",\"576\":\"The Alternative Role of DNA Methylation in Splicing Regulation.\",\"577\":\"Trends Genet.\",\"578\":\"31, 274\\u2013280.\",\"579\":\"doi:10.1016\\/ j.tig.2015.03.002 Liu, Y., Shen, Y., Guo, T., Parnell, L. D., Westerman, K. E., Smith, C. E., et al. (2020).\",\"580\":\"Statin Use Associates with Risk of Type 2 Diabetes via Epigenetic Patterns at ABCG1.\",\"581\":\"Front.\",\"582\":\"Genet.\",\"583\":\"11, 622.\",\"584\":\"doi:10.3389\\/fgene.2020.00622 Locke, A. E., Kahali, B., Berndt, S. I., Justice, A. E., Pers, T. H., Day, F. R., et al. (2015).\",\"585\":\"Genetic Studies of Body Mass index Yield New Insights for Obesity Biology.\",\"586\":\"Nature 518, 197\\u2013206.\",\"587\":\"doi:10.1038\\/nature14177 Luo, X., Ding, Y., Zhang, L., Yue, Y., Snyder, J. H., Ma, C., et al. (2017).\",\"588\":\"Genomic Prediction of Genotypic Effects with Epistasis and Environment Interactions for Yield-Related Traits of Rapeseed (Brassica napus L.).\",\"589\":\"Front Genet 8, 15.\",\"590\":\"doi:10.3389\\/fgene.2017.00015 Manolio, T. A., Collins, F. S., Cox, N. J., Goldstein, D. B., Hindorff, L. A., Hunter, D. J., et al. (2009).\",\"591\":\"Finding the Missing Heritability of Complex Diseases.\",\"592\":\"Nature 461, 747\\u2013753.\",\"593\":\"doi:10.1038\\/nature08494 Marioni, R. E., Shah, S., Mcrae, A. F., Chen, B. H., Colicino, E., Harris, S. E., et al. (2015).\",\"594\":\"DNA Methylation Age of Blood Predicts All-Cause Mortality in Later Life.\",\"595\":\"Genome Biol.\",\"596\":\"16, 25.\",\"597\":\"doi:10.1186\\/s13059-015-0584-6 Mendelson,M.M.,Marioni,R.E.,Joehanes,R.,Liu,C.,Hedman,A.\",\"598\":\"K.,Aslibekyan,S.,etal.\",\"599\":\"(2017).\",\"600\":\"Association of Body Mass Index with DNA Methylation and Gene Expression in Blood Cells and Relations to Cardiometabolic Disease: A Mendelian Randomization Approach.\",\"601\":\"Plos Med. 14, e1002215.\",\"602\":\"doi:10.1371\\/journal.pmed.1002215 Montanez, C. a. C., Fergus, P., Hussain, A., Al-Jumeily, D., Abdulaimma, B., Hind, J., et al. (2017).\",\"603\":\"Machine Learning Approaches for the Prediction of Obesity Using Publicly Available Genetic Pro\\ufb01les.\",\"604\":\"2017 International Joint Conference on Neural Networks (IJCNN).\",\"605\":\"IEEE.\",\"606\":\"doi:10.1109\\/ ijcnn.2017.7966194 Morris, T. J., Butcher, L. M., Feber, A., Teschendorff, A. E., Chakravarthy, A. R., Wojdacz, T. K., et al. (2014).\",\"607\":\"ChAMP: 450k Chip Analysis Methylation Pipeline.\",\"608\":\"Bioinformatics 30, 428\\u2013430.\",\"609\":\"doi:10.1093\\/bioinformatics\\/btt684 Mozaffarian, D., Hao, T., Rimm, E. B., Willett, W. C., and Hu, F. B. (2011).\",\"610\":\"Changes in Diet and Lifestyle and Long-Term Weight Gain in Women and Men.\",\"611\":\"N. Engl.\",\"612\":\"J. Med. 364, 2392\\u20132404.\",\"613\":\"doi:10.1056\\/nejmoa1014296 Mukhopadhyay, S., Carroll, A., Downs, S., and Dugan, T. M. (2015).\",\"614\":\"Machine Learning Techniques for Prediction of Early Childhood Obesity.\",\"615\":\"Appl.\",\"616\":\"Clin.\",\"617\":\"Inform.\",\"618\":\"06, 506\\u2013520.\",\"619\":\"doi:10.4338\\/aci-2015-03-ra-0036 Parnell, L. D., Blokker, B. A., Dashti, H. S., Nesbeth, P.-D., Cooper, B. E., Ma, Y., et al. (2014).\",\"620\":\"CardioGxE, a Catalog of Gene-Environment Interactions for Cardiometabolic Traits.\",\"621\":\"BioData Mining 7, 21.\",\"622\":\"doi:10.1186\\/1756-0381-7-21 Qi, Q., Chu, A. Y., Kang, J. H., Jensen, M. K., Curhan, G. C., Pasquale, L. R., et al. (2012).\",\"623\":\"Sugar-Sweetened Beverages and Genetic Risk of Obesity.\",\"624\":\"New Engl.\",\"625\":\"J. Med. 367, 1387\\u20131396.\",\"626\":\"doi:10.1056\\/nejmoa1203039 Rhoads, T. W., Burhans, M. S., Chen, V. B., Hutchins, P. D., Rush, M. J. P., Clark, J. P., et al. (2018).\",\"627\":\"Caloric Restriction Engages Hepatic RNA Processing Mechanisms in Rhesus Monkeys.\",\"628\":\"Cel Metab.\",\"629\":\"27, 677-+.\",\"630\":\"doi:10.1016\\/ j.cmet.2018.01.014 Rimm, E. B., Giovannucci, E. L., Stampfer, M. J., Colditz, G. A., Litin, L. B., and Willett, W. C. (1992).\",\"631\":\"Reproducibility and Validity of an Expanded SelfAdministered Semiquantitative Food Frequency Questionnaire Among Male Health Professionals.\",\"632\":\"Am. J. Epidemiol.\",\"633\":\"135, 1114\\u20131126.\",\"634\":\"doi:10.1093\\/ oxfordjournals.aje.a116211 Sayols-Baixeras, S., Subirana, I., Fern\\u00e1ndez-Sanl\\u00e9s, A., Sent\\u00ed, M., Llu\\u00eds-Ganella, C., Marrugat, J., et al. (2017).\",\"635\":\"DNA Methylation and Obesity Traits: An Epigenome-wide Association Study.\",\"636\":\"The REGICOR Study.\",\"637\":\"Epigenetics 12, 909\\u2013916.\",\"638\":\"doi:10.1080\\/15592294.2017.1363951 Szklarczyk, D., Gable, A. L., Nastou, K. C., Lyon, D., Kirsch, R., Pyysalo, S., et al. (2021).\",\"639\":\"The STRING Database in 2021: Customizable Protein-Protein Networks, and Functional Characterization of User-Uploaded Gene\\/measurement Sets.\",\"640\":\"Nucleic Acids Res. 49, D605\\u2013D612.\",\"641\":\"doi:10.1093\\/nar\\/gkaa1074 Thamrin, S. A., Arsyad, D. S., Kuswanto, H., Lawi, A., and Nasir, S. (2021).\",\"642\":\"Predicting Obesity in Adults Using Machine Learning Techniques: An Analysis of Indonesian Basic Health Research 2018.\",\"643\":\"Front.\",\"644\":\"Nutr. 8, 669155.\",\"645\":\"doi:10.3389\\/ fnut.2021.669155 Visscher, P. M., Hill, W. G., and Wray, N. R. (2008).\",\"646\":\"Heritability in the Genomics Era-Cconcepts and Misconceptions.\",\"647\":\"Nat.\",\"648\":\"Rev. Genet.\",\"649\":\"9, 255\\u2013266.\",\"650\":\"doi:10.1038\\/ nrg2322 Wahl, S., Drong, A., Lehne, B., Loh, M., Scott, W. R., Kunze, S., et al. (2017).\",\"651\":\"Epigenome-wide Association Study of Body Mass index, and the Adverse Outcomes of Adiposity.\",\"652\":\"Nature 541, 81\\u201386.\",\"653\":\"doi:10.1038\\/nature20784 World Health Organization (2021).\",\"654\":\"Obesity and Overweight.\",\"655\":\"World Health Organization.\",\"656\":\"Available: https:\\/\\/www.who.int\\/news-room\\/fact-sheets\\/detail\\/ obesity-and-overweight (Accessed August 2, 2021).\",\"657\":\"Xu, H.-M., Xu, L.-F., Hou, T.-T., Luo, L.-F., Chen, G.-B., Sun, X.-W., et al. (2016).\",\"658\":\"GMDR: Versatile Software for Detecting Gene-Gene and Gene-Environment Interactions Underlying Complex Traits.\",\"659\":\"Curr.\",\"660\":\"Genomics 17, 396\\u2013402.\",\"661\":\"doi:10.2174\\/1389202917666160513102612 Zhang, J., Zhang, Y. Z., Jiang, J., and Duan, C. G. (2020).\",\"662\":\"The Crosstalk between Epigenetic Mechanisms and Alternative RNA Processing Regulation.\",\"663\":\"Front.\",\"664\":\"Genet.\",\"665\":\"11.\",\"666\":\"doi:10.3389\\/fgene.2020.00998 Con\\ufb02ict of Interest: The authors declare that the research was conducted in the absence of any commercial or \\ufb01nancial relationships that could be construed as a potential con\\ufb02ict of interest.\",\"667\":\"Publisher\\u2019s Note: All claims expressed in this article are solely those of the authors and do not necessarily represent those of their af\\ufb01liated organizations, or those of the publisher, the editors, and the reviewers.\",\"668\":\"Any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher.\",\"669\":\"Copyright \\u00a9 2022 Lee, Christensen, Parnell, Smith, Shao, McKeown, Ordov\\u00e1s and Lai.\",\"670\":\"This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY).\",\"671\":\"The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice.\",\"672\":\"No use, distribution or reproduction is permitted which does not comply with these terms.\",\"673\":\"Frontiers in Genetics | www.frontiersin.org January 2022 | Volume 12 | Article 783845 11 Lee et al. Obesity Prediction Using Machine Learning\",\"674\":\"ORIGINAL RESEARCH published: 21 June 2021 doi: 10.3389\\/fnut.2021.669155 Frontiers in Nutrition | www.frontiersin.org 1 June 2021 | Volume 8 | Article 669155 Edited by: Francesco Sofi, Universit\\u00e0 degli Studi di Firenze, Italy Reviewed by: Jos\\u00e9 Mar\\u00eda Huerta, Instituto de Salud Carlos III (ISCIII), Spain Rosa Casas Rodriguez, Institut de Recerca Biom\\u00e8dica August Pi i Sunyer (IDIBAPS), Spain *Correspondence: Sri Astuti Thamrin tuti@unhas.ac.id \\u2020These authors have contributed equally to this work and share first authorship Specialty section: This article was submitted to Nutritional Epidemiology, a section of the journal Frontiers in Nutrition Received: 18 February 2021 Accepted: 27 April 2021 Published: 21 June 2021 Citation: Thamrin SA, Arsyad DS, Kuswanto H, Lawi A and Nasir S (2021) Predicting Obesity in Adults Using Machine Learning Techniques: An Analysis of Indonesian Basic Health Research 2018.\",\"675\":\"Front.\",\"676\":\"Nutr.\",\"677\":\"8:669155.\",\"678\":\"doi: 10.3389\\/fnut.2021.669155 Predicting Obesity in Adults Using Machine Learning Techniques: An Analysis of Indonesian Basic Health Research 2018 Sri Astuti Thamrin1 *\\u2020 , Dian Sidik Arsyad2\\u2020 , Hedi Kuswanto1 , Armin Lawi3 and Sudirman Nasir4 1 Department of Statistics, Faculty of Mathematics and Natural Science, Hasanuddin University, Makassar, Indonesia, 2 Department of Epidemiology, Faculty of Public Health, Hasanuddin University, Makassar, Indonesia, 3 Department of Mathematics, Faculty of Mathematics and Natural Sciences, Hasanuddin University, Makassar, Indonesia, 4 Department of Health Promotion, Faculty of Public Health, Hasanuddin University, Makassar, Indonesia Obesity is strongly associated with multiple risk factors.\",\"679\":\"It is significantly contributing to an increased risk of chronic disease morbidity and mortality worldwide.\",\"680\":\"There are various challenges to better understand the association between risk factors and the occurrence of obesity.\",\"681\":\"The traditional regression approach limits analysis to a small number of predictors and imposes assumptions of independence and linearity.\",\"682\":\"Machine Learning (ML) methods are an alternative that provide information with a unique approach to the application stage of data analysis on obesity.\",\"683\":\"This study aims to assess the ability of ML methods, namely Logistic Regression, Classification and Regression Trees (CART), and Na\\u00efve Bayes to identify the presence of obesity using publicly available health data, using a novel approach with sophisticated ML methods to predict obesity as an attempt to go beyond traditional prediction models, and to compare the performance of three different methods.\",\"684\":\"Meanwhile, the main objective of this study is to establish a set of risk factors for obesity in adults among the available study variables.\",\"685\":\"Furthermore, we address data imbalance using Synthetic Minority Oversampling Technique (SMOTE) to predict obesity status based on risk factors available in the dataset.\",\"686\":\"This study indicates that the Logistic Regression method shows the highest performance.\",\"687\":\"Nevertheless, kappa coefficients show only moderate concordance between predicted and measured obesity.\",\"688\":\"Location, marital status, age groups, education, sweet drinks, fatty\\/oily foods, grilled foods, preserved foods, seasoning powders, soft\\/carbonated drinks, alcoholic drinks, mental emotional disorders, diagnosed hypertension, physical activity, smoking, and fruit and vegetables consumptions are significant in predicting obesity status in adults.\",\"689\":\"Identifying these risk factors could inform health authorities in designing or modifying existing policies for better controlling chronic diseases especially in relation to risk factors associated with obesity.\",\"690\":\"Moreover, applying ML methods on publicly available health data, such as Indonesian Basic Health Research (RISKESDAS) is a promising strategy to fill the gap for a more robust understanding of the associations of multiple risk factors in predicting health outcomes.\",\"691\":\"Keywords: classification, Logistic Regression, machine learning, Naive Bayes, obesity status \\fThamrin et al. Predicting Obesity Using Machine Learning INTRODUCTION Obesity is a major health problem strongly associated with many chronic illnesses with negative effects and long-term consequences, not only for the patients but also their families.\",\"692\":\"In Southeast Asia, problems related to nutrition or malnutrition are a double burden because the number of cases of malnutrition and malnourishment is still relatively high and the number of cases of obesity has also increased significantly over time (1).\",\"693\":\"Data from the 2013 national-level survey of Indonesian Basic Health Research (RISKESDAS) showed the prevalence of obesity in Indonesia has increased over the years.\",\"694\":\"Obesity among adult men was 13.9% in 2007, 7.8% in 2010, and 19.7% in 2013, whereas for adult women the prevalence was 14.8% in 2007, 15.5% in 2010, and increased drastically to 32.9% in 2013 (2).\",\"695\":\"By 2018, the same survey (RISKESDAS 2018) showed that the prevalence of obesity in men and women had decreased slightly to 14.5 and 29.3%, respectively (3).\",\"696\":\"Risk factors for obesity have been studied extensively, and in general, they are divided into several categories: demographic and socio-economic factors (gender, age, education, income, marital status, and urban areas) (4\\u20136); lifestyle factors (consumption of fast food, stress, smoking, alcoholic drinks, and low level of physical activity) (6, 7); and genetic factors (obese parents) (4, 5).\",\"697\":\"Among these risk factors, some can be changed or modified, while others cannot.\",\"698\":\"Identifying modifiable risk factors for obesity at the individual and the population level is urgently required in order to implement an effective risk reduction strategy.\",\"699\":\"Numerous studies have explored better approaches to predicting obesity using available data.\",\"700\":\"A novel method recently introduced to answer this question uses Machine Learning (ML), which is currently one of the most popular topics in the scientific community for large-scale datasets.\",\"701\":\"Epidemiological data modeling using ML approaches is becoming increasingly popular in the published scientific literature.\",\"702\":\"These methods have the potential to improve our understanding of general health regarding disease distribution, detection, and the identification of risk factors for health problems, and thus, opportunities for intervention.\",\"703\":\"Various ML methods and algorithms have been applied to various aspects of health data including obesity (8).\",\"704\":\"In the case of obesity, it is essential to develop a precise data classification to facilitate the process of finding predictive risk factors from the given data, in efforts to control these risk factors and eventually to decrease morbidity and mortality linked to obesity.\",\"705\":\"For the purpose of obesity prevention, ML has been used to predict the probability of obesity based on data encoding adherence to dietary recommendations and several other factors (9).\",\"706\":\"The ML has also been applied for the prediction of obesity in children using electronic health records before the age of 2 (10); prediction of obesogenic environments for children (11); and for the aggregation of metabolomics, lipidomics, and other clinical data to modeling drug dose responses (12).\",\"707\":\"Based on previous research, ML approaches can increase the risk prediction of health outcomes compared to conventional approaches (13).\",\"708\":\"Prediction of obesity using ML has been investigated by many researchers: Zhang et al. (14), Adnan et al. (15), Toschke et al. (16), Golino et al. (17), Dugan et al. (10), Zheng and Ruggiero (18), Chatterjee et al. (19), Singh and Tawfik (20), and Colmenarejo (21).\",\"709\":\"The ML approach provides an alternative in providing information with a unique approach at the application stage of data analysis on obesity which is important in providing a better predictive solution to the likelihood of obesity (22).\",\"710\":\"MATERIALS AND METHODS Data Source The dataset used to develop the classification model in this study is publicly available data from an Indonesia national scale survey with a cross-sectional and non-intervention design, the RISKESDAS survey, which was conducted by the Indonesian Ministry of Health.\",\"711\":\"The RISKESDAS report is a communitybased health survey whose indicators can be generalized with variables described from the national level down to the district\\/city level.\",\"712\":\"It is conducted every 5 years across 34 provinces and 514 districts\\/cities in order to track important indicators of public health status, diseases risk factors, and to evaluate healthcare services delivery programs.\",\"713\":\"The methodology and detailed protocols of the survey are described elsewhere (3).\",\"714\":\"Briefly, the target sample for this study is 300,000 households from 30,000 Census Block (CBs) in 34 provinces and 514 district-cities throughout Indonesia.\",\"715\":\"The sampling frame lists are provided by the Central Bureau of Statistics (BPS) using a twostage sampling method.\",\"716\":\"In the first stage, 180,000 CBs (25%) were selected from 720,000 CBs from the national socio-economic survey (SUSENAS) as a sampling frame using a proportionate to population size (PPS) method and stratified by prosperity level, continued by systematically selecting 30,000 CBs from 180,000 CBs priorly selected and stratified by urban and rural for each district or city.\",\"717\":\"In the second stage, 10 households were selected systematically using implicit stratification for the education level of the head of household to maintain variation of education among households.\",\"718\":\"Household members who were eligible according to the inclusion criteria were invited to participate in the interview.\",\"719\":\"The dataset can be accessed by request at the Institute of Health Research and Development of the Indonesian Ministry of Health (https:\\/\\/www.litbang.kemkes.go.id\\/layanan-permintaandata-riset\\/).\",\"720\":\"Pre-processing Data Data Cleaning or Filtering The sample used in this study included all the data from the RISKESDAS dataset for individuals aged 18 or above; in total there was data for 634,709 respondents.\",\"721\":\"We conducted data cleaning by excluding all records with incomplete or missing values for the variable\\/feature Body Mass Index (BMI), a core feature used to categorize obesity status.\",\"722\":\"The number of samples included for the analysis process after cleaning was 618,898 records.\",\"723\":\"Data cleaning was performed by using the dplyr package of R version 3.5.1 to perform filtering (23).\",\"724\":\"Frontiers in Nutrition | www.frontiersin.org 2 June 2021 | Volume 8 | Article 669155 \\fThamrin et al. Predicting Obesity Using Machine Learning Feature Selection After removing missing values, we proceeded to variable or feature selection.\",\"725\":\"Variable selection is a process of reducing the data dimensions to reduce processing time as well as computation costs (24).\",\"726\":\"We selected a subset of variables that contributed significantly to the target class to improve the overall predictive performance of the classification using the Chi-Square (\\u03c72) test between obesity status with each of the variables and including those with a p-value < 0.05.\",\"727\":\"All features that met these criteria (a total of 21 features) were selected for developing the classification model.\",\"728\":\"These variables or features were location (X1), marital status (X2), age group (X3), education (X4), work category (X5), sugary foods (X6), sweet drinks (X7), salty foods (X8), fatty\\/oily foods (X9), grilled foods (X10), preserved foods (X11), seasoning powders (X12), soft\\/carbonated drinks (X13), energy drinks (X14), instant foods (X15), alcoholic drinks (X16), mental-emotional disorders (X17), diagnosed hypertension (X18), physical activity (X19), smoking (X20), and fruit and vegetables consumptions (X21).\",\"729\":\"A list of these features and how it was generated from the questionnaire (for composited and calculated feature, i.e., obesity, fruit and vegetables consumption, physical activity, and mental-emotional disorders) can be found in the Supplementary Table 1.\",\"730\":\"The process of developing a classification model was carried out by using the R Statistical Software version 3.5.1 (25).\",\"731\":\"Dealing With Imbalanced Datasets Data imbalance occurs when there are one or more classes that dominate the whole data as major classes, and other classes are rare occurrences or minor classes.\",\"732\":\"Imbalanced data will produce a good classification prediction accuracy against the major class, but in the minor class, the resulting accuracy is poor.\",\"733\":\"The Synthetic Minority Oversampling Technique (SMOTE) was introduced by Chawla et al. (26) and Chawla (27), as a way of dealing with the effect of the lack of information on minority classes in a data set.\",\"734\":\"SMOTE is an algorithm with an oversampling approach, which generates artificial data for minority data classes (28) so that the proportions of major and minor data classes are more balanced (29).\",\"735\":\"Artificial data or synthetic data are made based on the k-nearest neighbor.\",\"736\":\"All attributes used in this study were categorical features so that the calculation of the distance between the minor class samples was carried out using the Modify Value Difference Metric (MVDM) method (30).\",\"737\":\"In this method, several steps are taken, namely calculating the distance between two observations at a nominal scale and choosing the majority category between the minority class observations with its k-closest neighbors for a nominal value, and if the same value occurs, it is chosen randomly.\",\"738\":\"Furthermore, the selected value is a new observation.\",\"739\":\"In this study, the SMOTE technique with oversampling of 200% and 300% was used which resulted in two new datasets.\",\"740\":\"Machine Learning Classification Methods Logistic Regression One of the basic linear models developed with a probabilistic approach to classification problems is Logistic Regression (31) and is one of the supervised learning models widely used in ML.\",\"741\":\"Logistic Regression can be seen as a development of Linear Regression models with a logistic function for data with a target in the form of classes (32) as follows: y (x) = \\u03c3 \\u0010 \\u03b20 + \\u03b2T x \\u0011 , where x = (x1, x2, .\",\"742\":\".\",\"743\":\".\",\"744\":\", xD)T is the D-dimensional data, \\u03b2 = (\\u03b21, \\u03b22, .\",\"745\":\".\",\"746\":\".\",\"747\":\", \\u03b2D)T are the weight parameters, \\u03b20 is the bias parameter, and \\u03c3 is a logistic function that is shaped as \\u03c3 (a) = 1 1+e\\u2212 a .\",\"748\":\"The weights of \\u03b2 can be obtained by using probabilistic concepts.\",\"749\":\"For example, if yn = y (xn) and tn \\u2208 {0, 1} are an independent identical distribution.\",\"750\":\"The joint probabilistic or likelihood function for all the data can be expressed by the Bernoulli distribution p (t|\\u03b2) ,where t = (t1, t2, .\",\"751\":\".\",\"752\":\".\",\"753\":\", tN)T .\",\"754\":\"Therefore, the Logistic Regression learning and bias (\\u03b2) is to maximize p (t \\u2228 \\u03b2).\",\"755\":\"The learning method for determining the weight and bias (\\u03b2) parameters is known as the maximum likelihood method.\",\"756\":\"Generally, the solution to the maximum likelihood problem is done by minimizing the negative of the logarithm of the likelihood function, namely min\\u03b2 E (\\u03b2), where E (\\u03b2) = \\u2212 ln p (t \\u2228 \\u03b2) \\u0001 .\",\"757\":\"Logistic Regression models can use regularization techniques to solve the problem of overfitting by adding the weight norm ||w|| in the error function, namely E (\\u03b2) = 1 2 k\\u03b2k2 + C PN n=1 \\b tn ln yn \\u0001 + (1 \\u2212 tn) ln 1 \\u2212 yn \\u0001 , where C > 0 is the inverse parameter of the regulation.\",\"758\":\"Simultaneous and partial parameter testing is performed to examine the role of predictor variables in the model.\",\"759\":\"Simultaneous parameter testing uses the G test.\",\"760\":\"Classification and Regression Trees Breiman et al. (33) proposes a new algorithm for tree arrangement, namely Classification and Regression Tree (CART).\",\"761\":\"CART is a non-parametric statistical method used for classification analysis, both for categorical and continuous response variables, and for explanatory variables which may consist of nominal, ordinal, or continuous features.\",\"762\":\"The resulting tree model depends on the scale of the response attribute.\",\"763\":\"CART generates a classification tree if the response variables are categorical, and generates a regression tree if the response variables are continuous (33).\",\"764\":\"The tree structure in the CART method is obtained through a binary recursive partitioning algorithm against its explanatory variables (31, 32).\",\"765\":\"The binding is carried out by dividing the data set into two subclusters called nodes.\",\"766\":\"The impurity value at node t is a measurement of the heterogeneity level of a class from a particular node in the classification tree.\",\"767\":\"The process of forming a classification tree is carried out in three stages; selecting a classifier, determining the final node, and marking the class label (31).\",\"768\":\"In selecting the classifier, each partitioning depends on the value that comes from only one explanatory variable.\",\"769\":\"For categorical variables, the partitioning that occurs comes from all the possible partitioning based on the formation of two subgroups that are mutually exclusive (disjoint).\",\"770\":\"In addition, in solving classification tree problems, the Gini Splitting Rule (also known as the Gini Index) is the most common rule to be used (32).\",\"771\":\"Then, the partitioning evaluation is performed using Frontiers in Nutrition | www.frontiersin.org 3 June 2021 | Volume 8 | Article 669155 \\fThamrin et al. Predicting Obesity Using Machine Learning the goodness of split \\u03d5 (s, t) of the s partition at t node.\",\"772\":\"The partitioning function is defined as decreased heterogeneity.\",\"773\":\"A sort that produces a higher value is a better sort because it reduces the impurity value more significantly.\",\"774\":\"If the resulting node is of a non-homogeneous class, the same procedure will be repeated until the tree \\u03d5 (s, t) \\u03d5 (s\\u2217, t) = maxs\\u2208S \\u03d5 (s, t).\",\"775\":\"Determination of child nodes is carried out recursively by using the same method as determining the main node.\",\"776\":\"After selecting the classifier, the end node is determined.\",\"777\":\"The minimum number of cases in a node is generally five.\",\"778\":\"If this is fulfilled, tree development will be stopped and continued with the marking of class labels.\",\"779\":\"Class label marking at the end node is carried out based on the highest number rule.\",\"780\":\"The process of forming classification trees stops when there is only one observation in each child node.\",\"781\":\"One of the ways to get the optimal tree is by consecutively pruning the tree that is less important.\",\"782\":\"In random pruning, the observations are divided into two parts, namely training data L1 and test data L2.\",\"783\":\"Through the pruning process, a row of trees is formed from L1.\",\"784\":\"Next, L2 is used to form the total proportion of misclassification (R|ts (G)).\",\"785\":\"The optimal tree that meets the criteria as Rts G0 \\u0001 = min Rts (Gt ).\",\"786\":\"Na\\u00efve Bayesian Na\\u00efve Bayesian classification is a statistical approach which attempts to predict the probability of each class (14).\",\"787\":\"The advantage of this Bayes grouping is that it has a high level of accuracy and speed when using large data sets.\",\"788\":\"Na\\u00efve Bayesian grouping assumes that the values of the variables on the class labels are independent of other attribute values, which can facilitate the calculation (10, 34).\",\"789\":\"Na\\u00efve Bayesian Classification is achieved by applying the Bayes rule to calculate the probability of each attribute and predicting the class based on the highest prior probability (34).\",\"790\":\"Model Validation The validation process in this study used k-fold cross-validation (35).\",\"791\":\"Cross-Validation (CV) divides the dataset into two parts: one part is used as the training data and the other is used as testing data.\",\"792\":\"In this study, the data were divided into 10 parts, 90% of which was used as training and the rest was used for testing.\",\"793\":\"This process was done repeatedly, a maximum of 10 times, until all data records were part of the testing data.\",\"794\":\"This process is also known as the 10-fold CV.\",\"795\":\"The 10-fold CV process has been used in several previous health care- and medicalrelated studies (36).\",\"796\":\"Evaluation of Classification Performance Measuring accuracy is a diagnostic step to test the level of performance of an algorithm against the dataset used.\",\"797\":\"A matrix, known as the confusion matrix, is used to evaluate the learning algorithm (37).\",\"798\":\"Each column in the matrix shows the number of observations in the predicted class.\",\"799\":\"The rows in the matrix represent the actual number of observations in the class.\",\"800\":\"In ML, the term metric refers to a value that can be used to represent the performance of the resulting model.\",\"801\":\"In classification modeling, the model output is a label\\/class.\",\"802\":\"There are several metrics that are commonly used, namely accuracy, TABLE 1 | General description of obesity data from Indonesian RISKESDAS 2018.\",\"803\":\"Variables Categories Frequency Percentage Obesity status (Y) Non-obese 484,189 78.23 Obese 134,709 21.77 Location (X1) Urban 267,913 43.29 Rural 350,985 56.71 Marital status (X2) Not married 84,792 13.70 Married 472,269 76.31 Divorced 14,333 2.32 Widowed 47,504 7.68 Age groups (X3) 18\\u201324 years 69,532 11.23 25\\u201329 years 60,380 9.76 30\\u201334 years 68,683 11.10 35\\u201339 years 77,538 12.53 40\\u201344 years 73,775 11.92 45\\u201349 years 70,503 11.39 50\\u201354 years 58,618 9.47 55\\u201359 years 49,632 8.02 60\\u201364 years 35,471 5.73 >64 years 54,766 8.85 Education (X4) Not\\/Never schooled 40,861 6.60 Not finished basic school 84,637 13.68 Finished basic school 157,391 25.43 Finished Junior High School 104,435 16.87 Finished Senior High School 170,246 27.51 Finished Academy\\/College 20,005 3.23 Finished higher education 41,323 6.68 Work types (X5) Not working 171,984 27.79 School 12,238 1.98 Government employee 27,703 4.48 Private employee 50,049 8.09 Entrepreneur 91,011 14.71 Farmer 163,009 26.34 Fisherman 8,344 1.35 Daily waged labors 52,379 8.46 Others 42,181 6.82 Sugary foods (X6) >1 time per day 82,775 13.37 1 time per day 125,754 20.32 3\\u20136 times per week 138,685 22.41 1\\u20132 times per week 177,173 28.63 <3 times per month 62,972 10.17 Never 31,539 5.10 Sweet drinks (X7) >1 time per day 176,096 28.45 1 time per day 195,361 31.57 3\\u20136 times per week 87,827 14.19 1\\u20132 times per week 95,409 15.42 <3 times per month 33,666 5.44 Never 30,539 4.93 Salty foods (X8) >1 time per day 64,660 10.45 (Continued) Frontiers in Nutrition | www.frontiersin.org 4 June 2021 | Volume 8 | Article 669155 \\fThamrin et al. Predicting Obesity Using Machine Learning TABLE 1 | Continued Variables Categories Frequency Percentage 1 time per day 78,744 12.72 3\\u20136 times per week 105,363 17.02 1\\u20132 times per week 170,442 27.54 <3 times per month 107,318 17.34 Never 92,371 14.93 Fatty\\/Oily foods (X9) >1 time per day 103,634 16.74 1 time per day 113,057 18.27 3\\u20136 times per week 133,552 21.58 1\\u20132 times per week 164,703 26.61 <3 times per month 72,739 11.75 Never 31,213 5.04 Grilled foods (X10) >1 time per day 12,948 2.09 1 time per day 22,189 3.59 3\\u20136 times per week 63,967 10.34 1\\u20132 times per week 161,356 26.07 <3 times per month 202,251 32.68 Never 156,187 25.24 Preserved foods (X11) >1 time per day 6,310 1.02 1 time per day 12,024 1.94 3\\u20136 times per week 31,993 5.17 1\\u20132 times per week 72,618 11.73 <3 times per month 145,068 23.44 Never 350,885 56.70 Seasonings powders (X12) >1 time per day 227,357 36.74 1 time per day 226,628 36.62 3\\u20136 times per week 42,598 6.88 1\\u20132 times per week 34,030 5.50 <3 times per month 20,887 3.37 Never 67,398 10.89 Soft\\/Carbonated drinks (X13) >1 time per day 3,689 0.60 1 time per day 7,857 1.27 3\\u20136 times per week 16,470 2.66 1\\u20132 times per week 43,686 7.06 <3 times per month 100,398 16.22 Never 446,798 72.19 Energy drinks (X14) >1 time per day 3,654 0.59 1 time per day 7,761 1.25 3\\u20136 times per week 12,888 2.08 1\\u20132 times per week 31,045 5.02 <3 times per month 58,659 9.48 Never 504,891 81.58 Instant foods (X15) >1 time per day 12,144 1.96 1 time per day 28,943 4.68 3\\u20136 times per week 108,287 17.50 1\\u20132 times per week 220,125 35.57 <3 times per month 149,066 24.09 Never 100,333 16.21 Alcoholic drinks (X16) Yes 30,240 4.89 No 588,658 95.11 (Continued) TABLE 1 | Continued Variables Categories Frequency Percentage Mental-emotional disorders (X17) Yes 61,092 9.87 No 557,806 90.13 Diagnosed hypertension (X18) Yes 55,640 8.99 No 315,467 50.97 Unknown 247,791 40.04 Physical activity (X19) Adequate 73,736 11.91 Not adequate 545,162 88.09 Smoking (X20) Yes 233,306 37.70 No 385,592 62.30 Fruit and vegetables consumptions (X21) Adequate 29,321 4.74 Not adequate 589,577 95.26 precision, sensitivity, specificity, recall, F1-score, kappa, and F\\u03b2.\",\"804\":\"In terms of the confusion matrix, accuracy is the ratio of the number of diagonal elements to the total number of matrix elements.\",\"805\":\"The accuracy of the method is only considered adequate when the comparison of the actual number of data labels is nearly identical with the confusion matrix.\",\"806\":\"If the comparison is imbalanced, then other metrics can be used.\",\"807\":\"Precision is an appropriate metric when false positives are to be avoided.\",\"808\":\"Sensitivity can be interpreted as the degree of reliability of the model to detect data labeled positive correctly.\",\"809\":\"Sensitivity is an appropriate metric when false negatives are to be avoided (high risk).\",\"810\":\"Specificity is the degree of model reliability for detecting data labeled negative correctly.\",\"811\":\"This metric is closely related to sensitivity.\",\"812\":\"This metric is appropriate when the true negative rate is to be maximized.\",\"813\":\"To minimize both (false positive and false negative) outcomes at the same time, precision and sensitivity need to be summarized by using the F1-score.\",\"814\":\"Recall is a valid choice of evaluation metric when we want to capture as many positives (obese) as possible.\",\"815\":\"In this study, we want to be sure that the sample we catch is obese (precision) and we also want to capture as many obese (recall) as possible.\",\"816\":\"The F1-score manages this trade-off.\",\"817\":\"However, the main problem with the F1-score is that it gives equal weight to precision and recall.\",\"818\":\"Sometimes we may need to include domain knowledge in our evaluations where we want more recall or more precision.\",\"819\":\"To solve this, we can create a weighted F1 metric, where beta (\\u03b2) sets the balance between precision and recall.\",\"820\":\"This is called F\\u03b2.\",\"821\":\"In this study, we used \\u03b2 = 0.5 to measure more weight on precision and less weight on recall.\",\"822\":\"Kappa is used to test the inter reliability.\",\"823\":\"Kappa values range from 0 to 1.0 which can be divided into several classifications, namely 0\\u20130.20 (slight), 0.21\\u20130.40 (fair), 0.41\\u20130.60 (moderate), 0.61\\u20130.80 (substantial), and 0.81\\u20131.0 (perfect) (38).\",\"824\":\"The Area Under ROC Curve, also known as AUC, has a range between 0.5 (50%) and 1 (100%).\",\"825\":\"The interpretation of AUC Frontiers in Nutrition | www.frontiersin.org 5 June 2021 | Volume 8 | Article 669155 \\fThamrin et al. Predicting Obesity Using Machine Learning TABLE 2 | Comparison of classification accuracy with 10-fold CV based on the obesity test data using three models with confusion matrix.\",\"826\":\"ML methods Classification prediction Fold 1 Test Fold 2 Test Fold 3 Test Fold 4 Test Fold 5 Test Real circumstances Non-obese Obese Non-obese Obese Non-obese Obese Non-obese Obese Non-obese Obese CART Non-obese 360,554 193,472 360,260 193,579 360,791 193,595 360,325 193,504 360,459 193,685 Obese 75,298 291,411 75,283 291,744 75,227 291,362 75,294 291,335 75,401 291,611 Na\\u00efve-Bayes Non-obese 314,384 141,264 313,957 141,209 314,357 141,167 314,080 141,106 314,273 141,413 Obese 121,468 343,619 121,586 344,114 121,661 343,790 121,539 343,733 121,587 343,883 Logistic Regression Non-obese 320,456 140,260 319,952 140,279 320,628 140,336 320,202 140,144 320,285 140,474 Obese 115,396 344,623 115,591 345,044 115,390 344,621 115,417 344,695 115,575 344,822 ML methods Classification prediction Fold 6 Test Fold 7 Test Fold 8 Test Fold 9 Test Fold 10 Test Real circumstances Non-obese Obese Non-obese Obese Non-obese Obese Non-obese Obese Non-obese Obese CART Non-obese 360,531 193,271 360,426 193,360 360,177 193,275 360,566 193,586 360,411 193,430 Obese 75,312 291,645 75,410 291,447 75,351 291,331 75,308 291,504 75,317 291,377 Na\\u00efve-Bayes Non-obese 314,356 141,221 314,273 141,183 314,030 141,113 314,239 141,296 314,234 141,345 Obese 121,487 343,695 121,563 343,624 121,498 343,493 121,635 343,794 121,494 343,462 Logistic Regression Non-obese 320,479 140,281 320,423 140,220 320,206 140,253 320,464 140,277 320,355 140,328 Obese 115,364 344,635 115,413 344,587 115,322 344,353 115,410 344,813 115,373 344,479 Frontiers in Nutrition | www.frontiersin.org 6 June 2021 | Volume 8 | Article 669155 \\fThamrin et al. Predicting Obesity Using Machine Learning TABLE 3 | Evaluation of classification prediction performance with 10-fold CV based on the obesity test data using 3 ML methods.\",\"827\":\"ML methods Test Accuracy (%) Sensitivity (%) Specificity (%) Precision (%) F1-Score (%) Kappa (%) AUC (%) F\\u03b2 =0.5 (%) CART 1-Fold 70.81 82.72 60.10 65.08 72.85 42.24 74.57 67.98 2-Fold 70.80 82.72 60.11 65.05 72.83 42.24 74.56 67.95 3-Fold 70.81 82.75 60.08 65.08 72.86 42.25 74.56 67.98 4-Fold 70.80 82.72 60.09 65.06 72.83 42.22 74.55 67.96 5-Fold 70.79 82.70 60.09 65.05 72.82 42.21 74.54 67.95 6-Fold 70.83 82.72 60.14 65.10 72.86 42.28 74.55 68.00 7-Fold 70.81 82.70 60.12 65.08 72.84 42.24 74.55 67.98 8-Fold 70.81 82.70 60.12 65.08 72.84 42.24 74.56 67.97 9-Fold 70.80 82.72 60.09 65.07 72.84 42.23 74.56 67.97 10-Fold 70.81 82.71 60.10 65.07 72.84 42.24 74.54 67.97 Na\\u00efve-Bayes 1-Fold 71.46 72.13 70.87 69.00 70.53 42.90 78.47 69.60 2-Fold 71.46 72.08 70.90 68.98 70.50 42.89 78.47 69.58 3-Fold 71.46 72.10 70.89 69.01 70.52 42.89 78.47 69.61 4-Fold 71.47 72.10 70.90 69.00 70.52 42.90 78.47 69.60 5-Fold 71.45 72.10 70.86 68.97 70.50 42.87 78.45 69.57 6-Fold 71.47 72.13 70.88 69.00 70.53 42.90 78.48 69.60 7-Fold 71.46 72.11 70.88 69.00 70.52 42.89 78.46 69.60 8-Fold 71.46 72.10 70.88 69.00 70.52 42.89 78.45 69.60 9-Fold 71.45 72.09 70.87 68.98 70.50 42.87 78.48 69.58 10-Fold 71.45 72.12 70.85 68.97 70.51 42.86 78.47 69.58 Logistic Regression 1-Fold 72.23 73.52 71.07 69.56 71.49 44.47 79.80 70.32 2-Fold 72.21 73.46 71.10 69.52 71.44 44.43 79.79 70.27 3-Fold 72.23 73.54 71.06 69.56 71.49 44.47 79.80 70.32 4-Fold 72.24 73.51 71.09 69.56 71.48 44.47 79.80 70.31 5-Fold 72.20 73.48 71.05 69.51 71.44 44.41 79.77 70.27 6-Fold 72.24 73.53 71.07 69.55 71.49 44.47 79.80 70.31 7-Fold 72.23 73.52 71.08 69.56 71.48 44.47 79.78 70.32 8-Fold 72.22 73.52 71.06 69.54 71.48 44.45 79.78 70.30 9-Fold 72.24 73.52 71.08 69.55 71.48 44.48 79.81 70.31 10-Fold 72.22 73.52 71.05 69.54 71.48 44.45 79.79 70.30 Bold values shows in which aspect does the ML methods performed best.\",\"828\":\"values can be classified into five different sections, namely 0.5\\u2013 0.6 (false accuracy), 0.6\\u20130.7 (poor accuracy), 0.7\\u20130.8 (moderate accuracy), 0.8\\u20130.9 (high accuracy), and 0.9\\u20131 (very high level of accuracy) (39).\",\"829\":\"RESULTS An overview of the explanatory variables contained in the obesity data of the Indonesia RISKESDAS 2018 survey is given in Table 1.\",\"830\":\"As can be seen from Table 1, out of 618,898 respondents, there are 134,709 (21.77%) people who are classified as obese, 484,189 (78.23%) people are non-obese.\",\"831\":\"In Table 1, it can also be seen that the number of obese (21.77%) and nonobese classes (78.23%) seems imbalanced.\",\"832\":\"Based on Table 1, the respondents in this study lived in rural areas (56.71%), married (76.31%), aged 35\\u201339 years (12.53%), finished senior high school (25.43%), unemployed (27.79%), consumed sugary foods 1\\u20132 times per week (28.63%), drank sweet drinks one time per day (31.57%), consumed salty foods 1\\u20132 times per week (27.54%), consumed fatty\\/oily foods 1\\u20132 times per week (26.61%), consumed grilled foods more than 3 times per month (32.68%), never consumed preserved foods (56.70%), consumed seasoning powders less that one time per day (36.74%), never drank soft\\/carbonated drinks (72.19%), never drank energy drinks (81.58%), experienced no mental emotional disorders (90.13%), consumed instant foods 1\\u20132 times per week (35.57%), drank non-alcoholic drinks (95.11%), diagnosed with no hypertension (50.97%), not adequate physical activity (88.09%), not a smoker (62.30%), and consumed inadequate fruit and vegetables (95.26%).\",\"833\":\"This general description of the obesity data can be seen in detail in Table 1.\",\"834\":\"Moreover, the obesity status description can be seen in detail in the Supplementary Table 2.\",\"835\":\"To overcome the oversampling of the prediction of this obesity status classification due to class imbalance in the dataset (Table 1), the SMOTE technique was used.\",\"836\":\"In this study, the SMOTE technique used two different percentages, namely 200% and 300%.\",\"837\":\"SMOTE with 300% can improve minor class data Frontiers in Nutrition | www.frontiersin.org 7 June 2021 | Volume 8 | Article 669155 \\fThamrin et al. Predicting Obesity Using Machine Learning FIGURE 1 | AUC performance of the classification methods with 10-fold CV using the CART method.\",\"838\":\"FIGURE 2 | AUC performance on the classification method with the 10-fold CV using the Na\\u00efve Bayes method.\",\"839\":\"better (from 21.77%, in the original dataset, to 47.3%).\",\"840\":\"As a result, the comparison between major class (non-obese) and minor class (obese) is balanced, namely 47.3% and 52.7%, respectively.\",\"841\":\"The new dataset resulting from the SMOTE technique with 300% was used to build a classification model and prediction of obesity risk factors.\",\"842\":\"Frontiers in Nutrition | www.frontiersin.org 8 June 2021 | Volume 8 | Article 669155 \\fThamrin et al. Predicting Obesity Using Machine Learning FIGURE 3 | AUC performance on the classification method with the 10-fold CV using the Logistic Regression method.\",\"843\":\"Using the three models (Logistic Regression model, CART, and Na\\u00efve Bayes), 10-fold CV was carried out to train and see which model performed better in predicting test set points on all data (Tables 2, 3).\",\"844\":\"This is also to ensure that all these new data resulting from the SMOTE technique are not bias in the result.\",\"845\":\"The prediction performance for the classification of obesity status from these methods is also assessed based on accuracy, sensitivity, specificity, precision, recall, F1-score, kappa, and F\\u03b2.\",\"846\":\"The measurement results of these metrics based on the 10-fold CV using ML methods for the obesity data set can be seen in Table 3.\",\"847\":\"Based on Table 3, the classification prediction using the Logistic Regression method achieves the best performance based on the accuracy metric (72%), specificity (71%), precision (69%), Kappa (44%), and F\\u03b2 (70%).\",\"848\":\"Classification prediction by the CART method achieves the highest sensitivity (82%) and the highest F1-score (72%).\",\"849\":\"Figures 1\\u20133 show AUC performance of the respective classification methods with 10-fold CV.\",\"850\":\"The results show that the Logistic Regression classifier has the highest average AUC values (0.798) (Figure 3).\",\"851\":\"In addition to comparing the AUC values obtained, the accuracy, sensitivity, specificity, precision, F1-Score, and F\\u03b2 values of each method can also be considered.\",\"852\":\"The AUC is a classification threshold invariant metric that measures the predictive quality of a model regardless of which classification threshold is selected.\",\"853\":\"After calculating the classification performance for correctly determining the obesity status for each of the 3 different models, it is also necessary to estimate a set of risk factors for obesity among the available study variables.\",\"854\":\"Based on the evaluation of classification prediction performance, the Logistic Regression method had the better performance compared with the CART method and the Na\\u00efve Bayes method.\",\"855\":\"Overall, fold 6 out of 10-fold CV showed the best accuracy for the classification performance of the obesity status.\",\"856\":\"Partial testing of parameters of the Logistic Regression model using the Wald test showed that all explanatory variables qualify as factors that can affect the obesity status (Table 4).\",\"857\":\"From Table 4, the variables that have the greatest effect on the obesity status in adults (p-value < 0.05) included location (X1), marital status (X2), age groups (X3), education (X4), sweet drinks (X7), fatty\\/oily foods (X9), grilled foods (X10), preserved foods (X11), seasoning powders (X12), soft\\/carbonated drinks (X13), alcoholic drinks (X16), mental emotional disorders (X17), diagnosed hypertension (X18), physical activity (X19), smoking (X20), and fruit and vegetables consumptions (X21).\",\"858\":\"In addition to the Logistic Regression method, prediction of obesity classification also used CART and Na\\u00efve Bayes methods.\",\"859\":\"From Figure 4, it can be seen that the characteristics of the variables that influence the occurrence of obesity in the Indonesia RISKESDAS 2018 are significant variables that function as the main partitioning of all the trees produced.\",\"860\":\"In this case, the main partitioning variables for 10% test data with fold 6 out of the 10-fold CV are alcoholic drinks (X16).\",\"861\":\"The order of important variables in this CART model are alcoholic drinks (X16), energy drinks (X14), soft\\/carbonated drinks (X13), mentalemotional disorders (X17), fruit and vegetables consumptions (X21), diagnosed hypertension (X18), physical activity (X19), and marital status (X2).\",\"862\":\"Obesity prediction using the Na\\u00efve Bayes model was also done by looking for values of P (Ci) for the obese class and P Cj \\u0001 for Frontiers in Nutrition | www.frontiersin.org 9 June 2021 | Volume 8 | Article 669155 \\fThamrin et al. Predicting Obesity Using Machine Learning TABLE 4 | Estimation of the Logistic Regression parameters based on fold 6 out of the 10-fold CV for obesity dataset in Indonesian RISKESDAS 2018 survey.\",\"863\":\"Descriptive of variables Fold 6 out of 10-fold CV Test \\u03b2 SE Wald p-Value Odd Ratio Constant 6.510 0.046 142.754 0.000 671.976 Location (X1) Rural \\u22120.305 0.005 \\u221259.121 0.000 0.737 Marital status (X2) Married \\u22120.363 0.007 \\u221250.033 0.000 0.695 Divorced 0.271 0.015 18.000 0.000 1.311 Widowed 0.289 0.012 24.963 0.000 1.335 Age groups (X3) 25\\u201329 years 0.488 0.010 46.674 0.000 1.630 30\\u201334 years 0.560 0.011 52.679 0.000 1.750 35\\u201339 years 0.680 0.011 64.375 0.000 1.975 40\\u201344 years 0.746 0.011 69.255 0.000 2.110 45\\u201349 years 0.741 0.011 67.743 0.000 2.097 50\\u201354 years 0.549 0.012 46.783 0.000 1.731 55\\u201359 years 0.333 0.013 26.349 0.000 1.396 60\\u201364 years 0.304 0.014 21.859 0.000 1.355 >64 years \\u22120.457 0.014 \\u221232.580 0.000 0.633 Education (X4) Not finished basic school 0.313 0.013 24.156 0.000 1.367 Finished basic school 0.361 0.012 29.692 0.000 1.435 Finished Junior High School 0.456 0.013 35.808 0.000 1.577 Finished Senior High School 0.469 0.012 38.083 0.000 1.598 Finished Academy\\/College 0.502 0.018 28.496 0.000 1.652 Finished higher education 0.506 0.015 33.432 0.000 1.659 Work types (X5) School \\u22120.356 0.018 \\u221219.850 0.000 0.700 Government employee 0.197 0.013 15.224 0.000 1.218 Private employee \\u22120.117 0.010 \\u221212.055 0.000 0.889 Entrepreneur 0.069 0.008 8.797 0.000 1.072 Farmer \\u22120.548 0.007 \\u221274.090 0.000 0.578 Fisherman \\u22120.838 0.024 \\u221235.437 0.000 0.432 Daily waged labors \\u22120.389 0.010 \\u221239.463 0.000 0.678 Others 0.010 0.010 0.987 0.324 1.010 Sugary foods (X6) 1 times per day \\u22120.135 0.009 \\u221215.096 0.000 0.874 3\\u20136 times per week \\u22120.141 0.009 \\u221215.938 0.000 0.869 1\\u20132 times per week \\u22120.158 0.009 \\u221218.457 0.000 0.854 <3 times per month 0.013 0.011 1.189 0.234 1.013 Never \\u22120.101 0.014 \\u22127.308 0.000 0.904 Sweet drinks (X7) 1 times per day 0.094 0.007 13.815 0.000 1.099 3\\u20136 times per week 0.148 0.008 17.454 0.000 1.159 1\\u20132 times per week 0.189 0.008 22.735 0.000 1.208 <3 times per month 0.313 0.012 26.572 0.000 1.368 Never 0.297 0.013 23.106 0.000 1.346 Salty foods (X8) 1 times per day 0.070 0.010 6.824 0.000 1.073 3\\u20136 times per week \\u22120.077 0.010 \\u22127.773 0.000 0.926 1\\u20132 times per week \\u22120.113 0.009 \\u221212.268 0.000 0.893 <3 times per month \\u22120.056 0.010 \\u22125.640 0.000 0.946 Never \\u22120.016 0.010 \\u22121.568 0.117 0.984 Fatty\\/Oily foods (X9) 1 times per day \\u22120.092 0.009 \\u221210.707 0.000 0.913 3\\u20136 times per week \\u22120.158 0.008 \\u221219.229 0.000 0.854 1\\u20132 times per week \\u22120.165 0.008 \\u221220.722 0.000 0.848 <3 times per month \\u22120.184 0.010 \\u221218.937 0.000 0.832 Never \\u22120.495 0.014 \\u221235.457 0.000 0.609 Grilled foods (X10) 1 times per day \\u22120.184 0.019 \\u22129.749 0.000 0.832 3\\u20136 times per week \\u22120.311 0.016 \\u221218.881 0.000 0.733 (Continued) Frontiers in Nutrition | www.frontiersin.org 10 June 2021 | Volume 8 | Article 669155 \\fThamrin et al. Predicting Obesity Using Machine Learning TABLE 4 | Continued Descriptive of variables Fold 6 out of 10-fold CV Test \\u03b2 SE Wald p-Value Odd Ratio 1\\u20132 times per week \\u22120.419 0.016 \\u221226.825 0.000 0.658 <3 times per month \\u22120.430 0.016 \\u221227.690 0.000 0.651 Never \\u22120.452 0.016 \\u221228.697 0.000 0.636 Preserved foods (X11) 1 times per day \\u22120.465 0.025 \\u221218.674 0.000 0.628 3\\u20136 times per week \\u22120.550 0.022 \\u221225.115 0.000 0.577 1\\u20132 times per week \\u22120.597 0.021 \\u221228.800 0.000 0.551 <3 times per month \\u22120.694 0.020 \\u221234.273 0.000 0.499 Never \\u22120.856 0.020 \\u221242.964 0.000 0.425 Seasonings powders (X12) 1 times per day 0.117 0.006 19.308 0.000 1.124 3\\u20136 times per week 0.276 0.010 27.709 0.000 1.318 1\\u20132 times per week 0.229 0.011 20.837 0.000 1.257 <3 times per month 0.582 0.013 46.073 0.000 1.789 Never 0.399 0.008 47.027 0.000 1.491 Soft\\/Carbonated drinks (X13) 1 times per day 0.313 0.032 9.805 0.000 1.368 3\\u20136 times per week 0.156 0.029 5.284 0.000 1.169 1\\u20132 times per week 0.073 0.028 2.621 0.009 1.076 <3 times per month \\u22120.158 0.027 \\u22125.753 0.000 0.854 Never \\u22120.457 0.027 \\u221216.900 0.000 0.633 Energy drinks (X14) 1 times per day 0.046 0.031 1.476 0.140 1.047 3\\u20136 times per week 0.020 0.029 0.681 0.496 1.020 1\\u20132 times per week \\u22120.032 0.027 \\u22121.185 0.236 0.968 <3 times per month \\u22120.095 0.027 \\u22123.549 0.000 0.909 Never \\u22120.713 0.026 \\u221227.394 0.000 0.490 Instant foods (X15) 1 times per day 0.010 0.019 0.512 0.609 1.010 3\\u20136 times per week 0.048 0.017 2.767 0.006 1.049 1\\u20132 times per week \\u22120.063 0.017 \\u22123.710 0.000 0.939 <3 times per month 0.084 0.017 4.901 0.000 1.088 Never \\u22120.009 0.018 \\u22120.533 0.594 0.991 Alcoholic drinks (X16) No \\u22121.576 0.008 \\u2212190.048 0.000 0.207 Mental-emotional disorders (X17) No \\u22121.029 0.007 \\u2212150.755 0.000 0.357 Diagnosed hypertension (X18) No \\u22120.867 0.009 \\u2212100.728 0.000 0.420 Unknown \\u22120.982 0.009 \\u2212110.600 0.000 0.375 Physical activity (X19) Not adequate \\u22120.852 0.007 \\u2212128.275 0.000 0.427 Smoking (X20) No 0.219 0.005 41.165 0.000 1.244 Fruit and vegetables consumptions (X21) Not adequate \\u22121.248 0.009 \\u2212135.504 0.000 0.287 the non-obese class.\",\"864\":\"In this case, the value of i = 1 and the value of j = 2.\",\"865\":\"The probability value for each variable on the class label is presented in detail in the Supplementary Table 3.\",\"866\":\"DISCUSSION We have conducted a study to establish a set of risk factors for obesity in adults among the available study variables using ML methods using publicly available data on RISKESDAS (RISKESDAS 2018).\",\"867\":\"In this study, three methods (Logistic Regression, CART, and Na\\u00efve Bayes) were used in the ML approach to select a method that produces predictions with high accuracy.\",\"868\":\"The result revealed that the Logistic Regression method shows a better accuracy compared to the other methods with AUC = 0.798 using 21 variables, namely location (X1), marital status (X2), age groups (X3), education (X4), work types (X5), sugary foods (X6), sweet drinks (X7), fatty\\/oily foods (X9), grilled foods (X10), preserved foods (X11), seasoning powders (X12), soft\\/carbonated drinks (X13), energy drinks (X14), instant foods (X15), alcoholic drinks (X16), mental emotional disorders (X17), diagnosed hypertension (X18), physical activity (X19), smoking (X20), and fruit and vegetables consumptions (X21).\",\"869\":\"With the accelerated economic growth and lifestyle changes around the world, including in Indonesia, it is important to evaluate and build predictive models for obesity using common risk factors.\",\"870\":\"Based on RISKESDAS 2013 and 2018, Indonesia as a middle-income country seems to underestimate the significance of actual obesity cases even though there has Frontiers in Nutrition | www.frontiersin.org 11 June 2021 | Volume 8 | Article 669155 \\fThamrin et al. Predicting Obesity Using Machine Learning FIGURE 4 | Obesity data classification tree for fold 6 out of the 10-fold CV for CART model based on the variables of alcoholic drinks (X16), energy drinks (X14), soft\\/carbonated drinks (X13), mental-emotional disorders (X17), Fruit and Vegetables Consumptions (X21), diagnosed hypertension (X18), Physical Activity (X19), and Marital Status (X2).\",\"871\":\"been a significant increase in cases.\",\"872\":\"As shown in this study, the 21 selected measures play a prominent role in increasing the risk for obesity in adults.\",\"873\":\"This is in parallel with some previous studies.\",\"874\":\"In their study, Roemling and Qaim (4) found that obesity risk in Indonesia occurred both in rural and urban areas and was closely associated with food consumption pattern changes coupled with physical activity decreases.\",\"875\":\"Rachmi et al. (5) showed that the increasing prevalence of overweight children, adolescents, and adults in Indonesia over the past two decades coincides with higher numbers of obesity in urban areas.\",\"876\":\"Similarly, Oddo et al. (6) demonstrated that there were more obesity cases in rural areas compared to the past even though the overall case numbers are still higher in urban areas in Indonesia.\",\"877\":\"They also showed that highly processed foods are mostly consumed and decreased physical activities have led to the higher prevalence of obesity.\",\"878\":\"Dewi et al. (7) found that the consumption of oil and fat, animal source foods, and low physical activities are some of the significant determinants of obesity in Indonesia.\",\"879\":\"Emery et al. (40) revealed that there was a relationship between less healthy food consumption with obesity.\",\"880\":\"Sinha and Jastreboff (41) found that eating habits and the increased consumption of food result from stress.\",\"881\":\"Koski and Naukkarinen (42) strengthened the fact that the development of obesity is significantly due to persistent stress.\",\"882\":\"The difference in confounding factors involved in the analysis is one of the reasons for the differences found in this study with previous studies.\",\"883\":\"In this study, we employed the metrics for accuracy, sensitivity, specificity, precision, recall, F1-score, kappa, and F\\u03b2 with 10-fold CV for performance evaluation of the three classification methods.\",\"884\":\"The results obtained are the prediction of the classification with 10-fold CV using the Logistic Regression method, which achieved the best performance as assessed by the accuracy metric (72%), specificity (71%), precision (69%), kappa (44%), and F\\u03b2=0.5 (70%).\",\"885\":\"Classification prediction by the CART method achieved the highest sensitivity (82%), and F1-score (72%).\",\"886\":\"The Na\\u00efve Bayes method had an accuracy of 71% and a F\\u03b2=0.5 of 69%.\",\"887\":\"Frontiers in Nutrition | www.frontiersin.org 12 June 2021 | Volume 8 | Article 669155 \\fThamrin et al. Predicting Obesity Using Machine Learning In general, this ML approach is an alternative to the classical methods used so far (22).\",\"888\":\"Using ML methods on public health data can help to improve predictions and find a rich structure among available data and increase understanding of complex problems in public health, including risk factors for obesity with ML.\",\"889\":\"The ML method could inform the design of more appropriate health policies and programs to address NonCommunicable Diseases, most notably in predicting obesity incidence\\/prevalence, and in turn, reducing severity as well as the cost of treating obesity and obesity-related condition which eventually could improve the health and well-being of the population.\",\"890\":\"Apart from that, the ML method as shown in the current study could be utilized to identify the most significant risk factors for predicting obesity status can be applied to publicly available data, such as RISKESDAS data.\",\"891\":\"In general, RISKESDAS provides an overview of Indonesian health indicators, such as health status, health services, health behavior, and environmental health.\",\"892\":\"RISKESDAS is supposedly the best data available on health in Indonesia but its main limitation is the fact that the purpose and nature of RISKESDAS are based on a periodic study (every 5 years) examining a broad range of health issues and health behaviors.\",\"893\":\"This then results in a data set that lacks depth.\",\"894\":\"In Indonesia, policies on obesity prevention and control in adults are related to limiting consumption of fats and oils, sugary foods and carbohydrates, and increasing vegetable intake are carried out through the Health Community Movement, known as GERMAS and the Food Label with the inclusion of sugar, salt, and fat content on food labels (7).\",\"895\":\"Yet, these efforts seem to be ineffective as the increase in the proportion of obesity remains relatively high.\",\"896\":\"The findings of this study in predicting the risk factor for obesity among the available study variables on RISKESDAS 2018 can then convince the policy makers in Indonesia (primarily the government) to put more attention into the pressing obesity problems.\",\"897\":\"As a result, the effectiveness of existing program policies could be further improved and the financing of the health care system can be made more efficient (43).\",\"898\":\"This study provides an overview of the methods available for predicting risk factors for obesity in adults among the available study variables in Indonesia.\",\"899\":\"Several factors that might influence obesity (e.g., sex, dietary quality, clinical and physiological, wealth, genetic and cultural influences) were not included in this study, and thereby, the relationship between these factors and obesity cannot be explained further.\",\"900\":\"Further research needs to be carried out using large datasets with individual subjects to confirm the results of this study and to describe the variation in the results for individual regions.\",\"901\":\"CONCLUSION The Logistic Regression method showed better results on the accuracy, specificity, precision, kappa, and F\\u03b2 metrics.\",\"902\":\"Meanwhile, the CART method showed better results on the sensitivity, recall, and F1-score.\",\"903\":\"For the 10-fold CV, the Logistic Regression method had the highest AUC performance which was 0.798.\",\"904\":\"Then, from the Logistic Regression method, it can also be seen that the variables that affect the prediction of obesity status in adults are location, marital status, age groups, education, sweet drinks, fatty\\/oily foods, grilled foods, preserved foods, seasoning powders, soft\\/carbonated drinks, alcoholic drinks, mental emotional disorders, diagnosed hypertension, physical activity, smoking, and fruit and vegetables consumptions.\",\"905\":\"The constructed obesity classification model can evaluate and predict the risk of obesity using ML methods for the population of Indonesia which can then be applied to publicly available open data, such as the RISKESDAS survey data.\",\"906\":\"In general, this study has been able to establish a set of risk factors for obesity in adults among the available study variables.\",\"907\":\"However, more studies should be done to further improve the quality of predictions by exploring other ML models.\",\"908\":\"In the future work, we will validate the results with other relevant groups.\",\"909\":\"Additionally, we will also evaluate differences in the prediction of obesity status at the district\\/city or province level in Indonesia with regional disaggregation.\",\"910\":\"DATA AVAILABILITY STATEMENT Publicly available datasets were analyzed in this study.\",\"911\":\"This data can be found at: https:\\/\\/www.litbang.kemkes.go.id\\/layananpermintaan-data-riset.\",\"912\":\"AUTHOR CONTRIBUTIONS ST contributed to the concept and design of the study, carried out the statistical analysis, and wrote the manuscript.\",\"913\":\"DA interpreted the data, analyzed, and wrote the manuscript.\",\"914\":\"HK collected the necessary data and carried out the statistical analysis.\",\"915\":\"AL interpreted the data and analyzed the manuscript.\",\"916\":\"SN analyzed and wrote the manuscript.\",\"917\":\"All authors read and approved the final manuscript.\",\"918\":\"FUNDING This research was funded by the Ministry of Research, Technology\\/National Research, and Innovation Agency of Indonesia through Grant PDUPT Hasanuddin University in 2020 with the number 1516\\/UN4.22\\/PT.01.03\\/2020.\",\"919\":\"ACKNOWLEDGMENTS ST would like to thank the Ministry of Research and Technology\\/National Research and Innovation Agency for funding this research through the PDUPT Scheme for the 2020 fiscal year.\",\"920\":\"In addition, the authors would also like to thank the Ministry of Health through the Community Research and Development Agency for providing access to the Indonesian RISKESDAS survey data.\",\"921\":\"SUPPLEMENTARY MATERIAL The Supplementary Material for this article can be found online at: https:\\/\\/www.frontiersin.org\\/articles\\/10.3389\\/fnut.2021.\",\"922\":\"669155\\/full#supplementary-material Frontiers in Nutrition | www.frontiersin.org 13 June 2021 | Volume 8 | Article 669155 \\fThamrin et al. Predicting Obesity Using Machine Learning REFERENCES 1.\",\"923\":\"ASEAN\\/UNICEF\\/WHO Regional Report.\",\"924\":\"World Health Statistics 2016: Monitoring Health for the SDGs, Sustainable Development Goals.\",\"925\":\"(2016).\",\"926\":\"Available online at: https:\\/\\/www.who.int\\/about\\/licensing\\/copyright_form\\/en\\/ index.html 2.\",\"927\":\"Institute of Health Research and Development.\",\"928\":\"Basic Health Research Reports.\",\"929\":\"(2013).\",\"930\":\"Available online at: https:\\/\\/www.litbang.kemkes.go.id\\/laporan-risetkesehatan-dasar-riskesdas\\/ 3.\",\"931\":\"Institute of Health Research and Development.\",\"932\":\"Basic Health Research Reports.\",\"933\":\"(2018).\",\"934\":\"Available online at: http:\\/\\/labdata.litbang.kemkes.go.id\\/ images\\/download\\/laporan\\/RKD\\/2013\\/Laporan_riskesdas_2013_final.pdf 4.\",\"935\":\"Roemling C, Qaim M.\",\"936\":\"Obesity trends and determinants in Indonesia.\",\"937\":\"Appetite.\",\"938\":\"(2012) 58:1005\\u201313.\",\"939\":\"doi: 10.1016\\/j.appet.2012.02.053 5.\",\"940\":\"Rachmi CN, Li M, Alison Baur L.\",\"941\":\"Overweight and obesity in Indonesia: prevalence and risk factors-a literature review.\",\"942\":\"Public Health.\",\"943\":\"(2017) 147:20\\u20139.\",\"944\":\"doi: 10.1016\\/j.puhe.2017.02.002 6.\",\"945\":\"Oddo VM, Maehara M, Rah JH.\",\"946\":\"Overweight in Indonesia: an observational study of trends and risk factors among adults and children.\",\"947\":\"BMJ Open.\",\"948\":\"(2019) 9:e031198.\",\"949\":\"doi: 10.1136\\/bmjopen-2019-031198 7.\",\"950\":\"Dewi NU, Tanziha I, Solechah SA, Bohari B.\",\"951\":\"Obesity determinants and the policy implications for the prevention and management of obesity in Indonesia.\",\"952\":\"Curr Res Nutr Food Sci J.\",\"953\":\"(2020) 8:942\\u201355.\",\"954\":\"doi: 10.12944\\/CRNFS.8.3.22 8.\",\"955\":\"Wiemken TL, Kelley RR. Machine learning in epidemiology and health outcomes research.\",\"956\":\"Annu Rev Public Health.\",\"957\":\"(2020) 41:21\\u201336.\",\"958\":\"doi: 10.1146\\/annurev-publhealth-040119-094437 9.\",\"959\":\"Giabbanelli PJ, Adams J. Identifying small groups of foods that can predict achievement of key dietary recommendations: data mining of the UK National Diet and Nutrition Survey, 2008\\u201312.\",\"960\":\"Public Health Nutr.\",\"961\":\"(2016) 19:1543\\u201351.\",\"962\":\"doi: 10.1017\\/S1368980016000185 10.\",\"963\":\"Dugan TM, Mukhopadhyay S, Carroll A, Downs S.\",\"964\":\"Machine learning techniques for prediction of early childhood obesity.\",\"965\":\"Appl Clin Inform.\",\"966\":\"(2015) 6:506\\u201320.\",\"967\":\"doi: 10.4338\\/ACI-2015-03-RA-0036 11.\",\"968\":\"Nau C, Ellis H, Huang H, Schwartz BS, Hirsch A, Bailey-Davis L, et al.\",\"969\":\"Exploring the forest instead of the trees: an innovative method for defining obesogenic and obesoprotective environments.\",\"970\":\"Health Place.\",\"971\":\"(2015) 35:136\\u2013 46.\",\"972\":\"doi: 10.1016\\/j.healthplace.2015.08.002 12.\",\"973\":\"Acharjee A, Ament Z, West JA, Stanley E, Griffin JL.\",\"974\":\"Integration of metabolomics, lipidomics and clinical data using a machine learning method.\",\"975\":\"BMC Bioinformatics.\",\"976\":\"(2016) 17:440.\",\"977\":\"doi: 10.1186\\/s12859-0161292-2 13.\",\"978\":\"Selya AS, Anshutz D. Machine learning for the classification of obesity from dietary and physical activity patterns.\",\"979\":\"In: Giabbanelli P, Mago V, Papageorgiou E, editors.\",\"980\":\"Advanced Data Analytics in Health.\",\"981\":\"Springer (2018).\",\"982\":\"p.\",\"983\":\"77\\u201397.\",\"984\":\"Available online at: http:\\/\\/doi-org-443.webvpn.fjmu.edu.cn\\/10.1007\\/978-3319-77911-9_5 14.\",\"985\":\"Zhang S, Tjortjis C, Zeng X, Qiao H, Buchan I, Keane J.\",\"986\":\"Comparing data mining methods with logistic regression in childhood obesity prediction.\",\"987\":\"Inform Syst Front.\",\"988\":\"(2009) 11:449\\u201360.\",\"989\":\"doi: 10.1007\\/s10796-0099157-0 15.\",\"990\":\"Adnan MHBM, Husain W, Rashid NA.\",\"991\":\"Parameter identification and selection for childhood obesity prediction using data mining.\",\"992\":\"In: 2nd International Conference on Management and Artificial Intelligence.\",\"993\":\"Singapore (2012).\",\"994\":\"p.\",\"995\":\"7.\",\"996\":\"16.\",\"997\":\"Toschke AM, Beyerlein A, Von Kries R.\",\"998\":\"Children at high risk for overweight: a classification and regression trees analysis approach.\",\"999\":\"Obes Res.\",\"1000\":\"(2005) 13:1270\\u20134.\",\"1001\":\"doi: 10.1038\\/oby.2005.151 17.\",\"1002\":\"Golino HF, Amaral LSB, Duarte SFP, Gomes CMA, Soares J, Reis LA, et al. Predicting increased blood pressure using machine learning.\",\"1003\":\"J Obes.\",\"1004\":\"(2014) 2014:637635.\",\"1005\":\"doi: 10.1155\\/2014\\/637635 18.\",\"1006\":\"Zheng Z, Ruggiero K. Using machine learning to predict obesity in high school students.\",\"1007\":\"In: 2017 IEEE International Conference on Bioinformatics and Biomedicine (BIBM).\",\"1008\":\"Kansas (2017).\",\"1009\":\"p.\",\"1010\":\"2132\\u20132138.\",\"1011\":\"doi: 10.1109\\/BIBM.2017.8217988 19.\",\"1012\":\"Chatterjee A, Gerdes MW, Martinez SG.\",\"1013\":\"Identification of risk factors associated with obesity and overweight\\u2013a machine learning overview.\",\"1014\":\"Sensors.\",\"1015\":\"(2020) 20:2734.\",\"1016\":\"doi: 10.3390\\/s20092734 20.\",\"1017\":\"Singh B, Tawfik H.\",\"1018\":\"Machine learning approach for the early prediction of the risk of overweight and obesity in young people.\",\"1019\":\"Comput Sci ICCS 2020.\",\"1020\":\"(2020).\",\"1021\":\"12140:523\\u201335.\",\"1022\":\"doi: 10.1007\\/978-3-030-50423-6_39 21.\",\"1023\":\"Colmenarejo G.\",\"1024\":\"Machine learning models to predict childhood and adolescent obesity: a review.\",\"1025\":\"Nutrients.\",\"1026\":\"(2020) 12:2466.\",\"1027\":\"doi: 10.3390\\/nu12082466 22.\",\"1028\":\"DeGregory KW, Kuiper P, DeSilvio T, Pleuss JD, Miller R, Roginski JW, et al. A review of machine learning in obesity.\",\"1029\":\"Obes Rev.\",\"1030\":\"(2018) 19:668\\u201385.\",\"1031\":\"doi: 10.1111\\/obr.12667 23.\",\"1032\":\"Wickham H, Fran\\u00e7ois R, Henry L, M\\u00fcller K. dplyr: A Grammar of Data Manipulation.\",\"1033\":\"R package version 0.7.6 (2018).\",\"1034\":\"Available online at: https:\\/\\/cran.\",\"1035\":\"r-project.org\\/package=dplyr 24.\",\"1036\":\"Blum AL, Langley P.\",\"1037\":\"Selection of relevant features and examples in machine learning.\",\"1038\":\"Artif Intell.\",\"1039\":\"(1997) 97:245\\u201371.\",\"1040\":\"doi: 10.1016\\/S0004-3702(97)00063-5 25.\",\"1041\":\"R Core Team.\",\"1042\":\"R: A Language and Environment for Statistical Computing.\",\"1043\":\"Vienna: R Foundation for Statistical Computing (2020).\",\"1044\":\"26.\",\"1045\":\"Chawla NV, Bowyer KW, Hall LO, Kegelmeyer WP. SMOTE: synthetic minority over-sampling technique.\",\"1046\":\"J Artif Intell Res.\",\"1047\":\"(2002) 16:321\\u201357.\",\"1048\":\"doi: 10.1613\\/jair.953 27.\",\"1049\":\"Chawla NV.\",\"1050\":\"Data mining for imbalanced datasets: an overview.\",\"1051\":\"In: Maimon O, Rokach L, editors.\",\"1052\":\"Data Mining and Knowledge Discovery Handbook.\",\"1053\":\"Boston, MA: Springer (2005).\",\"1054\":\"p.\",\"1055\":\"853\\u201367.\",\"1056\":\"doi: 10.1007\\/0-38725465-X_40 28.\",\"1057\":\"Blagus R, Lusa L.\",\"1058\":\"Joint use of over- and under-sampling techniques and cross-validation for the development and assessment of prediction models.\",\"1059\":\"BMC Bioinformatics.\",\"1060\":\"(2015) 16:363.\",\"1061\":\"doi: 10.1186\\/s12859-0150784-9 29.\",\"1062\":\"Alghamdi M, Al-Mallah M, Keteyian S, Brawner C, Ehrman J, Sakr S.\",\"1063\":\"Predicting diabetes mellitus using SMOTE and ensemble machine learning approach: the Henry Ford ExercIse Testing (FIT) project.\",\"1064\":\"PLoS ONE.\",\"1065\":\"(2017) 12:e0179805.\",\"1066\":\"doi: 10.1371\\/journal.pone.0179805 30.\",\"1067\":\"Cost S, Salzberg S.\",\"1068\":\"A weighted nearest neighbor algorithm for learning with symbolic features.\",\"1069\":\"Mach Learn.\",\"1070\":\"(1993) 10:57\\u201378.\",\"1071\":\"doi: 10.1023\\/A:1022664626993 31.\",\"1072\":\"Hastie T, Tibshirani R, Friedman J.\",\"1073\":\"The Elements of Statistical Learning: Data Mining, Inference, and Prediction.\",\"1074\":\"Springer-Verlag (2009).\",\"1075\":\"Available online at: https:\\/\\/web.stanford.edu\\/~hastie\\/ElemStatLearn\\/ 32.\",\"1076\":\"Bishop C.\",\"1077\":\"Pattern Recognition and Machine Learning.\",\"1078\":\"Springer-Verlag New York (2006).\",\"1079\":\"Available online at: https:\\/\\/www.springer.com\\/gp\\/book\\/ 9780387310732 33.\",\"1080\":\"Breiman L, Friedman JH, Olshen RA, Stone CJ.\",\"1081\":\"Classification and Regression Trees.\",\"1082\":\"Washington, DC: Chapman & Hall; CRC (1984).\",\"1083\":\"34.\",\"1084\":\"Han J, Kamber M, Pei J.\",\"1085\":\"Data mining: Concepts and Techniques, 3rd ed. Morgan Kaufmann Publishers (2012).\",\"1086\":\"Available online at: http:\\/\\/myweb.\",\"1087\":\"sabanciuniv.edu\\/rdehkharghani\\/files\\/2016\\/02\\/The-Morgan-KaufmannSeries-in-Data-Management-Systems-Jiawei-Han-Micheline-KamberJian-Pei-Data-Mining.-Concepts-and-Techniques-3rd-Edition-MorganKaufmann-2011.pdf 35.\",\"1088\":\"Refaeilzadeh P, Tang L, Liu H.\",\"1089\":\"Cross-validation.\",\"1090\":\"In: LIU L, \\u00d6ZSU MT, editors.\",\"1091\":\"Encyclopedia of Database Systems.\",\"1092\":\"Boston, MA: Springer (2009).\",\"1093\":\"p.\",\"1094\":\"24.\",\"1095\":\"doi: 10.1007\\/978-0-387-39940-9 36.\",\"1096\":\"Liu B, Fang L, Liu F, Wang X, Chen J, Chou KC.\",\"1097\":\"Identification of real microRNA precursors with a pseudo structure status composition approach.\",\"1098\":\"PLoS ONE.\",\"1099\":\"(2015) 10:e0121501.\",\"1100\":\"doi: 10.1371\\/journal.pone.0121501 37.\",\"1101\":\"Nguyen GH, Bouzerdoum A, Phung SL. Learning Pattern Classification Tasks with Imbalanced Data Sets.\",\"1102\":\"London: IntechOpen (2009).\",\"1103\":\"doi: 10.5772\\/ 7544 38.\",\"1104\":\"Landis J, Koch G.\",\"1105\":\"The measurement of observer agreement for categorical data.\",\"1106\":\"Biometrics.\",\"1107\":\"(1977) 33:159\\u201374.\",\"1108\":\"doi: 10.2307\\/2529310 39.\",\"1109\":\"Brefeld U, Scheffer T. AUC maximizing support vector learning.\",\"1110\":\"In: Ferri C, Lachiche N, Macskassy S, Rakotomamonjy A, editors.\",\"1111\":\"Proceedings of the 2nd Workshop on ROC Analysis in Machine Learning (ROCML 2005).\",\"1112\":\"(2005).\",\"1113\":\"Available online at: https:\\/\\/citeseerx.ist.psu.edu\\/viewdoc\\/download?doi=10.1.1.59.7864&rep=rep1 &type=pdf 40.\",\"1114\":\"Emery CF, Olson KL, Lee VS, Habash DL, Nasar JL, Bodine A. Home environment and psychosocial predictors of obesity status among community-residing men and women.\",\"1115\":\"Int J Obes.\",\"1116\":\"(2015) 39:1401\\u20137.\",\"1117\":\"doi: 10.1038\\/ijo.2015.70 Frontiers in Nutrition | www.frontiersin.org 14 June 2021 | Volume 8 | Article 669155 \\fThamrin et al. Predicting Obesity Using Machine Learning 41.\",\"1118\":\"Sinha R, Jastreboff AM.\",\"1119\":\"Stress as a common risk factor for obesity and addiction.\",\"1120\":\"Biol Psychiatry.\",\"1121\":\"(2013) 73:827\\u201335.\",\"1122\":\"doi: 10.1016\\/j.biopsych.2013.01.032 42.\",\"1123\":\"Koski M, Naukkarinen H.\",\"1124\":\"The relationship between stress and severe obesity: a case-control study.\",\"1125\":\"Biomed Hub. (2017) 2:1\\u201313.\",\"1126\":\"doi: 10.1159\\/000 458771 43.\",\"1127\":\"Yu H, Chris K, Junxiu L, Yujin L, Jonathan PS, Brendan C. Cost-effectiveness of the US food and drug administration added sugar labeling policy for improving diet and health.\",\"1128\":\"Circulation.\",\"1129\":\"(2019) 139:2613\\u201324.\",\"1130\":\"doi: 10.1161\\/CIRCULATIONAHA.118.\",\"1131\":\"036751 Conflict of Interest: The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\",\"1132\":\"Copyright \\u00a9 2021 Thamrin, Arsyad, Kuswanto, Lawi and Nasir.\",\"1133\":\"This is an openaccess article distributed under the terms of the Creative Commons Attribution License (CC BY).\",\"1134\":\"The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice.\",\"1135\":\"No use, distribution or reproduction is permitted which does not comply with these terms.\",\"1136\":\"Frontiers in Nutrition | www.frontiersin.org 15 June 2021 | Volume 8 | Article 669155\",\"1137\":\"\\u00a9 2019 Eduardo De-La-Hoz-Correa, Fabio E. Mendoza-Palechor, Alexis De-La-Hoz-Manotas, Roberto C. Morales-Ortega and S\\u00e1nchez Hern\\u00e1ndez Beatriz Adriana.\",\"1138\":\"This open access article is distributed under a Creative Commons Attribution (CCBY) 3.0 license.\",\"1139\":\"Journal of Computer Science Original Research Paper Obesity Level Estimation Software based on Decision Trees 1 Eduardo De-La-Hoz-Correa, 2 Fabio E. Mendoza-Palechor, 2 Alexis De-La-Hoz-Manotas, 2 Roberto C. Morales-Ortega and 2 S\\u00e1nchez Hern\\u00e1ndez Beatriz Adriana 1 Corporaci\\u00f3n Universitaria Americana, Colombia 2 Universidad de la Costa, Colombia Article history Received: 20-06-2018 Revised: 20-11-2018 Accepted: 7-01-2019 Corresponding Author: Roberto C. Morales-Ortega Universidad de la Costa, Colombia Email: rmorales1@cuc.edu.co Abstract: Obesity has become a global epidemic that has doubled since 1980, with serious consequences for health in children, teenagers and adults.\",\"1140\":\"Obesity is a problem has been growing steadily and that is why every day appear new studies involving children obesity, especially those looking for influence factors and how to predict emergence of the condition under these factors.\",\"1141\":\"In this study, authors applied the SEMMA data mining methodology, to select, explore and model the data set and then three methods were selected: Decision trees (J48), Bayesian networks (Na\\u00efve Bayes) and Logistic Regression (Simple Logistic), obtaining the best results with J48 based on the metrics: Precision, recall, TP Rate and FP Rate.\",\"1142\":\"Finally, a software was built to use and train the selected method, using the Weka library.\",\"1143\":\"The results confirmed the Decision Trees technique has the best precision rate (97.4%), improving results of previous studies with similar background.\",\"1144\":\"Keywords: Obesity, Data Mining, Semma, Decision Trees, Naive Bayes, Logistic Regression, Weka, Java Introduction The World Health Organization (WHO) (OMS, 2016), describes obesity and overweight as excessive fat accumulation in certain body areas that can be harmful for health, the number of people that suffers from obesity has doubled since 1980 and also in 2014 more than 1900 million adults, 18 years old or older, are suffering from alteration of their weight.\",\"1145\":\"Some of the causes of overweight are the increase of intake of energy dense foods that are high in fat and decrease in physical activity due to the nature of a sedentary types of work, the new transportation modes and increasing urbanization.\",\"1146\":\"According to (Guti\\u00e9rrez, 2010), obesity is a public health problem worldwide and it can emerge in adults, teens and children.\",\"1147\":\"Hern\\u00e1ndez (2011), the authors show that obesity can be considered a disease with multiple factors, having as symptom, the uncontrolled increase of weight, due excessive intake of fat and energy consumption.\",\"1148\":\"Obesity can be caused by biological hazard factors such as hereditary background, so there can be several kinds of obesity as: Monogenic, leptin, polygenic and syndromic.\",\"1149\":\"Besides, there are other risk factors as social, psychological and eating habits as mentioned by (Zhingre and del Cisne, 2015).\",\"1150\":\"On the other side, authors as (Olmedo, 2011) propose other determining factors for obesity such as \\u201cbeing only child, family conflicts as divorce, depression and anxiety\\u201d.\",\"1151\":\"Based on the previous statements and the literature you can find in many studies working the obesity influence factors, they have implemented several data mining techniques as you can find in (Davila-Payan et al., 2015; Manna and Jewkes, 2014; Adnan and Husain, 2012; 2011; Adnan et al., 2010; Dugan et al., 2015; Zhang et al., 2009; Suguna, 2016; Abdullah et al., 2016).\",\"1152\":\"Data mining is a discipline that studies massive data sources, with the objective of obtaining new information from it, to support decision making.\",\"1153\":\"Several authors have studies to analyze the disease and generate web tools to calculate the obesity level of a person, nevertheless such tools are limited to the calculation of the body mass index, omitting relevant factors such as family background and time dedicated to.\",\"1154\":\"Based on this, the authors considered an intelligent tool was needed to be able to detect obesity levels on people more efficiently.\",\"1155\":\"This study had the objective of implementing several data mining techniques to determine if one person suffers from obesity.\",\"1156\":\"The methodology of the study was: Analysis of previous studies, creation of the dataset, analysis of data mining techniques, design and implementation of the estimation obesity tool, results and conclusions.\",\"1157\":\"Eduardo De-La-Hoz-Correa et al. \\/ Journal of Computer Science 2019, 15 (1): 67.77 DOI: 10.3844\\/jcssp.2019.67.77 68 Previous Works Obesity has become an area of interest for research and many studies can be found working with the factors that produce the disease.\",\"1158\":\"Next, you can find a brief review of works proposed by different authors that implement data mining techniques on datasets with attributes related with this health issue.\",\"1159\":\"Davila-Payan et al. (2015), a logistic regression model was presented to estimate the probability of body mass index on children from 2 to 17 years old in small geographic areas.\",\"1160\":\"Their results confirmed that estimates in small geographic areas are essential to generate effective interventions and to help planning of possible solutions to the problem.\",\"1161\":\"Manna and Jewkes (2014), a computational model was presented using fuzzy signature to understand and manage intricacies on the data of children obesity and a solution that could handle the risk associated with early obesity and children motor development.\",\"1162\":\"Their study used fuzz signatures based on fuzzy logic, a computational paradigm that provides a mathematical tool to handle uncertainty and imprecision, quite common in human reasoning.\",\"1163\":\"Adnan and Husain (2012), a framework was presented with a hybrid approach, based on Na\\u00efve Bayes for prediction and genetic algorithms for parameter optimization, applied to the problem of predicting children obesity, with a low rate of negative samples compared to positive samples.\",\"1164\":\"As result, they obtained 19 parameters to be implemented in prediction with a precision of 75%.\",\"1165\":\"Adnan and Husain (2011), they had an initial approach to the study of predicting children obesity, collecting information from primary sources: Parents, children and caretakers.\",\"1166\":\"The authors identified risk factors such as: Obesity and level of education of the parents, lifestyle and habits of the children and influence of environment.\",\"1167\":\"The proposed framework uses a hybrid technique of Na\\u00efve Bayes and decision trees called NBTree.\",\"1168\":\"Adnan et al. (2010), the study used data mining to predict children obesity.\",\"1169\":\"The purpose of the proposed survey was to provide the necessary knowledge for the obesity problem, introduce data mining for prediction, describe the current efforts in that area and show the benefits and weaknesses of each technique used.\",\"1170\":\"The techniques involved were Neural Networks, Na\\u00efve Bayes and Decision Trees.\",\"1171\":\"Dugan et al. (2015), the authors generated a predictive study of children obesity with subjects older than 2 years old, using exclusively the data previous to their second birthday using a decision-making system called CHICA.\",\"1172\":\"The methods analyzed included: RandomTree, RandomForest, J48, ID3, Na\\u00efve Bayes and Bayes.\",\"1173\":\"Their results showed that ID3 had better behavior with 85% in precision and 89% in sensibility.\",\"1174\":\"Zhang et al. (2009), the authors presented a comparison of logistic regression with six data mining techniques for children overweight and obesity prediction in 3-year-old subjects, using data at birth, at six weeks, at 8 months and two years old respectively.\",\"1175\":\"Authors noticed an improvement in the precision of prediction in the cases of 8 months and 2 years old in more than 10%.\",\"1176\":\"The techniques used were Decision Trees, Association Rules, Neural Networks, Na\\u00efve Bayes, Bayesian Networks and Support Vector Machines.\",\"1177\":\"Suguna (2016), the authors provided a framework using the Child and Adolescent Health Measurement Initiative (CAHMI) dataset, that analyzed obesity in children between 10 and 17 years old.\",\"1178\":\"The proposed model uses Decision Trees with three different algorithms: Simple Cart, J47 and NB Tree.\",\"1179\":\"Abdullah et al. (2016), the study showed a children obesity classification in grade school 6, from two different Malaysia districts.\",\"1180\":\"From the information collected, the authors created 4245 full datasets and they applied the classification techniques: Bayesian Networks, Decision Trees, Neural Networks and Support Vector Machines (SVM).\",\"1181\":\"Husain et al. (2013), the authors presented MyHealthyKids, an intervention system for primary schools with the goal of handling and reducing children obesity problems.\",\"1182\":\"The system was composed of three modules: Obesity prediction, persuasion and recipe suggestion.\",\"1183\":\"The prediction module was based on Na\\u00efve Bayes to identify children that are prone to obesity.\",\"1184\":\"Tests showed that the system had a precision of 73.3% and great response from children.\",\"1185\":\"Materials and Methods This study used data related with young undergraduate students between 18 and 25 years old, including nationals from Colombia, Mexico and Per\\u00fa.\",\"1186\":\"The size of the sample was 712 records, based on the surveys applied to 324 men and 388 women.\",\"1187\":\"To initiate the process of collecting information, it was necessary to select the right number of students and they were surveyed with a series of questions to identify their obesity level, considering several factors such as age, weight, sex, physical activity frequency, fast food intake and others, that could help to describe the behavior of obese people.\",\"1188\":\"With the information gathered by the survey, it was possible to create a dataset and then the authors performed several types of analysis to discover patterns about the factors that influence the emergence of obesity in young students.\",\"1189\":\"The methods and techniques used in the experimentation process of this study, refer to Decision Trees, Na\\u00efve Bayes and Logistic Regression.\",\"1190\":\"To identify the obesity levels, we used the table provided by WHO (Table 1), to categorize correctly the data analyzed based on the BMI.\",\"1191\":\"Eduardo De-La-Hoz-Correa et al. \\/ Journal of Computer Science 2019, 15 (1): 67.77 DOI: 10.3844\\/jcssp.2019.67.77 69 Dataset The main causes for development of obesity are related to a high intake of calories, decrease of energy consumption (due to lack of physical activity), genetics, socio-economic factors and\\/or anxiety and depression, according to (G\\u00f3mez and \\u00c1vila, 2008).\",\"1192\":\"To create the dataset, first we searched for literary sources with the purpose of identify the main factors or habits that contribute to obesity.\",\"1193\":\"The dataset generated had 18 variables that make possible to determine if a person has the pathology, the information was collected, by the authors, through a survey and applied to undergraduate students of universities in Colombia, M\\u00e9xico and Per\\u00fa.\",\"1194\":\"In Table 2 you can see the factors considered to obtain the obesity levels with their corresponding values.\",\"1195\":\"Table 1: BMI classification according to WHO and Mexican normativity (DO, 2010) BMI Classification Underweight Less than 18.5 Normal 18.5 to 24.9 Overweight 25.0 to 29.9 Obesity I 30.0 to 34.9 Obesity II 35.0 to 39.9 Obesity III Higher than 40 Table 2: Dataset description Attributes Values Sex H: Male M: Female Age Integer Numeric Values Height Integer Numeric Values (Mt) Weight Integer Numeric Values (Kg) Family with overweight \\/ Obesity Yes No Fast Food Intake Yes No Vegetables Consumption Frequency S: Always A: Sometimes CN: Rarely Number of main meals daily 1 to 2: UD 3: TR More than 3: MT Food intake between meals S: Always CS: Usually A: Sometimes CN: Rarely Smoking Yes No Liquid intake daily MU: Less than one liter UAD: Between 1 and 2 liters MD: More than 2 liters Calories Consumption Calculation Yes No Physical Activity UOD: 1 to 2 days TAC: 3 to 4 days COS: 5 to 6 days NO: No physical activity Schedule dedicated to technology CAD: 0 to 2 hours TAC: 3 to 5 hours MC: More than 5 hours Alcohol consumption NO: No consumo de alcohol CF: Rarely S: Weekly D: Daily Type of Transportation used TP: Public transportation MTA: Motorbike BTA: Bike CA: Walking AU: Automobile IMC WHO Classification Vulnerable Based on the WHO Classification \\fEduardo De-La-Hoz-Correa et al. \\/ Journal of Computer Science 2019, 15 (1): 67.77 DOI: 10.3844\\/jcssp.2019.67.77 70 Finally, the dataset is a product generated based on the answers of the students who applied to the survey.\",\"1196\":\"Next, several data mining methods or techniques were applied to extract information that can be used to identify people with tendency to suffer obesity.\",\"1197\":\"Decision Trees Decision trees are considered classification algorithms with high performance, the most popular ones have been implemented in several tools and their names are ID3, C4.5, C5, BFTree and RandomForest.\",\"1198\":\"According to (Safavian and Landgrebe, 1991) decision trees can be used in many research areas as: To classify radar signals, text recognition, medical diagnoses, expert systems and others, with high levels of success.\",\"1199\":\"Decision trees are classification methods that take the analyzed data and use a representation in a tree data structure, to provide better insight of the information from the data.\",\"1200\":\"Mart\\u00ednez et al. (2009), a Decision tree was defined to perform inductive learning from observations and logical constructions, like the predictive systems based on rules, that allow to represent and categorize the data subject to analysis.\",\"1201\":\"According to (Chang and Pavlidis, 1977), one of the main advantages of using Decision trees is that they can decompose a process that has many factors in a set of processes of less size and obtain solutions easier to interpret.\",\"1202\":\"Na\\u00efve Bayes A Bayesian network is considered, according to Edwards (1998; Edwards and Fasolo, 2001), a structure composed by four levels.\",\"1203\":\"In the higher level, you can find a set of variables represented by nodes and arrows that are related in terms of influence.\",\"1204\":\"In a lower level, you can find the levels or states, also known as space of states (Nadkarni and Shenoy, 2001; 2004) that can assume each of the variables of the model.\",\"1205\":\"In third place, the level is composed by a set of functions of conditional probability, one for each node, where you can find the probability of occurrence of each state of the variable, considering the possible values of the variables that determine their value.\",\"1206\":\"In the lower level you can find a set of algorithms that allow the network to recalculate the probabilities assigned to each level when there is new evidence about the model.\",\"1207\":\"It is relevant to highlight that a Bayesian network is based on two elements, a qualitative dimension and a quantitative dimension (Mart\\u00ednez et al., 2003).\",\"1208\":\"The qualitative dimension is based on graph theory and probability theory (R\\u00edos, 1995).\",\"1209\":\"According to (Spirtes et al., 2000) a Bayesian network is a type of graph called Acyclic Directed Graph (ADG).\",\"1210\":\"There are three key elements that form the quantitative dimension of a Bayesian network: The probability concept, the Bayes Theorem and the probability conditional functions.\",\"1211\":\"The probability can be understood as something subjective, such as the level of belief of an event (Dixon and Pastor, 1970) and this concept of probability is called Bayesian and is derived from the principle of insufficient reasoning or uncertainty principle (Cowell et al., 1999).\",\"1212\":\"The Bayes Theorem is deducted from the axiom that relates the probability of the event intersection and the conditional probability, which can help to work in an efficient way with the propagation of probabilities in graphic models in terms of conditional dependence or independence (Cowell et al., 1999).\",\"1213\":\"Next, you can see in Fig. 1, an example of the structure of a decision tree.\",\"1214\":\"Fig. 1: Decision Tree Structure (Mart\\u00ednez et al., 2009) Root Node Attribute Leaf Node Child Node Attribute Class variable Child Node Leaf Node Class variable Attribute Leaf Node Class variable \\fEduardo De-La-Hoz-Correa et al. \\/ Journal of Computer Science 2019, 15 (1): 67.77 DOI: 10.3844\\/jcssp.2019.67.77 71 A Bayesian network basically updates the probabilities inside an acyclic directed graph, considering the conditional independence principles when new evidence is added to the model.\",\"1215\":\"A Bayesian network needs a set of conditional probability functions, one for each variable or node in the network, the ones that will be applied the Bayes rule.\",\"1216\":\"Specifically, each variable of the network is characterized by a conditional probability table that represents the values that can assume that variable considering the values of the set of variables that is dependent, following Cowell et al. (1999).\",\"1217\":\"Logistic Regression Logistic regression is a multivariant statistic technique that can estimate the existing relationship between a variable dependent non-metric, dichotomic and a set of variables independent of metric and nonmetric.\",\"1218\":\"Systematically, the logistic regression has two objectives: The first, is to study the influence of the probability of occurrence of a specific event, the presence of several factors or not and the value or level of these; the second is to determine the better fit model that describe this relationship between the response variable and the set of variables to predict as mentioned by (Salcedo, 2002).\",\"1219\":\"According to (Kurt et al., 2008), logistic regression is useful for situations where you need to predict the presence or absence of a feature or output, based on values of the set of variables to predict.\",\"1220\":\"It is similar to a regression linear model, but it is more appropriate for models where the dependent variable is dichotomic.\",\"1221\":\"The main goal of logistic regression is to model the influence of the variables that need to be predicted related to the probability of occurrence of those variables.\",\"1222\":\"SEMMA Methodology The SEMMA Methodology was developed by the SAS Institute, including the processes of selection, exploration, modeling of big datasets to discover relevant information or patterns as mentioned by (SASI, 2017).\",\"1223\":\"According to (Moine et al., 2011), the SEMMA methodology have five basic phases which are: Sample, Explore, Modify, Model and Assess.\",\"1224\":\"From (Olson and Delen, 2008) SEMMA facilitates the statistic exploration, the visualization techniques and the selection and transforming of the relevant variables in prediction, also can model the variables for prediction processes and later validate the precision of the model.\",\"1225\":\"In Fig. 2, you can see the relevant aspects and stages of the methodology.\",\"1226\":\"In this study, each phase of the SEMMA methodology was implemented to obtain finer control of the activities developed starting with the data collecting stage to the results stage, so the authors could validate the capacity and quality of the proposed model.\",\"1227\":\"Fig. 2: SEMMA Methodology Evaluation Methodology for Data Mining Methods and Techniques This study proposed a software for prediction and detection of obesity levels in young people.\",\"1228\":\"With this goal in mind, we performed the stages based on the SEMMA methodology.\",\"1229\":\"First, we proceeded to the dataset creation, from the information collected by the survey, as described in section 3.1.\",\"1230\":\"After the dataset creation, we validated the data, looking for missing values, atypical data and the correlation level between variables, which it is lower than 0.5, so we can be sure that the stored data and the basis for the software implementation and the data mining methods, are correct.\",\"1231\":\"Once the dataset was validated and prepared, the data mining techniques and methods were applied, using the Weka tool, that has a set of algorithms that can be applied to many situations.\",\"1232\":\"In this study, the methods used were Decision Trees (J48), Bayesian Networks (Na\\u00efve Bayes) and Logistic Regression (Simple Logistic).To validate the model and selecting the best technique, we used the precision metrics Recall, TP Rate and FP Rate.\",\"1233\":\"For the training process, we used crossed validation, as mentioned by (Palechor et al., 2015), to use part of the data for training and other part for testing, to guarantee optimal results and avoiding over training issues.\",\"1234\":\"The proposed model considers classes or categories, the values of underweight, normal, overweight, obesity level I, obesity level II and obesity level III, as you can see in Table 1.\",\"1235\":\"Software Development The proposed software was based on the dataset created and implements the best data mining technique of the study.\",\"1236\":\"Next, you can see the flow diagram of the development of the software in Fig. 3.\",\"1237\":\"Sample (representative sample extraction).\",\"1238\":\"SEMMA Explore (detection, identification of abnormal data).\",\"1239\":\"Modify (data modification).\",\"1240\":\"Model (application of data mining techniques).\",\"1241\":\"Assess (Quality validation of the model).\",\"1242\":\"Eduardo De-La-Hoz-Correa et al. \\/ Journal of Computer Science 2019, 15 (1): 67.77 DOI: 10.3844\\/jcssp.2019.67.77 72 Fig. 3: Flow diagram for software development Fig. 4: Using the weka toolkit (weka.jar) Fig. 5: Presentation Form of the proposed software For the development of the software we used the NetBeans IDE, based on Java.\",\"1243\":\"To be able to use the data mining methods, we added the Weka Toolkit (weka.jar), in Fig. 4 you can see the library import in the tool used for it.\",\"1244\":\"Once the library was imported, we proceeded to coding the classes, methods, procedures and forms as you can see in Fig. 3.\",\"1245\":\"First, we designed the presentation form, to help describe the tool.\",\"1246\":\"You can see it in Fig. 5.\",\"1247\":\"Database definition ARFF creation Use of software Method testing ARFF training Prediction from the data provided by user CAD_Niveles_Obesidad Source Packages Conjunto_Datos modelo_modificado.model prueba.arff Imagenes cad_niveles_obesidad Presentacion.java clasificacion.java form1.java help.java instancia.java libreria otros Test packages Libraries weka.jar JDK 1.8 (Default) Test Libraries Information System for Detection of Obesity Levels in Youth Information System for Detection of Obesity Levels in Youth It is a tool that allows the identification of the degree of obesity in young people, through the use of data mining techniques or techniques.\",\"1248\":\"The decision tree is the method that yields better results in metrics such as precision, coverage, true positive rate and false positive rate.\",\"1249\":\"The data handled in the software must have a specific format defined by the tool administrator.\",\"1250\":\"Enter \\fEduardo De-La-Hoz-Correa et al. \\/ Journal of Computer Science 2019, 15 (1): 67.77 DOI: 10.3844\\/jcssp.2019.67.77 73 Fig. 6: Form for estimating obesity levels Fig. 7: Path to the dataset After the presentation form, the user will find the input form, to receive the variables that we considered as factors for obesity levels.\",\"1251\":\"You can see it in Fig. 6.\",\"1252\":\"To avoid missing data, all fields in the input form were validated and are mandatory to make a correct prediction.\",\"1253\":\"The tool also must have access to the dataset or training model, which it is loaded automatically by the software.\",\"1254\":\"In Fig. 7, you can see the sentence of code to access the model or dataset to train the tool.\",\"1255\":\"Next, you can find the ARFF file that was used to generate the model and train the tool, as depicted in Fig. 8.\",\"1256\":\"After the training and classification process, you can find the predictions produced by the tool as shown in Fig. 9.\",\"1257\":\"Next, you can see in Fig. 10 the result shown by the tool, after data input to the forms in Fig. 9.\",\"1258\":\"Information System for Detection of Obesity Levels in Youth Personal information Answer the following questions Family medical history: Do you eat fast food?\",\"1259\":\"Frequency of consumption of vegetables Number of main meals Male Prediction Sex: Female Age: 10 Weight: KG: Height: Meters Intake of food between meals?\",\"1260\":\"Frequency of physical activity Smoke?\",\"1261\":\"Amount of fluids per day Look at the amount of calories per day Frequency of use of technology devices Frequency of alcohol consumption Type of transportation used Muscle mass index Obesity level Process Home Help \\fEduardo De-La-Hoz-Correa et al. \\/ Journal of Computer Science 2019, 15 (1): 67.77 DOI: 10.3844\\/jcssp.2019.67.77 74 Fig. 8: ARFF File Fig. 9: Form with example data Fig. 10: Form with results given by the tool Results and Discussion Based on the data shown in Table 3 and Fig. 11, the technique with best results was Decision Trees, so we chose the J48 algorithm to be the one selected to implement in the proposed software.\",\"1262\":\"Personal information Weight: Male Female Sex: Age: 25 KG: Height: Meters Answer the following questions Family medical history: Do you eat fast food?\",\"1263\":\"Frequency of consumption of vegetables Number of main meals Intake of food between meals?\",\"1264\":\"Frequency of physical activity Smoke?\",\"1265\":\"Amount of fluids per day Look at the amount of calories per day Frequency of use of technology devices Frequency of alcohol consumption Type of transportation used 62 160 No Yes Sometimes 3 Yes No Sometimes Less than one liter Does not perform physi.\",\"1266\":\"3 to 5 Hours With little frequency Care Obesity level NORMAL Process Home Help \\fEduardo De-La-Hoz-Correa et al. \\/ Journal of Computer Science 2019, 15 (1): 67.77 DOI: 10.3844\\/jcssp.2019.67.77 75 Table 3: Results of the implemented techniques Method Precision Recall TP.\",\"1267\":\"Rate FP.\",\"1268\":\"Rate J48 97,4% 97,8% 97,8% 0,2% Naive Bayes 90,1% 91,1% 91,1% 6,0% Simple Logistic 90,4% 91,6% 91,6% 4,1% Table 4: Confusion matrix a b c d e f Classification 40 4 0 0 0 0 a = Underweight 0 360 0 0 0 0 b = Normal 0 0 180 4 0 0 c = Overweight 0 0 0 92 8 0 d = Obesity level I 0 0 0 0 20 0 e = Obesity level II 0 0 0 0 4 0 f = Obesity level III Fig. 11: Results of the implemented techniques Next, you can see in Table 4, the confusion matrix, where you can find the number of records organized by category.\",\"1269\":\"Conclusion Obesity is a disease with worldwide exposure, no matter social or cultural level of the people, it is a disease that has doubled since 1980, in 2014 more than 1900 million of adults suffered from it.\",\"1270\":\"To help fight this disease, several tools and solutions have been developed to be able to detect or predict the appearance of the disease.\",\"1271\":\"Data mining is an essential tool that allow us to discover information, in our study we used different techniques to achieve best precision rates to detect obesity.\",\"1272\":\"According to this, the Decision Trees method obtained 97.4% precision levels to classify users that carry the disease, also the technique shows a TP Rate of 97.8%, which guarantees a high percentage of success to classify data, finally have a FP Rate of 0.2%, a correct value for it.\",\"1273\":\"The technique also obtained better results than the values from techniques such as Bayesian Networks and Logistic Regression.\",\"1274\":\"The proposed method also surpasses the results obtained in (Adnan and Husain, 2012) that had 75% in precision, (Dugan et al., 2015) that obtained 85% and (Husain et al., 2013) that showed 73.3%.\",\"1275\":\"The software created in this study allows to classify patients with obesity and it is a clear integration between Weka, Java and NetBeans, integration that can generate many tools to analyze diseases that affect a group of the population, which represents a positive advance in this research area.\",\"1276\":\"Acknowledgement The authors are grateful to the collaboration from Ana Isabel Oviedo Carrascal, her efforts and counseling were keys to achieve the expected results and the divulgation of these, through this paper.\",\"1277\":\"The authors would like to thank the support of the Universidad de la Costa, this study would have not been possible without it.\",\"1278\":\"Author\\u2019s Contributions Dr. Eduardo De la Hoz Correa: Lead research, coordinate developer, doing experiments, adapt analysis and writing the manuscript.\",\"1279\":\"Roberto Morales Ortega and Fabio Mendoza Palechor: Advise research, adapting analysis for the data mining methods part and writing manuscript and proof reading.\",\"1280\":\"Alexis De la Hoz Manotas and Beatriz S\\u00e1nchez Hernandez: English proof reading and software adapting analysis and result verifications.\",\"1281\":\"Ethics This article is original and contains unpublished material.\",\"1282\":\"The corresponding author confirms that the coauthor has read and approved the manuscript and there are no ethical issues involved.\",\"1283\":\"100.0% 80.0% 60.0% 40.0% 20.0% 0.0% Precision RECALL TP RATE FP RATE J48 Na\\u00efve Bayes Regresion logistica \\fEduardo De-La-Hoz-Correa et al. \\/ Journal of Computer Science 2019, 15 (1): 67.77 DOI: 10.3844\\/jcssp.2019.67.77 76 References Abdullah, F.S., N.S.A. Manan, A. Ahmad, S.W. Wafa and M.R. Shahril et al., 2016.\",\"1284\":\"Data mining techniques for classification of childhood obesity among year 6 school children.\",\"1285\":\"Proceedings of the International Conference on Soft Computing and Data Mining, Aug.\",\"1286\":\"18-20, Springer, Cham, pp: 465-474. DOI: 10.1007\\/978-3-319-51281-5_47 Adnan, M.H.B.M. and W. Husain, 2012.\",\"1287\":\"A hybrid approach using Na\\u00efve Bayes and genetic algorithm for childhood obesity prediction.\",\"1288\":\"Proceedings of the International Conference on Computer and Information Science, Jun. 12-14, IEEE Xplore Press, Kuala Lumpeu, Malaysia, pp: 281-285. DOI: 10.1109\\/ICCISci.2012.6297254 Adnan, M.H.B.M., W. Husain and F. Damanhoori, 2010.\",\"1289\":\"A survey on utilization of data mining for childhood obesity prediction.\",\"1290\":\"Proceedings of the 8th AsiaPacific Symposium on Information and Telecommunication Technologies, Jun. 15-18, IEEE Xplore Press, Kuching, Malaysia, pp: 1-6.\",\"1291\":\"Adnan, M.H.M. and W. Husain, 2011.\",\"1292\":\"A framework for childhood obesity classifications and predictions using NBtree.\",\"1293\":\"Proceedings of the 7th International Conference on Information Technology in Asia, Jul. 12-13, IEEE Xplore Press, Kuching, Sarawak, Malaysia, pp: 1-6. DOI: 10.1109\\/CITA.2011.5999502 Calabria-Sarmiento, J. C., Ariza-Colpas, P., PineresMelo, M., Ayala-Mantilla, C., Urina-Triana, M., Morales-Ortega, R. and I. Echeverri-Ocampo, 2018.\",\"1294\":\"Software Applications to Health Sector: A Systematic Review of Literature.\",\"1295\":\"Chang, R.L. and T. Pavlidis, 1977.\",\"1296\":\"Fuzzy decision tree algorithms.\",\"1297\":\"IEEE Trans.\",\"1298\":\"Syst. Man Cybernet., 7: 28-35. DOI: 10.1109\\/TSMC.1977.4309586 Cowell, R.G., A.P. Dawid, S.L. Lauritzen and D.J. Spiegelhalter, 1999.\",\"1299\":\"Probabilistic networks and expert systems.\",\"1300\":\"Davila-Payan, C., M. DeGuzman, K. Johnson, N. Serban and J. Swann, 2015.\",\"1301\":\"Estimating prevalence of overweight or obese children and adolescents in small geographic areas using publicly available data.\",\"1302\":\"Prevent.\",\"1303\":\"Chronic Dis., 12: E32-E32.\",\"1304\":\"DOI: 10.5888\\/pcd12.140229 Dixon, J.R. and V.M. Pastor, 1970.\",\"1305\":\"Introducci\\u00f3n a la Probabilidad: Texto Programado.\",\"1306\":\"1st Edn., LimusaWiley, ISBN-10: 9681807200, pp: 418.\",\"1307\":\"DO, 2010.\",\"1308\":\"NORMA Oficial Mexicana NOM-008-SSA32010, Para el tratamiento integral del sobrepeso y la obesidad.\",\"1309\":\"Diario Oficial.\",\"1310\":\"Dugan, T.M., S. Mukhopadhyay, A. Carroll and S. Downs, 2015.\",\"1311\":\"Machine learning techniques for prediction of early childhood obesity.\",\"1312\":\"Applied Clin.\",\"1313\":\"Inform., 6: 506-520. DOI: 10.4338\\/ACI-2015-03-RA-0036 Edwards, W. and B. Fasolo, 2001.\",\"1314\":\"Decision technology.\",\"1315\":\"Annual Rev.\",\"1316\":\"Psychol., 52: 581-606. DOI: 10.1146\\/annurev.psych.52.1.581 Edwards, W., 1998.\",\"1317\":\"Hailfinder: Tools for and experiences with Bayesian normative modeling.\",\"1318\":\"Am. Psychol., 53: 416-416. DOI: 10.1037\\/0003-066X.53.4.416 G\\u00f3mez, M. and L. \\u00c1vila, 2008.\",\"1319\":\"La obesidad: un factor de riesgo cardiometab\\u00f3lico.\",\"1320\":\"Medicina de Familia.\",\"1321\":\"Guti\\u00e9rrez, H.M., 2010.\",\"1322\":\"Diez problemas de la poblaci\\u00f3n de jalisco: Una perspectiva sociodemogr\\u00e1fica (Primera Edici\\u00f3n ed.).\",\"1323\":\"Direcci\\u00f3n de Publicaciones del Gobierno de Jalisco, Guadalajara, M\\u00e9xico.\",\"1324\":\"Hern\\u00e1ndez, G.M., 2011.\",\"1325\":\"Prevalencia de sobrepeso y obesidad, y factores de riesgo, en ni\\u00f1os de 7-12 a\\u00f1os, en una escuela p\\u00fablica de Cartagena septiembre - octubre de 2010.\",\"1326\":\"Universidad Nacional de Colombia, Bogota \\u2013 Colombia.\",\"1327\":\"Husain, W., M.H.M. Adnan, L.K. Ping, J. Poh and L.K. Meng, 2013.\",\"1328\":\"My healthy kids: Intelligent obesity intervention system for primary school children.\",\"1329\":\"Proceedings of the 3rd International Conference on Digital Information Processing and Communications, (IPC\\u2019 13), The Society of Digital Information and Wireless Communication, pp: 627-633.\",\"1330\":\"Kurt, I., M. Ture and A.T. Kurum, 2008. Comparing performances of logistic regression, classification and regression tree and neural networks for predicting coronary artery disease.\",\"1331\":\"Expert Syst. Applic., 34: 366-374. DOI: 10.1016\\/j.eswa.2006.09.004 Manna, S. and A.M. Jewkes, 2014.\",\"1332\":\"Understanding early childhood obesity risks: An empirical study using fuzzy signatures.\",\"1333\":\"Proceedings of the IEEE International Conference on Fuzzy Systems, Jul. 6-11, IEEE Xplore Press, Beijing, China, pp: 1333-1339. DOI: 10.1109\\/FUZZ-IEEE.2014.6891838 Mart\\u00ednez, F., M.C. D\\u00edaz, M.T. Mart\\u00edn, V.M. Rivas and L.A. Ure\\u00f1a, 2003.\",\"1334\":\"Aplicaci\\u00f3n de redes neuronales y redes bayesianas en la detecci\\u00f3n de multipalabras para tareas IR. Artculo presentado en las II Jornadas de Tratamiento y Recuperacin de la Informacin, Madrid.\",\"1335\":\"Mart\\u00ednez, R.E.B., N.C. Ram\\u00edrez, H.G.A. Mesa, I.R. Su\\u00e1rez and M.D.C.G. Trejo et al., 2009.\",\"1336\":\"\\u00c1rboles de decisi\\u00f3n como herramienta en el diagn\\u00f3stico m\\u00e9dico.\",\"1337\":\"Revista M\\u00e9dica de la Univ.\",\"1338\":\"Veracruzana, 9: 19-24.\",\"1339\":\"Moine, J.M., A.S. Haedo and S.E. Gordillo, 2011.\",\"1340\":\"Estudio comparativo de metodolog\\u00edas para miner\\u00eda de datos.\",\"1341\":\"13th Workshop de Investigadores en Ciencias de la Computaci\\u00f3n.\",\"1342\":\"Eduardo De-La-Hoz-Correa et al. \\/ Journal of Computer Science 2019, 15 (1): 67.77 DOI: 10.3844\\/jcssp.2019.67.77 77 Nadkarni, S. and P.P. Shenoy, 2001.\",\"1343\":\"A Bayesian network approach to making inferences in causal maps.\",\"1344\":\"Eur.\",\"1345\":\"J. Operat.\",\"1346\":\"Res., 128: 479-498. DOI: 10.1016\\/S0377-2217(99)00368-9 Nadkarni, S. and P.P. Shenoy, 2004.\",\"1347\":\"A causal mapping approach to constructing Bayesian networks.\",\"1348\":\"Dec.\",\"1349\":\"Support Syst., 38: 259-281. DOI: 10.1016\\/S0167-9236(03)00095-2 Olmedo, M.V., 2011.\",\"1350\":\"La obesidad: Un problema de salud p\\u00fablica.\",\"1351\":\"Revista de divulgaci\\u00f3 cient\\u00edfica y tecnol\\u00f3gica de la Universidad Veracruzana.\",\"1352\":\"https:\\/\\/www.uv.mx\\/cienciahombre\\/revistae\\/vol24nu m3\\/articulos\\/obesidad\\/ Olson, D.L. and D. Delen, 2008.\",\"1353\":\"Advanced Data Mining Techniques.\",\"1354\":\"1st Edn., Springer Science and Business Media, Berlin, ISBN-10: 354076917X, pp: 180.\",\"1355\":\"OMS, 2016.\",\"1356\":\"Organizaci\\u00f3n Mundial de la Salud.\",\"1357\":\"Obesidad y sobrepeso.\",\"1358\":\"Palechor, F.M., A.D.L.H. Manotas, E.D.L.H. Franco and P.A. Colpas, 2015.\",\"1359\":\"Feature selection, learning metrics and dimension reduction in training and classification processes in intrusion detection systems.\",\"1360\":\"J. Theoretical Applied Inform. Technol., 82: 291-298.\",\"1361\":\"Palechor, F.M., A.\",\"1362\":\"De la Hoz Manotas, P.A. Colpas, J.S. Ojeda and R.M. Ortega et al., 2017.\",\"1363\":\"Cardiovascular disease analysis using supervised and unsupervised data mining techniques.\",\"1364\":\"JSW, 12: 81-90.\",\"1365\":\"R\\u00edos, S., 1995.\",\"1366\":\"Modelizaci\\u00f3n.\",\"1367\":\"Alianza Universidad, Madrid.\",\"1368\":\"Safavian, S.R. and D. Landgrebe, 1991.\",\"1369\":\"A survey of decision tree classifier methodology.\",\"1370\":\"IEEE Trans.\",\"1371\":\"Syst. Man Cybernet., 21: 660-674. DOI: 10.1109\\/21.97458 Salcedo, C.M., 2002.\",\"1372\":\"Estimaci\\u00f3n de la Ocurrencia de incidencias en declaraciones de p\\u00f3lizas de importaci\\u00f3n.\",\"1373\":\"Universidad Nacional Mayor de San Marcos, Lima.\",\"1374\":\"SASI, 2017.\",\"1375\":\"Data mining and the case for sampling.\",\"1376\":\"SAS Institute.\",\"1377\":\"Spirtes, P., C.N. Glymour and R. Scheines, 2000.\",\"1378\":\"Causation, Prediction and Search.\",\"1379\":\"1st Edn., MIT Press, Cambridge, Mass, ISBN-10: 0262194406, pp: 543.\",\"1380\":\"Suguna, M., 2016.\",\"1381\":\"Childhood obesity epidemic analysis using classification algorithms.\",\"1382\":\"Int.\",\"1383\":\"J. Mod.\",\"1384\":\"Comput.\",\"1385\":\"Sci., 4: 22-26.\",\"1386\":\"Zhang, S., C. Tjortjis, X. Zeng, H. Qiao and I. Buchan et al., 2009. Comparing data mining methods with logistic regression in childhood obesity prediction.\",\"1387\":\"Inform. Syst. Frontiers, 11: 449-460. DOI: 10.1007\\/s10796-009-9157-0 Zhingre, O. and P. del Cisne, 2015.\",\"1388\":\"Factores de riesgo que influyen en los estudiantes 10-13 a\\u00f1osde la Instituci\\u00f3n Educativa Mater Dei para desarrollar sobrepeso y obesidad en la vida adulta (Bachelor's Thesis).\",\"1389\":\"IJCSNS International Journal of Computer Science and Network Security, VOL.21 No.3, March 2021 103 Manuscript received March 5, 2021 Manuscript revised March 20, 2021 https:\\/\\/doi.org\\/10.22937\\/IJCSNS.2021.21.3.14 Obesity Level Prediction Based on Data MiningTechniques Asma Alqahtani, Fatima Albuainin, Rana Alrayes, Noura Al muhanna, Eyman Alyahyan1 and Ezaz Aldahasi2 Computer Science Department, College of Science and Humanities, Imam Abdulrahman Bin Faisal University, P.O. Box 31961, Jubail, Kingdom of Saudi Arabia Summary Obesity affects individuals of all gender and ages worldwide; consequently, several studies have performed great works to define factors causing it.\",\"1390\":\"This study develops an effective method to trace obesity levels based on supervised data mining techniques such as Random Forest and Multi-Layer Perception (MLP), so as to tackle this universal epidemic.\",\"1391\":\"Notably, the dataset was from countries like Mexico, Peru, and Colombia in the 14- 61year age group, with varying eating habits and physical conditions.\",\"1392\":\"The data includes 2111 instances and 17 attributes labelled using NObesity, which facilitates categorization of data using Overweight Levels l I and II, Insufficient Weight, Normal Weight, as well as Obesity Type I to III.\",\"1393\":\"This study found that the highest accuracy was achieved by Random Forest algorithm in comparison to the MLP algorithm, with an overall classification rate of 96.7%.\",\"1394\":\"Key words: Obesity, Data Mining, prediction, Multilayer Perceptron (MLP), Random Forest.\",\"1395\":\"1.\",\"1396\":\"Introduction The obesity epidemic is universally prevalent [1].\",\"1397\":\"It contributes to exacerbate many chronic ailments like kidney disease, cardiovascular, and cancer, etc. [2] [3].\",\"1398\":\"Obesity refers to an excessive accumulation of body fat in certain areas of the body that can be harmful to health.\",\"1399\":\"It is found in adults, teenagers, and children [4].\",\"1400\":\"Biological risk factors, such as genetic history, are known to cause obesity.\",\"1401\":\"Other risk factors such as psychological and social habits and eating can also not be ruled out.\",\"1402\":\"Since 1980, the number of obese individuals globally has doubled, and in 2014, more than 1900 million adults experienced a change in their weight.\",\"1403\":\"Some of the causes of weight gain are increased intake of energy-dense, high-fat foods and decreased physical activity caused by sedentary work, new transportation modes, and increasing urbanization [5].\",\"1404\":\"Despite many attempts to reduce obesity through exercise\\/diet, raising awareness, surgery, and drug therapy, an effective solution has not yet been found to and diagnose it accurately at an early stage.\",\"1405\":\"Data mining has been utilized in information technology for medical decision-making, such as prognostic and diagnostic problems, and for detecting correlations between the risk factors and outcomes [6].\",\"1406\":\"Data Mining (DM) analyzes many data to discover unknown patterns and extract hidden information [7].\",\"1407\":\"DM can be categorized into descriptive and predictive tasks.\",\"1408\":\"The descriptive task focuses more on describing the data, grouping it into categories, and summarizing it.\",\"1409\":\"On the other hand, the predictive task analyzes historical data and produces patterns\\/conclusions for future predictions [8].\",\"1410\":\"Machine learning techniques (ML) find numerous applications in the domain of DM.\",\"1411\":\"Many studies have predicted and analyzed obesity using web tools[9][10][11][12][13][14][15].\",\"1412\":\"However, these studies are typically confined to calculating BMI and omitting as associated factors like family background and the time allocated to it.\",\"1413\":\"To the best of our knowledge, only one study forecasts obesity that considers family background [16].\",\"1414\":\"They primarily depend on three modeling methods: decision trees (J48), na\\u00efve bayes, and logistic regression.\",\"1415\":\"This study aims to predict obesity using Random forest and multi-layer perceptron (MLP).\",\"1416\":\"It also aims to determine the most important predictive factors with a significant effect on obesity.\",\"1417\":\"The main contribution of this study is to carry out a comparative analysis of previous algorithms via a recent dataset used in [17].\",\"1418\":\"The results will go a long way in addressing the obesity issue and enhancing the health prospects of individuals.\",\"1419\":\"This paper is structured in the following manner.\",\"1420\":\"Section 2 elaborates on this work\\u2019s literature Section 3, describes proposed techniques.\",\"1421\":\"Section 4 focuses on Empirical studies, whereas Section 5 shows the optimization strategy.\",\"1422\":\"Section 6 presents results and discussion.\",\"1423\":\"Section 7 further expounds discussion highlights.\",\"1424\":\"Finally, Section 8 provides the conclusion and future works.\",\"1425\":\"2.\",\"1426\":\"Related Work In [16], the problem of obesity was considered, and the disease was analyzed before producing web tools.\",\"1427\":\"The SEMMA data mining methodology was undertaken to pick, model, and explore the dataset.\",\"1428\":\"Next, three techniques, Bayesian networks, Logistic Regression, and Decision trees, were chosen.\",\"1429\":\"The decision trees were found to have the best outcome on the basis of metrics: precision, TP rate, FP rate, and recall.\",\"1430\":\"Using WEKA, the Decision Trees technique was observed to have the best precision rate of 97.4%.\",\"1431\":\"In [9], the authors considered obesity that has been growing steadily in children, teenagers, and adults.\",\"1432\":\"In this study, a \\fIJCSNS International Journal of Computer Science and Network Security, VOL.21 No.3, March 2021 104 computational intelligence-based method was put forth, utilizing Decision Trees, Supportive Vector Machines (SVM) and K-Means \\u2013 data mining techniques.\",\"1433\":\"The dataset was selected from 81 male students and 97 female students in the (18 - 25) age group from Colombia, Peru, and Mexico.\",\"1434\":\"A comparative examination was done to improve the proposed tool.\",\"1435\":\"Then, the best approach was combined with the clustering technique after obtaining the results of classification techniques.\",\"1436\":\"In [10], the authors took into consideration the importance of defining people at risk of being affected by obesity as quickly as possible and quickly\\/accurately predict possible BMI rates for young adults from data pertaining to early childhood in the Millennium Cohort Study (MCS) using machine learning techniques.\",\"1437\":\"Various experiments were done using multivariate regression algorithms as well as multi-layer perceptron feed-forward artificial neural networks (MLPFFANN).\",\"1438\":\"The MLPFFANN technique obtained better results than regression algorithms, with over 90% prediction accuracy.\",\"1439\":\"In [11], the authors utilized data mining techniques for forecasting the obesity\\u2019s risk factors in Bangladesh through middle ages.\",\"1440\":\"The study proposed the risk mining technique (PRMT) to forecast obesity class-based risk factors.\",\"1441\":\"The class level precision, evaluation method and the data analysis results rely on WEKA's software using different machine learning algorithms.\",\"1442\":\"The study collected data from rural and urban regions regarding different risk factors concerning daily activities.\",\"1443\":\"The Na\\u00efve Bayes technique was found to yield the best results via 10-fold cross-validation.\",\"1444\":\"In [12], the authors explored the challenges of predicting health diseases.\",\"1445\":\"They proposed improved machine learning models to forecast obesity: binary logistic regression, improved decision tree IDT, \\u060cweighted k-nearest neighbor KNN and artificial neural network ANN.\",\"1446\":\"When comparing the binary logistic regression model with an accuracy of 56.02%, KNN, IDT, and ANN were found to be significantly better, as the accuracy of the KNN model was 88.82%.\",\"1447\":\"The IDT model had an accuracy of 80.23%, whereas it was 84.22% for the ANN model.\",\"1448\":\"In [13], the authors examined body fat percentage (BFP) and the high cost of its measuring devices.\",\"1449\":\"This study aimed to define the BFP using hybrid machine learning classifiers at a high rate and minimum parameters.\",\"1450\":\"To that end, they generated four various hybrid models with SVM, MLFFNN, and DT.\",\"1451\":\"This study\\u2019s practical outcome showed that the produced system could be utilized to predict the BFP.\",\"1452\":\"The system is also capable of measuring BFP with a single anthropometric measurement.\",\"1453\":\"In [14],the current traditional methods\\u2019 high cost to gather data on public health was considered with a view to predicting obesity.\",\"1454\":\"This study used the data mining tool of WEKA data and carried out predictive analytics via the J48 classifier so as to ascertain the rate of accuracy.\",\"1455\":\"The result confirmed the J48 classifier had predicted obesity from patterns of calorie consumption with a precision of 89.41%.\",\"1456\":\"In [15], this study adopted a country-level approach to gauge obesity\\u2019s spreading rate using domestic sales of food and beverages categories (a subset).\",\"1457\":\"The study introduced three machine learning algorithms for non-linear regression.\",\"1458\":\"This study ascertained data and obesity prevalence for 79 nations.\",\"1459\":\"The proposed method was validated with regard to both proportions of the countries and the absolute prediction error where a satisfactory obesity prevalence was forecasted.\",\"1460\":\"It was observed that baked goods and flour, accompanied by carbonated beverages and cheese, are the most significant food type to forecast g obesity.\",\"1461\":\"Data mining is known to be the pivotal factor to curb this global disease which damages the health of people across all age groups.\",\"1462\":\"Therefore, a review of previous literature found that many sources share the same goal of detecting and reducing obesity levels using data mining techniques.\",\"1463\":\"However, they differed in terms of databases and the target age range.\",\"1464\":\"From Table 1, it can be seen that similar algorithms were used to deal with different databases such as Decision Trees, Supportive Vector Machines (SVM), KMean, along with other algorithms.\",\"1465\":\"Therefore, we used random forest and multi-layer perception algorithms in our study to achieve the best accuracy rates to trace levels of obesity.\",\"1466\":\"Table 1: Previous studies highlight obesity disease.\",\"1467\":\"Ref Year Proposed Method Dataset Best Method [16] 2019 J48 NB LR Attributes: 18 Instances: 712 Related to: The undergraduates ages of (18 - 25) from (Colombia, Mexico, and Peru).\",\"1468\":\"DT precision rate of 97.4 % [9] 2020 DT SVM K-Means Related to: (18 - 25) years, 81 males and 97 females from institutions in Colombia, Peru, and Mexico.\",\"1469\":\"DT ROC Area 98.2 % [10] 2019 Multivari ate linear regression Linear SVM, Quadratic SVM Fine Tree Ensemble Bagged Trees Trees Related to: Young Adults (14 years old and older).\",\"1470\":\"The data used: From the Millennium Cohort Study (MCS).\",\"1471\":\"MLPFFANN prediction accuracy rate of 93.4% \\fIJCSNS International Journal of Computer Science and Network Security, VOL.21 No.3, March 2021 105 MLPFFA NN [11] 2018 NB IBK KStar ZeroR Random tree Simple logistic Related to: Middl e-Aged People from Bangladesh.\",\"1472\":\"The data used: From specified urban and rural areas.\",\"1473\":\"NB accuracy rate of 99.2 % [12] 2017 KNN IDT ANN BLR Related to: high school students (in grades 9-12) The data used: High schools in Tennessee.\",\"1474\":\"ANN accuracy rate of 99.46% [13] 2020 MLFFNN SVM DT It is related to body fat percentage values and anthropometric measurements of 252 individuals.\",\"1475\":\"MAPE Performance MLFFNN + DT + SVMs [14] 2018 J48 Related to: Malaysian grocery data, demographic data, and anthropometric data.\",\"1476\":\"J48 accuracy rate of 89.4118% [15] 2019 SVM Random Forest Extreme gradient boosting.\",\"1477\":\"Related to: beverage and food sales data in 48 categories for 79 nations.\",\"1478\":\"Baked goods, flour, carbonated drinks as well as cheese, are most pertinentfood category to forecast obesity.\",\"1479\":\"3.\",\"1480\":\"Description of Proposed Techniques 3.1 Artificial Neural Network An artificial neural network (ANN) involves performance attributes that are similar to the biological neural networks of human brains [18].ANN is capable of identifying nonlinear linkages between the data set\\u2019s inputs and outputs.\",\"1481\":\"As modeling tools, it is practical and useful, particularly in difficult problems to explain through statistical and physical equations [18].\",\"1482\":\"In this context, one of the neural networks that is used most extensively is Multilayer Perceptron (MLP) which primarily comprises nodes -artificial neuronsorganized into three types of layers, namely, input nodes, hidden nodes, and output nodes.\",\"1483\":\"Fig.\",\"1484\":\"1 illustrates the network process of an MLP [20].\",\"1485\":\"Fig 1 Illustration of an MLP network [20] 3.2 Random Forest The random forest model consists of numerous individual decision trees working as an ensemble.\",\"1486\":\"Leo Breiman introduced this algorithm in 2001 on the basis of a regression tree [21].\",\"1487\":\"The random forest approach is broadly used in classification problems [22][23] due to its power and ability to manage extensive features with small samples.\",\"1488\":\"As shown in Fig.2, the bootstrap sample method is applied to train each tree of the training data set.\",\"1489\":\"This technique seeks a random subset of variables to split in each node.\",\"1490\":\"For classification, the input vector of each unit is fed into the RF and each tree votes for a class.\",\"1491\":\"The RF finally selects the target with maximum votes.\",\"1492\":\"It can manage enormous input data sets unlike other models[24].\",\"1493\":\"Fig 2 Structure of a random forest [24] \\fIJCSNS International Journal of Computer Science and Network Security, VOL.21 No.3, March 2021 106 4.\",\"1494\":\"Empirical Studies 4.1 Description of the Dataset The dataset includes data to predict obesity of who depend on their diet and lifestyles belonging to Mexico, Colombia, and Peru.\",\"1495\":\"We used an internet platform to collect data (23%) from users; we then used Waikato Environment for Knowledge Analysis (WEKA) tool to create 77% of the data.\",\"1496\":\"The data consist of 17 attributes (see Table 2) and 2111 records.\",\"1497\":\"The approach of data preparation is summarized in Fig.\",\"1498\":\"3.\",\"1499\":\"NObesity, the class variable makes it possible to classify data (using values Normal Weight, Insufficient Weight, Obesity Type I\\/Type II\\/Type III, and Overweight Level I\\/ Overweight Level II Fig 3 Preparing dataset process. Table 2 Attribute\\u2019s description Attribute Description Initial value Gender The gender of obesity-prone condition Male Female Age The age of the obesity-prone case Integer Numeric Values Height The duration of the obesityprone case Integer Numeric Values (Mt) Weight The weight of the obese condition Integer Numeric Values (Kg) Family history with Obesity an obesity-prone family or no Yes No FAVC Consumption of calorie-rich food on a frequent basis Yes No FCVC Usage of vegetables (frequency) Always Sometimes Rarely NCP Number of meals 1 to 2 3 More than 3 CAEC Consumption of food between meals Always Usually Sometimes Rarely CH20 Consumption of water daily Less than one liter More than 2 liters Between 1 and 2 liters CALC Consumption of alcohol Less than one liter More than 2 liters Between 1 and 2 liters SCC Calorie's consumption monitoring Yes No FAF Physical activity frequency 1 to 2 days 3 to 4 days 5 to 6 days No physical activity TUE Time using technology devices.\",\"1500\":\"0to 2 hours 3 to 5 hours MTRANS Transportation used.\",\"1501\":\"MTRANS Transportation used Public transportation Motorbike Bike Walking Automobile Smoking Determining if obesity-prone individual smokes or not Yes No NObesity The class variable facilitates the data classification so as to classify a person's obesity level and recommend systems monitoring obesity levels.\",\"1502\":\"Insufficient Weight, Normal Weight Obesity Type I, Obesity Type II Obesity Type II Overweight Level I, Overweight Level II \\fIJCSNS International Journal of Computer Science and Network Security, VOL.21 No.3, March 2021 107 4.2 Experimental Setup Obesity prediction was made using WEKA, machine learning software and toolkit.\",\"1503\":\"The Java framework was distributed under the GNU General Public License.\",\"1504\":\"The tool presents several modern and popular techniques for analyzing and mining data.\",\"1505\":\"WEKA is able to support many data mining activities to forecast health problems, such as data preprocessing, classification, grouping, simulation, correlation, and functional choice.\",\"1506\":\"[25].\",\"1507\":\"The data contains many issues that need to be preprocessed, such as missing values, outliers, irrelevant or redundant data, etc.\",\"1508\":\"This is one of the most important data mining phases that helps clean the data to be used as input to the other processes [26].\",\"1509\":\"To begin with, the database is prepared and preprocessed for the experiment.\",\"1510\":\"Then, the outliers and extreme values in the dataset were detected using WEKA's unsupervised attribute filter (Interquartile range).\",\"1511\":\"After determining instances with outliers or extreme values, we got rid of these instances from dataset through the RemoveWithValues filter.\",\"1512\":\"It was necessary to increase the models' accuracy by overcoming outliers' problem.\",\"1513\":\"Next, the optimization parameters for Random Forest and MLP were determined to obtain better performance as well as to guarantee optimal results.\",\"1514\":\"This step entailed adjusting the Seed, Numerations factors for Random Forest, while Seed and Hidden layers and the Learning Rate for MLP.\",\"1515\":\"As shown in Table 3 and Table 4, the performance was better with the default value of the parameters.\",\"1516\":\"Random Forest had an accuracy of 96.70%, while the MLP had an accuracy of 95.06%.\",\"1517\":\"Moreover, we determine the relationship of information gain and coefficients between class variables and calculated all attributes so as to get the characteristics of selected features ranked.\",\"1518\":\"Tables 5 and 6 show the findings.\",\"1519\":\"Subsequently, to predict if one person suffers from obesity, the capability to increase the precision of classification performance was examined by ascertaining the important features.\",\"1520\":\"Feature selection\\/correlation-based features selection were studied based on Info Gain.\",\"1521\":\"The results are shown in Table 7 and Table 8.\",\"1522\":\"Following the gathering of results, the classifiers were implemented using numerous ratios of partition.\",\"1523\":\"The Random Forest and MLP attained a ratio accuracy of 70:30 (70 % for data training as well as 30 % for testing).\",\"1524\":\"Findings are shown in Table 9.\",\"1525\":\"Eventually, based on the above experimental results, we generated the final model by selecting the most effective subset features achieving the optimal cross-validation or partition ratio.\",\"1526\":\"5.\",\"1527\":\"Optimization Strategy In order to enhance the classification results and to obtain accuracy-based better performance, the Weka meta-learner (CV Parameter Selection) search methodology was used [27].\",\"1528\":\"Table 3 shows the default and optimum parameters for each classifier, and it was found that the optimum parameters for the classifiers are the default parameters.\",\"1529\":\"Table 4 depicts the classifiers\\u2019 performance using optimal parameters.\",\"1530\":\"Table 3 Default and optimal parameters for each classifier-Values Table 4 Default and optimal parameters for each classifier-Performance 6.\",\"1531\":\"Results and Discussion 6.1 Feature Selection Impact on Dataset The Information Gain (InfoGain) [28], and correlationbased features selection method [29],were used to select the best performing subset, besides the most significant attributes with the highest impact to forecast obesity.\",\"1532\":\"As Table 5 shows, the coefficient\\u2019s correlation was taken into consideration for ranking characteristics on the basis of Pearson values with the involvement of class variable (output).\",\"1533\":\"In addition, Table 6 shows that InfoGain was implemented to classify the features on the basis of measure, of information gain with the involvement of class variable (output).\",\"1534\":\"Table 7 and Table 8 present the results of the Info Gain and correlation-based features selection method.\",\"1535\":\"The best performance was observing to require the use of each features.\",\"1536\":\"Furthermore, accuracy was found to reduce upon reducing the number of factors.\",\"1537\":\"Parameters Values Model Optimal value Default value Parameters 100 100 numIterations Random Forest 1 1 Seed 0 0 Seed MLP a a Hidden Layers 0.3 0.3 Learning Rate Performance (accuracy) Model Default value (Optimal value) 96.70% Random Forest 95.06% MLP \\fIJCSNS International Journal of Computer Science and Network Security, VOL.21 No.3, March 2021 108 Table 5.\",\"1538\":\"Each attribute and the class- Correlation Correlation with class Attribute's name Order 0.342 Weight 1 0.1997 Family_history_with_overweight 2 0.1955 Gender 3 0.1734 CAEC 4 0.1725 FCVC 5 0.1552 CALC 6 0.1501 Age 7 0.1287 FAVC 8 0.1253 NCP 9 0.1069 Height 10 0.0982 MTRANS 11 0.0921 SCC 12 0.0832 FAF 13 0.0682 CH2O 14 0.0645 TUE 15 0.0558 SMOKE 16 Table 6.\",\"1539\":\"Each attribute and the class \\u2013 Information gain Infogain with class Attribute's name Order 1.7517 Weight 1 0.8016 Age 2 0.6259 FCVC 3 0.4839 FAF 4 0.4346 TUE 5 0.4153 CH2O 6 0.3471 Gender 7 0.344 NCP 8 0.2563 Height 9 0.2163 Family_history_with_overweight 10 0.2058 CAEC 11 0.169 CALC 12 0.1172 MTRANS 13 0.0881 FAVC 14 0.0437 SCC 15 0.015 SMOKE 16 Table 7.\",\"1540\":\"Correlation-based feature selection results Numb er of featur es Features Rand om Forest MLP AVG All featur es All 96.70 % 95.06 % 95.88 % Nine featur es Weight Family_history_with_ov erweight Gender CAEC FCVC CALC Age FAVC NObesity 91.25 % 83.71 % 87.48 % Five featur es Weight Family_history_with_ov erweight Gender CAEC NObesity 77.46 % 76.2 % 76.83 % Four featur es Weight Family_history_with_ov erweight Gender NObesity 76.16 % 74.97 % 75.56 % Three featur es Weight Family_history_with_ov erweight NObesity 67.8% 61.5 % 64.65 % Table 8.\",\"1541\":\"Infogain feature selection results Number of features Features Random Forest MLP AVG All features All 96.70% 95.06% 95.88% Nine features Weight Age FCVC FAF TUE CH2O Gender NCP NObesity 92.67% 79.17% 85.92% Five features Weight Age FCVC FAF NObesity 88.76% 72.6% 80.68% Four features Weight Age FCVC NObesity 87.06% 69.46% 78.26% Three features Weight Age NObesity 83.65% 64.2% 73.9% \\fIJCSNS International Journal of Computer Science and Network Security, VOL.21 No.3, March 2021 109 6.2 Effect of Different Partition Ratios on The Dataset Following the identification of optimal features, it was evident that each feature assumed significance in InfoGain as well as the correlation-based features selection method.\",\"1542\":\"The performance of each classifier was evaluated by performing many experiments on the data using various ratios of partition in the 50-80 range.\",\"1543\":\"Table 9 illustrates the findings of each classifier\\u2019s direction participations.\",\"1544\":\"Table 9.\",\"1545\":\"Results of different partition ratios Performance Partition ratio MLP Random Forest 91.6% 94.55% 50:50 91.48% 95.03% 60:40 93.38% 94.51% 70:30 93.18% 94.6% 80:20 6.3 Direct Partition Techniques and 10-fold validation\\u2013 Comparison During the comparison of the above two methods, it was observed that the (10-fold validation method helped obtain an improved value as compared to the direct partition ratio.\",\"1546\":\"As shown in Table 10.\",\"1547\":\"Table 10.\",\"1548\":\"Direct partition techniques versus 10-fold cross validation Proposed model Techniques MLP Random Forest 95.06% 96.70% 10-fold validation 93.38% 94.51% Partition ratio 7.\",\"1549\":\"Further Discussion Table 11 shows that the ultimate model to forecast obesity was developed using each feature via optimum parameters.\",\"1550\":\"By using the method of 10-fold cross-validation, we obtained optimal results for each Random Forest and MLP.\",\"1551\":\"Random Forest was found to outperform MLP to forecast obesity disease with a satisfactory accuracy of 96.70%.\",\"1552\":\"The classification performance could also be enhanced by using each feature (16 of them) by making use of the optimal criteria for each classifier, as illustrated in Fig.\",\"1553\":\"4.\",\"1554\":\"Through this process, we identified attributes that significantly affected the ability to predict Type II obesity disease: Weight Age, FCVC, FAF, TUE, CH2O, Gender, NCP, Height, Family_history_with_overweight, CAEC, CALC, MTRANS, FAVC, SCC, and SMOKE.\",\"1555\":\"Another indicator of the performance of the classification model is the Receiver Operating Characteristic (ROC) curve.\",\"1556\":\"The placement and proximity of this curve to the lefthand side (on the top) reveals the high accuracy level of this experiment.\",\"1557\":\"Overall, the area under the curve for each classifier shown in Fig.\",\"1558\":\"5 and Fig.\",\"1559\":\"6 shows that the most suitable classifier is determined to be Random Forest in comparison to MLP.\",\"1560\":\"The proposed method was found to surpass the findings achieved by [10] with 93.4% precision, whereas [14] showed a precision of 89.41 %.\",\"1561\":\"The results can investigate the importance of computational intelligence-based approaches to research various diseases or pathologies, detecting them early and adequately, while minimizing their societal effects Table 11.\",\"1562\":\"Performance of proposed model.\",\"1563\":\"Proposed Model Techniques MLP Random Forest 95.06% 96.70% 10-fold validation Fig 4.\",\"1564\":\"Default and optimized models \\u2013 Comparison Fig 5.\",\"1565\":\"Random Forest curve - Obesity Type II class 94 94.5 95 95.5 96 96.5 97 Random Forest MLP default model optimized models \\fIJCSNS International Journal of Computer Science and Network Security, VOL.21 No.3, March 2021 110 Fig 6.\",\"1566\":\"MLP ROC curve - Obesity Type II class 8.\",\"1567\":\"CONCLUSION Data mining involves carrying out data analysis with a view to distinguishing knowledge behaviors or patterns.\",\"1568\":\"Researchers have used this discipline to develop solutions for addressing numerous societal issues, for example disease identification on the basis of historical data.\",\"1569\":\"Analysis of obesity assumes importance as it is a global menace damaging the lives of millions of people worldwide, regardless of gender or age.\",\"1570\":\"Various authors have devoted time and effort to examine this issue and define the pathology providing a theme relating to continuous evolution.\",\"1571\":\"This study applied two techniques, random forest and MLP, to obtain the best accuracy rates to predict obesity.\",\"1572\":\"Consequently, the random forest method outperforms MLP to predict obesity at an early stage with high accuracy of 96.70%.\",\"1573\":\"The experiment showed that the algorithms work better when using all features; accordingly, all 16 features were used to achieve the highest accuracy ratio.\",\"1574\":\"The findings were found to surpass those in earlier studies [10] [14] with precision values of 93.4% and 89.41 %, respectively.\",\"1575\":\"This study\\u2019s results will facilitate the evaluation of the importance of computational intelligencebased approaches to accurately and correctly examine various diseases or pathologies, diagnose them on a timely basis, and lower the adverse impact of such diseases on society.\",\"1576\":\"In the future, it could be possible to expand this research to other feature selection approaches with a view to enhancing the obesity production\\u2019s accuracy and evaluation, also potentially replicating or adopting other machine learning algorithms.\",\"1577\":\"The dataset could also possibly be expanded in the future.\",\"1578\":\"Making use of massive data can be beneficial in the health sector.\",\"1579\":\"Quite a few studies have been carried out in this field in Saudi Arabia.\",\"1580\":\"A comprehensive data collection to develop Saudi-based models will make a significant contribution to Saudi development.\",\"1581\":\"References [1] A. Bewick and E. P. Greener, \\u201cRef 1.Pdf.\\u201d p. 4623, 1969.\",\"1582\":\"[2] H. B. Hubert, M. Feinleib, P. M. McNamara, and W. P. Castelli, \\u201cObesity as an independent risk factor for cardiovascular disease: A 26-year follow-up of participants in the Framingham Heart Study,\\u201d Circulation, vol. 67, no.\",\"1583\":\"5, pp. 968\\u2013977, 1983, doi: 10.1161\\/01.CIR.67.5.968.\",\"1584\":\"[3] A. Must, J. Spadano, E. H. Coakley, A. E. Field, G. Colditz, and W. H. Dietz, \\u201cThe disease burden associated with overweight and obesity,\\u201d J. Am. Med. Assoc., vol. 282, no.\",\"1585\":\"16, pp. 1523\\u20131529, 1999, doi: 10.1001\\/jama.282.16.1523.\",\"1586\":\"[4] B. Guy-Grand, \\u201cBeyond body mass index,\\u201d Cah.\",\"1587\":\"Nutr.\",\"1588\":\"Diet., vol. 49, no.\",\"1589\":\"3, pp. 93\\u201394, 2014, doi: 10.1016\\/j.cnd.2014.05.002.\",\"1590\":\"[5] E. Alyahyan and D. Dusteaor, \\u201cDecision trees for very early prediction of student\\u2019s achievement,\\u201d 2020 2nd Int. Conf. Comput.\",\"1591\":\"Inf.\",\"1592\":\"Sci. ICCIS 2020, 2020, doi: 10.1109\\/ICCIS49240.2020.9257646.\",\"1593\":\"[6] N. Lavra\\u010d, \\u201cSelected techniques for data mining in medicine,\\u201d Artif.\",\"1594\":\"Intell.\",\"1595\":\"Med., vol. 16, no.\",\"1596\":\"1, pp. 3\\u201323, 1999, doi: 10.1016\\/S0933-3657(98)00062-1.\",\"1597\":\"[7] M. H. J. and P. Jian and Kamber, \\u201cData Mining Techniques, Third Edition,\\u201d p. 847, 2011.\",\"1598\":\"[8] M. Khajehei and F. Etemady, \\u201cData mining and medical research studies,\\u201d Proc. - 2nd Int. Conf. Comput.\",\"1599\":\"Intell.\",\"1600\":\"Model.\",\"1601\":\"Simulation, CIMSim 2010, no.\",\"1602\":\"September 2010, pp. 119\\u2013122, 2010, doi: 10.1109\\/CIMSiM.2010.24.\",\"1603\":\"[9] R. C. Cervantes and U. M. Palacio, \\u201cEstimation of obesity levels based on computational intelligence,\\u201d Informatics Med. Unlocked, vol. 21, no.\",\"1604\":\"November, 2020, doi: 10.1016\\/j.imu.2020.100472.\",\"1605\":\"[10] B. Singh and H. Tawfik, \\u201cA Machine Learning Approach for Predicting Weight Gain Risks in Young Adults,\\u201d Conf. Proc. 2019 10th Int. Conf. Dependable Syst.\",\"1606\":\"Serv.\",\"1607\":\"Technol.\",\"1608\":\"DESSERT 2019, pp. 231\\u2013234, 2019, doi: 10.1109\\/DESSERT.2019.8770016.\",\"1609\":\"[11] R. Hossain, S. M. H. Mahmud, M. A. Hossin, S. R. Haider Noori, and H. Jahan, \\u201cPRMT: Predicting Risk Factor of Obesity among Middle-Aged People Using Data Mining Techniques,\\u201d Procedia Comput.\",\"1610\":\"Sci., vol. 132, pp. 1068\\u20131076, 2018, doi: 10.1016\\/j.procs.2018.05.022.\",\"1611\":\"[12] Z. Zheng and K. Ruggiero, \\u201cUsing machine learning to predict obesity in high school students,\\u201d Proc. - 2017 IEEE Int. Conf. Bioinforma.\",\"1612\":\"Biomed.\",\"1613\":\"BIBM 2017, vol. 2017-Janua, pp. 2132\\u20132138, 2017, doi: 10.1109\\/BIBM.2017.8217988.\",\"1614\":\"[13] M. K. U\\u00e7ar, Z. U\\u00e7ar, F. K\\u00f6ksal, and N. Daldal, \\u201cEstimation of body fat percentage using hybrid machine learning algorithms,\\u201d Meas.\",\"1615\":\"J. Int. Meas.\",\"1616\":\"Confed., vol. 167, 2021, doi: 10.1016\\/j.measurement.2020.108173.\",\"1617\":\"[14] N. Daud, N. L. Mohd Noor, S. A. Aljunid, N. Noordin, and N. I. M. Fahmi Teng, \\u201cPredictive Analytics: The Application of J48 Algorithm on Grocery Data to Predict Obesity,\\u201d 2018 IEEE Conf. Big Data Anal.\",\"1618\":\"ICBDA 2018, pp. 1\\u20136, 2019, doi: 10.1109\\/ICBDAA.2018.8629623.\",\"1619\":\"[15] J. Dunstan, M. Aguirre, M. Bast\\u00edas, C. Nau, T. A. Glass, and F. Tobar, \\u201cPredicting nationwide obesity from food \\fIJCSNS International Journal of Computer Science and Network Security, VOL.21 No.3, March 2021 111 sales using machine learning,\\u201d Health Informatics J., vol. 26, no.\",\"1620\":\"1, pp. 652\\u2013663, 2020, doi: 10.1177\\/1460458219845959.\",\"1621\":\"[16] E. De-La-Hoz-Correa, F. E. Mendoza-Palechor, A. DeLa-Hoz-Manotas, R. C. Morales-Ortega, and S. H. B. Adriana, \\u201cObesity level estimation software based on decision trees,\\u201d J. Comput.\",\"1622\":\"Sci., vol. 15, no.\",\"1623\":\"1, pp. 67\\u201377, 2019, doi: 10.3844\\/jcssp.2019.67.77.\",\"1624\":\"[17] F. M. Palechor and A. de la H. Manotas, \\u201cDataset for estimation of obesity levels based on eating habits and physical condition in individuals from Colombia, Peru and Mexico,\\u201d Data Br., vol. 25, p. 104344, 2019, doi: 10.1016\\/j.dib.2019.104344.\",\"1625\":\"[18] A. S. Nur, \\u201cArtificial Neural Network Weight Optimization: A Review,\\u201d Telkomnika, 2014.\",\"1626\":\"[19] R. A. Flauzino, Artificial Neural Networks A Practical Course.\",\"1627\":\"Springer International Publishing, 2016.\",\"1628\":\"[20] S. Riad, J. Mania, L. Bouchaou, and Y. Najjar, \\u201cPredicting catchment flow in a semi-arid region via an artificial neural network technique,\\u201d Hydrol.\",\"1629\":\"Process., vol. 18, no.\",\"1630\":\"13, pp. 2387\\u20132393, 2004, doi: 10.1002\\/hyp.1469.\",\"1631\":\"[21] Y. Qi, \\u201cRandom forest for bioinformatics,\\u201d Springer, 2012, pp. 307\\u2013323.\",\"1632\":\"[22] P. M. Chakraborty Sounak, Khalilia Mohammed, \\u201cPredicting disease risks from highly imbalanced data using random forest,\\u201d vol. 11, no.\",\"1633\":\"1, p. 51, 2011.\",\"1634\":\"[23] A. F. in A. N. L. Sarica, Alessia; Cerasa, Antonio; Quattrone, \\u201cRandom Forest algorithm for the classification of neuroimaging data in Alzheimer\\u2019s disease: A systematic review,\\u201d 2017.\",\"1635\":\"[24] and S. H. ] A. Hemmati-Sarapardeh, A. Larestani, M. Nait Amar, Chapter 2 - Intelligent models.\",\"1636\":\"2020.\",\"1637\":\"[25] B. J. Saleh, A. Y. F. Saedi, A. T. Q. Al-aqbi, and L. A. Salman, \\u201cA Review Paper: Analysis of Weka Data Mining Techniques for Heart Disease Prediction System,\\u201d Libr.\",\"1638\":\"Philos.\",\"1639\":\"Pract., vol. 7, no.\",\"1640\":\"1, p. 1, 2020.\",\"1641\":\"[26] R. Sangeetha and S. Sathappan, \\u201cPreprocessing Using Attribute Selection in Data Stream Mining,\\u201d Proc. 3rd Int. Conf. Commun.\",\"1642\":\"Electron.\",\"1643\":\"Syst.\",\"1644\":\"ICCES 2018, no.\",\"1645\":\"Icces, pp. 431\\u2013438, 2018, doi: 10.1109\\/CESYS.2018.8723918.\",\"1646\":\"[27] R. Kohavi, \\u201cWrappers for performance enhancement and obvious decision graphs,\\u201d no.\",\"1647\":\"September, 1995.\",\"1648\":\"[28] C. M. Lai, W. C. Yeh, and C. Y. Chang, \\u201cGene selection using information gain and improved simplified swarm optimization,\\u201d Neurocomputing, vol. 218, no.\",\"1649\":\"November 2018, pp. 331\\u2013338, 2016, doi: 10.1016\\/j.neucom.2016.08.089.\",\"1650\":\"[29] M. Mursalin, Y. Zhang, Y. Chen, and N. V. Chawla, \\u201cAutomated epileptic seizure detection using improved correlation-based feature selection with random forest classifier,\\u201d Neurocomputing, vol. 241, no.\",\"1651\":\"February, pp. 204\\u2013214, 2017, doi: 10.1016\\/j.neucom.2017.02.053.\"}}", "query": "Obesity is a significant problem in populations worldwide, affecting all age groups alike. According to the World Health Organization (WHO) website (2021), around 39% of the world population of adults aged 18 years and over were overweight in 2016, and 13% were obese. In 2019, over 340 million children and adolescents aged 5-19 were overweight or obese (WHO, 2021). The majority of the world's population today lives in nations where obesity and overweight kill more people than underweight (World Obesity, 2022). However, this is preventable if underlying factors leading to weight gain are identified and precautionary measures are taken to avoid being overweight and obese. In this study, factors were identified that have direct influence on Obesity in Males and Females separately, and individuals were then classified according to the response variable \u2018Obesity\u2019 into seven distinct levels, namely, Insufficient Weight, Normal Weight, Overweight Levels I, II and Obesity Levels I, II and III, with Obesity Level III being morbidly obese. The study used supervised learning techniques such as Logistic Regression (One vs. Rest approach), Decision Tree and Random Forest on data collected from South American countries of Chile, Peru, and Mexico; the highest performance was achieved in the Random Forest algorithm with an accuracy of 96.55%. ", "history": "{\"filename\":{\"1013\":\"fnut-08-669155.pdf\",\"540\":\"fgene-12-783845.pdf\",\"1144\":\"Obesity based on Decision Tree.pdf\",\"1458\":\"Obesity based on Data mining.pdf\",\"678\":\"fnut-08-669155.pdf\",\"1231\":\"Obesity based on Decision Tree.pdf\",\"1235\":\"Obesity based on Decision Tree.pdf\",\"1505\":\"Obesity based on Data mining.pdf\",\"64\":\"obesity.pdf\",\"1464\":\"Obesity based on Data mining.pdf\",\"1637\":\"Obesity based on Data mining.pdf\",\"1142\":\"Obesity based on Decision Tree.pdf\",\"1454\":\"Obesity based on Data mining.pdf\",\"1243\":\"Obesity based on Decision Tree.pdf\",\"1441\":\"Obesity based on Data mining.pdf\",\"1206\":\"Obesity based on Decision Tree.pdf\",\"1527\":\"Obesity based on Data mining.pdf\",\"605\":\"fgene-12-783845.pdf\",\"1430\":\"Obesity based on Data mining.pdf\",\"1428\":\"Obesity based on Data mining.pdf\"},\"sentence\":{\"1013\":339,\"540\":265,\"1144\":7,\"1458\":69,\"678\":4,\"1231\":94,\"1235\":98,\"1505\":116,\"64\":64,\"1464\":75,\"1637\":248,\"1142\":5,\"1454\":65,\"1243\":106,\"1441\":52,\"1206\":69,\"1527\":138,\"605\":330,\"1430\":41,\"1428\":39},\"text\":{\"1013\":\"Identification of risk factors associated with obesity and overweight\\u2013a machine learning overview.\",\"540\":\"Health Effects of Overweight and Obesity in 195 Countries over 25 Years.\",\"1144\":\"Keywords: Obesity, Data Mining, Semma, Decision Trees, Naive Bayes, Logistic Regression, Weka, Java Introduction The World Health Organization (WHO) (OMS, 2016), describes obesity and overweight as excessive fat accumulation in certain body areas that can be harmful for health, the number of people that suffers from obesity has doubled since 1980 and also in 2014 more than 1900 million adults, 18 years old or older, are suffering from alteration of their weight.\",\"1458\":\"This study ascertained data and obesity prevalence for 79 nations.\",\"678\":\"doi: 10.3389\\/fnut.2021.669155 Predicting Obesity in Adults Using Machine Learning Techniques: An Analysis of Indonesian Basic Health Research 2018 Sri Astuti Thamrin1 *\\u2020 , Dian Sidik Arsyad2\\u2020 , Hedi Kuswanto1 , Armin Lawi3 and Sudirman Nasir4 1 Department of Statistics, Faculty of Mathematics and Natural Science, Hasanuddin University, Makassar, Indonesia, 2 Department of Epidemiology, Faculty of Public Health, Hasanuddin University, Makassar, Indonesia, 3 Department of Mathematics, Faculty of Mathematics and Natural Sciences, Hasanuddin University, Makassar, Indonesia, 4 Department of Health Promotion, Faculty of Public Health, Hasanuddin University, Makassar, Indonesia Obesity is strongly associated with multiple risk factors.\",\"1231\":\"Once the dataset was validated and prepared, the data mining techniques and methods were applied, using the Weka tool, that has a set of algorithms that can be applied to many situations.\",\"1235\":\"Software Development The proposed software was based on the dataset created and implements the best data mining technique of the study.\",\"1505\":\"WEKA is able to support many data mining activities to forecast health problems, such as data preprocessing, classification, grouping, simulation, correlation, and functional choice.\",\"64\":\"Data preprocessing \\uf0b7 Data cleaning.\",\"1464\":\"From Table 1, it can be seen that similar algorithms were used to deal with different databases such as Decision Trees, Supportive Vector Machines (SVM), KMean, along with other algorithms.\",\"1637\":\"[25] B. J. Saleh, A. Y. F. Saedi, A. T. Q. Al-aqbi, and L. A. Salman, \\u201cA Review Paper: Analysis of Weka Data Mining Techniques for Heart Disease Prediction System,\\u201d Libr.\",\"1142\":\"Finally, a software was built to use and train the selected method, using the Weka library.\",\"1454\":\"This study used the data mining tool of WEKA data and carried out predictive analytics via the J48 classifier so as to ascertain the rate of accuracy.\",\"1243\":\"To be able to use the data mining methods, we added the Weka Toolkit (weka.jar), in Fig. 4 you can see the library import in the tool used for it.\",\"1441\":\"The class level precision, evaluation method and the data analysis results rely on WEKA's software using different machine learning algorithms.\",\"1206\":\"In the lower level you can find a set of algorithms that allow the network to recalculate the probabilities assigned to each level when there is new evidence about the model.\",\"1527\":\"Optimization Strategy In order to enhance the classification results and to obtain accuracy-based better performance, the Weka meta-learner (CV Parameter Selection) search methodology was used [27].\",\"605\":\"IEEE.\",\"1430\":\"Using WEKA, the Decision Trees technique was observed to have the best precision rate of 97.4%.\",\"1428\":\"Next, three techniques, Bayesian networks, Logistic Regression, and Decision trees, were chosen.\"},\"relevance\":{\"1013\":false,\"540\":false,\"1144\":true,\"1458\":false,\"678\":false,\"1231\":true,\"1235\":false,\"1505\":true,\"64\":false,\"1464\":false,\"1637\":false,\"1142\":true,\"1454\":false,\"1243\":true,\"1441\":true,\"1206\":false,\"1527\":true,\"605\":false,\"1430\":true,\"1428\":true}}"}